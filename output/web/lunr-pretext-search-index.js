var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "colophon-1",
  "level": "1",
  "url": "colophon-1.html",
  "type": "Colophon",
  "number": "",
  "title": "Open Source License",
  "body": " Open Source License   copyright  "
},
{
  "id": "dedication-1",
  "level": "1",
  "url": "dedication-1.html",
  "type": "Dedication",
  "number": "",
  "title": "Dedication",
  "body": " For everyone who wants to learn to contribute to open source projects.  "
},
{
  "id": "acknowledgement-1",
  "level": "1",
  "url": "acknowledgement-1.html",
  "type": "Acknowledgements",
  "number": "",
  "title": "Acknowledgements",
  "body": " I would like to thank Berea College for sabbatical leave support that gave me time and made this work possible. I am also grateful to the software innovation lab Tweag for financial support and the time of my Tweag mentors, Michael Gale and Georgios Karachalias.  Several parts of this textbook including the Forward and several portions of chapters 1 and 2 are modified from Karsten Wade's quiad.fedorapeople.org site Teaching Open Source . Many thanks to the authors Greg DeKoenigsberg, Chris Tyler, Karsten Wade, Max Spevack, Mel Chua, and Jeff Sheltren for releasing this work under the open source license Creative Commons Attribution–Share Alike 3.0 Unported license (\"CC-BY-SA\") which is listed as compatible with CC-BY-SA 4.0 . See Creative Commons Compatible Licenses where it states, \"your contributions to adaptations of BY-SA 3.0 materials may only be licensed under: BY-SA 3.0, or a later version of the BY-SA license .\" (Emphasis add for clarity.)  With the exception of the which is original, nearly all of is modified from Choose a License which is curated by Github . Many thanks to Github for all that they do for the open source community and for releasing this work under the Creative Commons Attribution 3.0 Unported License , which as noted in the previous paragraph is compatible with the licensing of this text.  Nearly all of is abridged and modified from the Second edition of Pro Git which is licensed under the Creative Commons Attribution Non Commercial Share Alike 3.0 license . Many thanks to the authors, Scott Chacon and Ben Straub for making such a tremendous resource available to the open source community.  I would like to thank Rob Beezer for the creation of PreTeXt which is the authoring platform of this text and for his amazing level of responsiveness in the PreTeXt support channel. I would also like to thank David Farmer for his help in the PreText support channels. Additionally, I am very grateful for Oscar Levin's work in the creation of PreText converter for Pandoc which made adaption of other open source materials much less time consuming.  Brad Miller deserves a hearty thanks for his work in creating Runestone Academy where this book is hosted, and for his collaborative work with the PreTeXt authoring group.  Finally, I would like to thank my husband, Bob Fairchild, for his patience and for his cooking as I endeavored to create this book.  "
},
{
  "id": "meta_frontmatter-preface",
  "level": "1",
  "url": "meta_frontmatter-preface.html",
  "type": "Preface",
  "number": "",
  "title": "Preface",
  "body": "   This textbook is designed for instructors, formal students, and self-learners. It explains what open source software is and teaches the basic skills of open source development incrementally, through real involvement in meaningful projects.  "
},
{
  "id": "meta_frontmatter-forward",
  "level": "1",
  "url": "meta_frontmatter-forward.html",
  "type": "Preface",
  "number": "",
  "title": "Forward",
  "body": " Forward   Why is This Book Necessary?   Note that other than making minor corrections, this Forward is unchanged from the original forward for Teaching Open Source by Greg DeKoenigsberg, Chris Tyler, Karsten Wade, Max Spevack, Mel Chua, and Jeff Sheltren. These authors have not been involved in the creation of this text, but the stated purpose is exactly the same.     In March 2006, David A. Patterson wrote an article entitled “Computer science education in the 21st century.” David A. Patterson was, at the time, the president of the Association for Computer Machinery, the world’s largest educational and scientific computing society. In this article — which, sadly, you cannot read unless you are an ACM member — he advocated for fundamental changes to how computer science is taught. One of the changes to the standard undergraduate computer science curriculum that he advocated for was the inclusion of courses in open source software development.  One might think that such a clarion call, made by someone of such obvious influence, would generate a groundswell of enthusiasm. When the president of the ACM proclaims that it is “time to teach open source development,” the world of academia must certainly follow, yes?  Its a little more complicated than that.  We've spent a lot of time over the past few years talking to computer science professors. Mostly we’ve asked lots of questions — actually, the same ones over and over.   Do you use open source software in your classes? (Increasingly.)  Are your students interested in open source? (Increasingly.)  Do you or your students participate in open source software? (Rarely.)  Do you teach open source development practices? (Almost never.)  For these last two, the follow-up question is, invariably, “why not?”   And the answer is, invariably, “because its hard.”  There are good reasons why professors don’t teach the practice of open source. It’s easy for open source advocates to explain away these reasons. At a certain point, though, one must accept the idea that most professors are well-intentioned, but bound by circumstances that make it frustratingly difficult to introduce students to open source development.  So why bother?  The answer is simple: the skills required to succeed in an open source software project are the exact same skills required to succeed in any large software project. The biggest difference is that, with just a bit of guidance, anyone can build their software skills in the open source world.  We hope that this textbook helps provide that guidance to a whole generation of students.    Why Traditional Student Projects Are Ineffective    Almost every modern computer science degree program requires its students to complete a Big Project. Sometimes it’s the “Senior Project,” and sometimes it’s the “Capstone Project.” Whatever it’s called, the purpose of this Big Project is to expose students to “real” software engineering practices.  In other words, this typically translates to “coding with other people.” Unfortunately, up until this point in a student’s education, this has usually been discouraged as “cheating.”  The problem is that these Big Projects actually tend to focus on extremely bounded problems. Most of the time, a small team of students works on a small project for a semester, and the result is, quite naturally, a small project. While good learning can take place in a small project, it actually does very little to prepare students to work on Really Big Projects.  To find Really Big Projects, one must venture out into the world, where there are Really Big Problems. The real world is full of gigantic applications that require build systems and revision control and defect tracking and prioritization of work. They are written in languages that one may or may not know, by people one may or may not ever meet. And in order to successfully navigate through these Really Big Projects, the novice developer must possess one skill above all others: the ability, in the words of our colleague David Humphrey, to be “productively lost.”  The great advantage of open source, for the learner, is that the Really Big Projects of the open source world provide unparalleled opportunities to be productively lost. Complex code bases are immediately accessible by anyone who wants to participate. This accessibility is crucial to the learner, as participating in an activity is by far the most effective way to learn that activity.  Sooner or later, the coder aspirant must work at scale, with teammates. Open source provides that opportunity in a way that nothing else can.    Using This Textbook to Get Started    This textbook exists because professors asked for it, but the textbook’s fundamental approach — teaching the basic skills of open source development incrementally, through real involvement in meaningful projects — should make it suitable for self-learners as well. Regardless of whether you are using this text as part of a course or working with it on your own, you should work through it while adhering to the principles of contributing, calling for help, and being bold.  First, always be contributing. The majority of exercises in this textbook are designed to lead to direct and useful contributions to a project, no matter how small. Even a simple act, such as adding comments to a part of the code you don’t understand, can add real value to a project; that’s the great thing about community developed software. Contribution matters, and legitimate contributions, no matter how small, are welcome in many projects.  Second, ask for help when you’re stuck. If you have trouble with an exercise — and at some point you will — look to your fellow contributors for help. Your chosen project likely has mechanisms for getting in touch with the more advanced developers: mailing lists, IRC channels, Slack channels, or Discourse channels, or forums, or more than one of the above. Communicating with those around you is not only “not cheating,” it’s key to establishing greater understanding. Keep this in mind, though: in the real world, people are most likely to help those who are trying to help themselves. Before you ask someone a question of more senior developers, ask the same question of Google. A good rule of thumb: if you can’t figure something out in 15 minutes of searching the Internet, it’s reasonable to ask for a bit of help.  And third, be bold. Try things. Break stuff. Don’t be afraid to play around with your own copy of the code; it’s only code, after all, and if you break something, you can always revert to the previous version. If you reach a point at which you think you’re ready to make a contribution of some kind, then offer to help on the project's preferred communication channel. The answer will usually be “go ahead, thanks!” Sometimes the offer will be “no thanks, and here’s why,” and you’ll learn something. Occasionally the answer will be “no, go away,” which is also useful, since it tells you to invest your energies into another project. Sometimes the answer may be silence; don’t be afraid to keep asking until you get an answer, or even plunge ahead without one. Learn the rules of the project and follow them; if the rules of the project are vague or confusing, you can help to make them clear. This alone can be a critical contribution, as it clearly helps those who come along after you.  In most educational contexts, you have likely been “trained” to wait for permission before doing anything not previously specified, but you must avoid letting that get in the way of your progress when engaging with an open source project. When the rules are unclear, don’t sit on your hands. Do your best to help the project. It’s better to do something wrong, and learn from it, than to do nothing at all.   "
},
{
  "id": "sec_oss_what_it_is",
  "level": "1",
  "url": "sec_oss_what_it_is.html",
  "type": "Section",
  "number": "1.1",
  "title": "What is Open Source Software?",
  "body": " What is Open Source Software?  This is, first and foremost, a textbook about how people create software collaboratively using a community development model, and about how you can become a member of one of those communities. When the source code is open to viewing, most people call the result of such work by the name open source software (OSS) .  The following related terms relate to OSS that guarantees additional freedoms: free software  free and open source software  FOSS  FLOSS  free\/libre and open source software Some people call free software or use both terms: free and open source software (FOSS) . Some people throw in the word libre to clarify the intended meaning of free, and call it free\/libre open source software (FLOSS) .  There are valid reasons for the usage of these different terms in different contexts, but for the sake of breadth, we primarily use the terms open source or open source software (OSS) in this book. If you are interested in additional clarification or on the history of these related types of software and the evolution of the terms, see What is Free Software by the open source GNU Operating System .  The specific definition of the term as we will use it:  open source  open source software  OSS    Open source software (OSS) is software that is designed with code that is publicly accessible and openly viewed.     Open source software is typically developed in a collaborative way. It often relies upon peer review and community member contributions, frequently with community members from all over the world. In addition to seeing the code, often anyone can also freely modify and distribute the code as they see fit as long as the open source license is followed. We will explore licensing details in   Enough of the pep talk. Its time to get started.  "
},
{
  "id": "p-41",
  "level": "2",
  "url": "sec_oss_what_it_is.html#p-41",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "open source software (OSS) "
},
{
  "id": "p-42",
  "level": "2",
  "url": "sec_oss_what_it_is.html#p-42",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "free software free and open source software (FOSS) free\/libre open source software (FLOSS) "
},
{
  "id": "p-43",
  "level": "2",
  "url": "sec_oss_what_it_is.html#p-43",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "open source open source software (OSS) "
},
{
  "id": "p-44",
  "level": "2",
  "url": "sec_oss_what_it_is.html#p-44",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Open source software (OSS) "
},
{
  "id": "sec_oss_matters",
  "level": "1",
  "url": "sec_oss_matters.html",
  "type": "Section",
  "number": "1.2",
  "title": "Why OSS Matters",
  "body": " Why OSS Matters   Because of the open nature of the source code, many credible organizations believe that OSS is at least comparable to proprietary software in the area of software security. And, security in nearly every type of software matters to some extent, often to a critical extent. A user of proprietary software must accept the level of security (as well as the lack there of) that the software vendor is able and willing to provide as well as the speed at which fixes and updates to the software are released. If the user is not willing to accept these limitations, they must simply choose a different vender. Hence, some organizations such as the US Department of Defense require that all software either have a warranty or be open source. So, open source matters for reasons of security.  Unfortunately, most people do not even read the legal terms and conditions for software packages before accepting them. A 2017 study entitled You're not alone, no one reads terms of service agreements found that over 90% of people do not read these statements before agreeing to them. Honestly, I am shocked that statistic is not even higher... So, everyone who does not read these is at the mercy of the developers, which might or might not be a safe choice. Open source should matter to those who do not read these license agreements because they and others can look at the source code.  Did you realize that open source software is so incredibly prevalent that you would be pretty hard-pressed to not be using it regularly? Android and Apple iOS very heavily dominate the global market share for cell phone operating systems. However, the Android system has more than three times as many users as Apple's iOS, and Android is open source. Linux is a family of open source operating systems that powers the majority of the webpages on the Internet. Chrome is by far the most popular browser on the planet, and while it is not fully open source, it is built on top of a number of OSS projects, the details of which can be found by going to \"chrome:\/\/credits\" in the Chrome browser's URL bar. Even Apple iOS, which as mentioned above is the second most popular operating systems for cell phones, includes a lot of OSS components which are listed in \"Settings > General > Legal and Regulatory\". We will learn a lot more about open source licensing in . So, OSS matters to everyone who uses a cell phone or searches the Internet. In fact, these are just examples, virtually any piece of software that the reader is using will likely include OSS components, so OSS should matter to you !  OSS might also matter to you if you are a student or a learner because it is real. You can see into not only the source code but also into the process of making code improvements. And if you choose to go out into the real world looking for a job as a software developer, you will have a tremendous advantage if you can prove that you have experience in real software projects — ugly, messy, confusing, gigantic real software projects.  Without OSS, getting experience in real software projects requires access, and probably permission, to see the source code. For students, that access is usually limited to those who can get  internships  or positions in  co-op  programs. Not everyone has the opportunity to spend the summer interning with a company that does large-scale software development, meaning that too few students have the opportunity to work with large (proprietary\/closed) code-bases. And even if they do, those students typically cannot show their work to anyone outside of the sponsoring company, and they sometimes cannot even discuss that work.  In the world of OSS, the source code is available to anyone who wants to see it. Not only is the source code available — also available are all of the interesting challenges that go with managing large software projects. In this book, we explore a number of these challenges and help you engage in them in direct and practical ways.    Source Control  How do fifteen software engineers work on the same piece of software together? When two software engineers decide independently to edit the same line of code, what happens? In the world of OSS, we make use of version control systems to help avoid these kinds of problems. Without version control, it’s a disaster, which is why we cover version control in the chapter .     Documentation  There’s a lot more to good software than just the code. How do you make sure people have the resources and knowledge they need to find and run (and\/or contribute to) the software that you make? Beautiful code that doesn’t get used is exactly as useful as code that was never written. Even the very best code can still have bugs, which means the ability to find and eliminate bugs is a critical skill for all software engineers. If you don’t know how to find the bugs your users find, you’re in trouble. Which is why we cover documentation and the mechanics of fixing code in the chapter entitled .  ch_building_code  Experiencing the Software Lifecycle  There’s a saying about software programs: they’re never finished, only abandoned. There’s always more work to do to improve any software project. The thing that makes OSS so unique, and so interesting to the aspiring programmer, is that anyone can participate in a OSS project. Many large projects can benefit from contribution by even novice programmers. There are also more OSS projects than ever before, with an almost unlimited number of interesting problems. Want to learn how web browsers work? Hack on Firefox. Want to put together an awesome multilingual book reader for the blind? Hack on Pretext or espeak.  Honestly, the primary key is to find a project that interests you.   Exercise: Finding a Cool Project Imagine that you have just been hired as a programmer for OSS Inc., and your manager has told you that you must spend 20% of your time to work on a OSS project that matters to you.  First, search the web and  find sites that host OSS projects . There are many. Bookmark these so that you can come back to them later.  Second,  browse through several of these sites  and find one or more projects that are interesting to you. You might be interested in projects that benefit others. You might be interested in tools that support work that you do. Or, it might be that you might find something strikes your fancy that you never considered before! Take this as an opportunity to explore broadly.  After you find an open source project of interest,  write a blog post about it . At this point, the most important thing you can probably do is to explain why the project is interesting to you.  If you don’t have a blog, set one up for free! Visit Blogger or WordPress ; setting up a new blog is easy. Blogs are widely used in the FOSS world by project members to share what they’re doing. Your voice will become one of many, and who knows — your blog might become a resource that other students later look to for inspiration when they are looking for projects to get involved in!  "
},
{
  "id": "ex-finding-a-project",
  "level": "2",
  "url": "sec_oss_matters.html#ex-finding-a-project",
  "type": "Checkpoint",
  "number": "1.2.1",
  "title": "Exercise: Finding a Cool Project.",
  "body": "Exercise: Finding a Cool Project Imagine that you have just been hired as a programmer for OSS Inc., and your manager has told you that you must spend 20% of your time to work on a OSS project that matters to you.  First, search the web and  find sites that host OSS projects . There are many. Bookmark these so that you can come back to them later.  Second,  browse through several of these sites  and find one or more projects that are interesting to you. You might be interested in projects that benefit others. You might be interested in tools that support work that you do. Or, it might be that you might find something strikes your fancy that you never considered before! Take this as an opportunity to explore broadly.  After you find an open source project of interest,  write a blog post about it . At this point, the most important thing you can probably do is to explain why the project is interesting to you.  If you don’t have a blog, set one up for free! Visit Blogger or WordPress ; setting up a new blog is easy. Blogs are widely used in the FOSS world by project members to share what they’re doing. Your voice will become one of many, and who knows — your blog might become a resource that other students later look to for inspiration when they are looking for projects to get involved in! "
},
{
  "id": "sec_oss_source_code",
  "level": "1",
  "url": "sec_oss_source_code.html",
  "type": "Section",
  "number": "1.3",
  "title": "About Source Code",
  "body": " About Source Code   Let’s start with an explanation of  source code . One cannot understand  open source  without first understanding source.    What is Source Sode  Source code is a set of instructions for computers that is meant to be read and written by humans.  Here’s an example of source code, in the C programming language, for a simple, but complete, program.   #include <stdio.h> main() { for(;;) { printf (\"Hello World!\\n\"); } }    In order to run this program, it must be compiled into machine code using a program called a compiler. First, we save the program into a file called hello.c. Then, we compile it:  gcc -o hello hello.c  The compilation command is gcc, which stands for “GNU Compiler Collection.” The flag -o sets the name of the program that we are about to generate; here, we’ve decided to call it hello. The last argument is the name of the source file that we want to compile (hello.c). After compiling the program, you should be able to run it. To run the program, type the following at the prompt:  .\/hello  This says “run the program called hello that is in the current directory.” When run, this program will print Hello World! until we kill the program. Hold down the  CTRL  key and press the  C  key to kill the program’s execution.  At this point, you have two files in your directory: hello.c, the source code, and hello, the program binary. That binary is a piece of that machine code. You can open it with a program called hexdump that will let you see the binary in a hexidecimal form. You can do this yourself on the command line:  hexdump hello  We’ve reproduced some of what it looks like when hello is viewed in hexdump after hello.c has been compiled by gcc:   0000000 457f 464c 0101 0001 0000 0000 0000 0000 0000010 0002 0003 0001 0000 8300 0804 0034 0000 0000020 0820 0000 0000 0000 0034 0020 0008 0028 0000030 001e 001b 0006 0000 0034 0000 8034 0804 0000040 8034 0804 0100 0000 0100 0000 0005 0000 0000050 0004 0000 0003 0000 0134 0000 8134 0804 0000060 8134 0804 0013 0000 0013 0000 0004 0000 0000070 0001 0000 0001 0000 0000 0000 8000 0804 0000080 8000 0804 0518 0000 0518 0000 0005 0000 0000090 1000 0000 0001 0000 0518 0000 9518 0804 00000a0 9518 0804 00fc 0000 0104 0000 0006 0000 00000b0 1000 0000 0002 0000 052c 0000 952c 0804 00000c0 952c 0804 00c8 0000 00c8 0000 0006 0000 00000d0 0004 0000 0004 0000 0148 0000 8148 0804 00000e0 8148 0804 0044 0000 0044 0000 0004 0000 00000f0 0004 0000 e550 6474 04a4 0000 84a4 0804 0000100 84a4 0804 001c 0000 001c 0000 0004 0000 0000110 0004 0000 e551 6474 0000 0000 0000 0000 0000120 0000 0000 0000 0000 0000 0000 0006 0000 0000130 0004 0000 6c2f 6269 6c2f 2d64 696c 756e 0000140 2e78 6f73 322e 0000 0004 0000 0010 0000 0000150 0001 0000 4e47 0055 0000 0000 0002 0000 0000160 0006 0000 0012 0000 0004 0000 0014 0000 0000170 0003 0000 4e47 0055 ac29 394b 26bf 01f1 0000180 e396 f820 3c24 f98c 8c5a 8909 0002 0000 0000190 0004 0000 0001 0000 0005 0000 2000 2000 00001a0 0000 0000 0004 0000 4bad c0e3 0000 0000 00001b0 0000 0000 0000 0000 0000 0000 0001 0000 00001c0 0000 0000 0000 0000 0020 0000 002e 0000 00001d0 0000 0000 0000 0000 0012 0000 0029 0000 00001e0 0000 0000 0000 0000 0012 0000 001a 0000 00001f0 848c 0804 0004 0000 0011 000f 5f00 675f  That’s only a small chunk of the program binary. The full binary is much larger — even though the source code that produces this binary is only two lines long.  As you can see, there’s a huge difference between  source code , which is intended to be read and written by humans, and  binary code , which is intended to be read and written by computer processors.  This difference is a crucial one for programmers who need to modify a computer program. Let’s say you wanted to change the program to say “Open source is awesome!!!”. With access to the source code, making this change is trivial, even for a novice programmer. Without access to the source code, making this change would be incredibly difficult. And this for two lines of code.    On Decompilation  Compilation transforms a high-level language into a low-level language like machine code or byte code. Decompilation is the reverse. The process of reverse engineering a program from its binary code to source code is called decompiling , and the level of difficulty of decompiling a program differs rather significantly by the programming language of the source code. C code is notoriously difficult to decompile, while Java is much easier, partly because of far fewer compiler optimizations and partly because the intact metadata including such details as data types and method names.  The challenges of decompilation and the potential security risks inherent in programs that are closed source led the Research Directorate of the US National Security Agency (NSA) to develop a suite of open source reverse engineering and decompilation tools called Ghidra . That this work was developed by one of the top cybersecurity agencies in the world and that they released and maintain it as open source software stands as a very strong testimonial to both the potential security concerns inherent in closed source software and to the potential security benefits of open source software.  Note that copyright law generally provides the copyright holder with a set of exclusive rights. Decompilation is carried out by making copies of the software program, and so to be in compliance with law, one must consider the copyright before undertaking decompilation. Laws in both the United States and Europe do permit decompilation to a limited extent and for limited specific purposes. Laws in other areas of the world will vary, but reverse engineering a program for the purpose of reselling it under a different name and license would likely open you up to legal battles – the authors of this text strongly caution you against such action.   Exercise – Change the source code Change the source code to print out “Open source is awesome!!!” instead of “Hello World!”. Spend no more than half an hour on this exercise.  Optional (Very Difficult) Exercise – Change the binary code Change the binary code to print out “OSS Rocks!” instead of “Hello World!”. Spend no more than half a day on this exercise. This is actually a very tricky exercise, and it could take you a fair bit of time. We included it here because you might be curious and want to go poking around in the binary. Under most flavors of Linux you should be able to find or install a program called hexedit. To get you started, you use  TAB  to switch from hex to ASCII, \/ to search, and  F2  to save your changes. You can read the rest of the documentation for hexedit by reading the manpage, which you can get to by typing man hexedit on the command line, or pressing  F1  while running hexedit.  "
},
{
  "id": "p-64",
  "level": "2",
  "url": "sec_oss_source_code.html#p-64",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "compiled "
},
{
  "id": "p-66",
  "level": "2",
  "url": "sec_oss_source_code.html#p-66",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "CTRL C "
},
{
  "id": "p-72",
  "level": "2",
  "url": "sec_oss_source_code.html#p-72",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "decompiling "
},
{
  "id": "exercise-change-the-source-code",
  "level": "2",
  "url": "sec_oss_source_code.html#exercise-change-the-source-code",
  "type": "Checkpoint",
  "number": "1.3.1",
  "title": "<dfn class=\"terminology\">Exercise – Change the source code<\/dfn>.",
  "body": "Exercise – Change the source code Change the source code to print out “Open source is awesome!!!” instead of “Hello World!”. Spend no more than half an hour on this exercise. "
},
{
  "id": "optional-exercise-change-the-binary-code",
  "level": "2",
  "url": "sec_oss_source_code.html#optional-exercise-change-the-binary-code",
  "type": "Checkpoint",
  "number": "1.3.2",
  "title": "<dfn class=\"terminology\">Optional (Very Difficult) Exercise – Change the binary code<\/dfn>.",
  "body": "Optional (Very Difficult) Exercise – Change the binary code Change the binary code to print out “OSS Rocks!” instead of “Hello World!”. Spend no more than half a day on this exercise. This is actually a very tricky exercise, and it could take you a fair bit of time. We included it here because you might be curious and want to go poking around in the binary. Under most flavors of Linux you should be able to find or install a program called hexedit. To get you started, you use  TAB  to switch from hex to ASCII, \/ to search, and  F2  to save your changes. You can read the rest of the documentation for hexedit by reading the manpage, which you can get to by typing man hexedit on the command line, or pressing  F1  while running hexedit. "
},
{
  "id": "sec_oss_share_code",
  "level": "1",
  "url": "sec_oss_share_code.html",
  "type": "Section",
  "number": "1.4",
  "title": "On Sharing Source Code",
  "body": " On Sharing Source Code   Obviously, not all software is FOSS.    Source Code: To Share, or Not To Share?  Most software developers do not share their source code — especially companies that produce software with the intention of selling software to their customers. Microsoft, for example, does not share the source code for the Windows operating system.  Even freeware — programs that are downloadable for free from the internet — may not share their source code with the world. You can get the program for free, but if it breaks, or if you think of a way to make it better, there’s no good way to fix it if you don't have the source code. For example, you can get the Flash Player from Adobe for free, but if you find a bug that crashes Firefox, you’re stuck with that bug until Adobe fixes it.  There are definite advantages to keeping source code hidden, especially if your goal is to sell the software itself. It’s harder to sell a software program when anyone is free to take the source code and use it for any purpose. If Microsoft were to release the Windows source code under an open source software license, anyone would then be able to take that source code, build “Bob’s Own Operating System,” maybe make a few changes, and then re-sell that product as a competitor to Microsoft Windows. Obviously, most companies who are selling commercial software don’t want that to happen.    The value of sharing  That’s not to say that programmers who write open source software never make money. Some of the most successful companies in the world use open source software to power their businesses. Google, Amazon, Wall Street, the US Department of Defense — some of the world’s largest and most innovative companies, government agencies, and industries are writing software using FOSS every day. They don’t sell that code; they share it, and by sharing, create more value for their organizations.  The amazing thing about contributing to FOSS software is that you don’t have to work for a large company to see the benefits of working in a free and open manner. As a developers, you might write a utilities that solves a particular problem. By sharing it, others might discover the utility of your tool. Others might extend it and help see it grow. At this point, what started as a hack has become something valuable for many. At this point, we begin to see how FOSS development practices can provide demonstrable advantages over proprietary software development practices. Among them:    Shared development cost . Writing software can be expensive, at least in terms of time. Good software takes time to develop, and time is money. And if writing software is expensive, then maintaining it is even more expensive. In the FOSS model, the cost of the writing and maintaining the software can be spread out over several individuals and\/or companies.   Users can fix their own bugs . This is not a freedom that is obviously useful to everybody. Not every software user is knowledgeable enough to fix a bug when they find it. That’s fine; FOSS also means that users can find other people to fix their bugs for them. Not everybody who owns a car is competent to change their own oil, but the freedom to change your oil, or fix a flat tire, or rebuild your own brakes — or the freedom to be able to go to any mechanic or any mechanically inclined friend and ask them to do it for you — is a crucial freedom to car owners. FOSS extends that freedom to software.   (Arguably) better and (potentially) more secure software.  Allowing users to fix bugs can often lead to better and potentially more secure software. One of the problems with proprietary software is that there’s a limit to the number of people companies can pay to fix code — that limit is usually directly proportional to how many software licenses the company can sell. OSS projects have the potential to build a huge base of participants, far greater than the number of developers that any one company could pay. The Apache HTTP server project is a great example of an OSS project with many developers, both commercial and independent — that has created  demonstrably more popular  and arguably better and more secure software than any of its proprietary counterparts.   Software that outlives its creator.  There are literally thousands and thousands of pieces of software, written for outdated computers, that are no longer useful for any purpose. If we had source code for these pieces of software, we might be able to extend them to new computers, making them continually more useful and more interesting — but because we don’t have the source code for these programs, we have very little use for them anymore. There’s a word for this kind of software: abandonware. In FOSS, there’s no such thing as abandonware . Sure, people may stop working on a piece of software, but the source is always there, ready to be picked up and carried forward by anyone who has the time and interest to do so. Every dead FOSS project has a chance to be reborn.   The freedom to fork.  Sometimes software projects go wrong. If a project is proprietary, no one has any recourse if they don’t like the direction of the project: the owner of the project decides the direction of the project, period. But because FOSS guarantees everybody the right to redistribute and modify the source code, developers can always take a FOSS project and move it in a new direction, without anybody’s permission. This process is called  forking . Forks are usually regarded as last resorts, since contentious forks can divide scarce developer resources and confuse users. However, a number of FOSS projects have benefited greatly from forks; the  X.org server  and  Inkscape  are notable successful forks.    Exercise: List of software Create a list of all the software that you use on a regular basis. Which software is OSS? Which applications have OSS equivalents? What are those equivalents?  Exercise: Compare and contrast similar proprietary and OSS software Choose one piece of proprietary software that you use regularly and find its OSS equivalent if it has one. (If not, pick another program.) Write a blog post comparing the two. Don’t just look at the code; look at the entire experience. How are the user interfaces different or similar? What about the user’s experience overall? Is the quality of the documentation comparable? Is one buggier than the other? (This may take some spelunking in forums, looking for bug reports, etc?) What, in your estimation, would it take for a new user to switch from the proprietary, closed-source software to the FOSS equivalent?  Exercise: Install a new OSS tool and blog about it Go find a new piece of open source software that interests you. Install it, and blog about any problems that you have. Bear in mind that your notes may come in handy during later exercises.  "
},
{
  "id": "p-84",
  "level": "2",
  "url": "sec_oss_share_code.html#p-84",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Shared development cost Users can fix their own bugs (Arguably) better and (potentially) more secure software. Software that outlives its creator. The freedom to fork. "
},
{
  "id": "exercise-list-of-software",
  "level": "2",
  "url": "sec_oss_share_code.html#exercise-list-of-software",
  "type": "Checkpoint",
  "number": "1.4.1",
  "title": "Exercise: List of software.",
  "body": "Exercise: List of software Create a list of all the software that you use on a regular basis. Which software is OSS? Which applications have OSS equivalents? What are those equivalents? "
},
{
  "id": "exercise-compare-and-contrast-proprietary-and-foss-software",
  "level": "2",
  "url": "sec_oss_share_code.html#exercise-compare-and-contrast-proprietary-and-foss-software",
  "type": "Checkpoint",
  "number": "1.4.2",
  "title": "Exercise: Compare and contrast similar proprietary and OSS software.",
  "body": "Exercise: Compare and contrast similar proprietary and OSS software Choose one piece of proprietary software that you use regularly and find its OSS equivalent if it has one. (If not, pick another program.) Write a blog post comparing the two. Don’t just look at the code; look at the entire experience. How are the user interfaces different or similar? What about the user’s experience overall? Is the quality of the documentation comparable? Is one buggier than the other? (This may take some spelunking in forums, looking for bug reports, etc?) What, in your estimation, would it take for a new user to switch from the proprietary, closed-source software to the FOSS equivalent? "
},
{
  "id": "exercise-install-new-foss-tool-and-blog-about-it",
  "level": "2",
  "url": "sec_oss_share_code.html#exercise-install-new-foss-tool-and-blog-about-it",
  "type": "Checkpoint",
  "number": "1.4.3",
  "title": "Exercise: Install a new OSS tool and blog about it.",
  "body": "Exercise: Install a new OSS tool and blog about it Go find a new piece of open source software that interests you. Install it, and blog about any problems that you have. Bear in mind that your notes may come in handy during later exercises. "
},
{
  "id": "sec_oss_contributor_mountain",
  "level": "1",
  "url": "sec_oss_contributor_mountain.html",
  "type": "Section",
  "number": "1.5",
  "title": "Climbing Contributor Mountain",
  "body": " Climbing Contributor Mountain   Participation in FOSS projects is similar, in many ways, to an apprenticeship. It takes some effort, and some help, to work your way to the top. Let’s watch the path a typical newbie takes up Contributor Mountain.     a visual of the contributor mountain with user at the bottom     User  Everyone begins at the base of the mountain as a user of software. Let’s take our hypothetical friend Alice as an example.  Alice is a budding artist, and she likes to share her work with friends online. She’s a big fan of anime. One of her friends suggests that she might be interested in a program called  Inkscape , a cool illustration program.  So Alice goes and downloads Inkscape and installs it on her computer. She plays with it. She doesn’t understand it very well, but it seems kinda cool.  Then her friend points her to a couple of Inkscape anime tutorials online, and Alice’s opinion of Inkscape changes from “kinda cool” to “incredibly cool.” Within a few short months and a lot of practice, Alice becomes a devoted Inkscape user. As it happens, developers sometimes forget that  users are the reason that software exists. Alice, in becoming a devoted and expert user of Inkscape has taken the first, critical steps to being a valuable contributor to the Inkscape project.  Note: Alice may not yet know, or care, that Inkscape is FOSS software; in fact, she probably doesn’t even know what FOSS is. It’s irrelevant to her. She loves the fact that Inkscape is freely available, which is one of the great features of FOSS software — but beyond that, the concept of FOSS just isn’t meaningful to her. Yet.    Seeker  The Internet has changed the way we ask questions. Billions of people can now go to a web page, ask almost any imaginable question, and get some kind of response — maybe right, maybe dramatically wrong, but some kind of response. It is this experience that is, in no small part, why the word “google” is now a verb. Alice, without realizing it, will quickly move from a “User” of Inkscape to a “Seeker” of information.  Our friend Alice has a problem. She has an Inkscape file with lots of cool images that some of her friends have made, and she wants to use them as part of a new illustration she’s working on. But when she opens that file, and then tries to cut and paste into a new document, Inkscape crashes. Well, it crashes  sometimes . And this unpredictability is becoming annoying — so Alice goes to her favorite online anime discussion forum to ask her friends if they’re seeing this problem.  One friend recommends that she go ask on the Inkscape developers mailing list. Another friend recommends that she file a bug. A third friend asks for more details: when does it happen? Does it happen randomly, or can she make it happen by doing a particular thing over and over? Then another person pops up and says that yes, he’s had that problem too, but he works around it by opening his documents in a certain order. After some back-and-forth with this new friend, trying to figure out exactly what he means, Alice figures out the workaround: no more crashes! Alice thanks everyone for their help and gets back to her project.  Alice has become a seeker. By looking for answers, Alice has discovered a broad community of people who are willing to help her figure out how to do things a better way.    Collaborator  This bug still bugs Alice.  When she forgets about the workaround, the bug still bites her. Lately, some of the other people who hang out on her anime forums have been complaining about this bug, too, and she always points them to the forum thread where she learned about the workaround. But still she wonders: when is it going to get fixed?  And then she wonders: is there anything I can do about it?  This crucial step is what makes FOSS unique: it’s the step at which Alice decides to become a collaborator.  Why? Good question. Contributors to FOSS have many different reasons — but a frequently heard rationale is the desire to “scratch an itch.” Alice loves Inkscape, but she hates this bug.  She thinks back to the forum discussion in which one of her friends advised her to “file a bug.” She’s not even quite sure what that means, exactly, but now that she’s decided she wants to help, she starts looking around. After a bit of googling and sorting through some stuff that doesn’t make any sense to her at all, she finds a page on the Inkscape wiki that tells her what to do.  One sentence stands out: “Check the bug tracker first; your bug may be already there.” So she goes to the Inkscape bug tracker and searches for “crash”, and finds a ton of bugs — seems like software crashes a lot! She tries a few more search terms (like “copy” and “paste”), and the number of bugs she has to look through starts to drop. Alice’s search through the bugs uncovers a great deal that she doesn’t quite understand… until she finds a bug that looks almost exactly like her bug! She sees some comments on the bug that say things like “I’ve confirmed this on my Ubuntu system” and so on — so she creates an account for the Inkscape bug tracker, and adds her comment, confirming that she, too, has experienced this bug on her Mac Powerbook. Two months later, she receives an email that the latest version will contain a fix.  Even a seemingly small collaboration can be useful.    Contributor  The line between collaborator and contributor can be a blurry line, and there are many ways to define contribution, but here’s one good way of thinking about it: a contributor is a person that a FOSS community actively relies upon for help.  Of course, some contributors focus on writing code — but for the most successful projects, this is a comparatively small percentage of contributors. Some contributors maintain a wiki and help keep it up to date. Some contributors test every new beta version the day it’s released. Some write documentation about the project. Some go through bug reports, to make sure that bugs are useful for developers. Some blog about the new features to help spread the word.  All of these contributors are making their projects better — and every FOSS project needs more of these kinds of contributors.  It is our hope that this book will help guide you, the reader, to the top of the Contributor Mountain.   "
},
{
  "id": "p-91",
  "level": "2",
  "url": "sec_oss_contributor_mountain.html#p-91",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Inkscape "
},
{
  "id": "p-93",
  "level": "2",
  "url": "sec_oss_contributor_mountain.html#p-93",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "users are the reason that software exists. "
},
{
  "id": "sec_oss_build_portfolio",
  "level": "1",
  "url": "sec_oss_build_portfolio.html",
  "type": "Section",
  "number": "1.6",
  "title": "Building your OSS Portfolio",
  "body": " Building your OSS Portfolio   Perhaps the greatest benefit of contributing to OSS projects: you have the opportunity to prove, to yourself and to others, that you can usefully contribute to real software projects. You will meet and interact with other developers, some of whom work on OSS projects for a living. If you can help them solve their problems, they are inclined to help you solve yours — with advice, contacts, recommendation letters, and maybe even job offers.    Building Your OSS Portfolio  One of the big differences between working in OSS and working on proprietary software is that your work is visible to anyone who cares to look. Every mailing list post you write, every blog entry you post, every bug report you file, every word of documentation you improve, every wiki page you edit, and every line of code you write, are available for anyone’s inspection.  This a huge potential advantage, if you know how to use it. In the coming chapters, as you begin to engage with your chosen OSS project, we point out portfolio building opportunities.  Really, though, the portfolio should be a side effect. If you choose a project that matters to you, and if you work hard to help that project achieve its goals, then your portfolio builds itself.   Exercise: Learn about a project’s leaders Revisit the project you blogged about in , and spend some time figuring out who some of the project leaders are. Read through the project wiki, mailing lists, and so on. What can you find out about the project leaders? What information do they make available about themselves? Given what you’ve read, what do you think about their work?  Exercise: Write your own OSS bio Find an online wiki provider —  Wikispaces , for example — and create a wiki page that will become your online OSS portfolio. Write a little bit about yourself. Link to content: your resume, your blog, your Twitter account, or anything that might be relevant to potential employers. You will use this portfolio extensively over the course of this book.   Supplemental Materials   The Cathedral and The Bazaar is a great story about the OSS principles in action. Written originally in 1998 by Eric S. Raymond, it’s considered a must-read by many OSS practitioners.   "
},
{
  "id": "ex-learn-about-a-projects-leaders",
  "level": "2",
  "url": "sec_oss_build_portfolio.html#ex-learn-about-a-projects-leaders",
  "type": "Checkpoint",
  "number": "1.6.1",
  "title": "Exercise: Learn about a project’s leaders.",
  "body": "Exercise: Learn about a project’s leaders Revisit the project you blogged about in , and spend some time figuring out who some of the project leaders are. Read through the project wiki, mailing lists, and so on. What can you find out about the project leaders? What information do they make available about themselves? Given what you’ve read, what do you think about their work? "
},
{
  "id": "ex-write-your-own-oss-bio",
  "level": "2",
  "url": "sec_oss_build_portfolio.html#ex-write-your-own-oss-bio",
  "type": "Checkpoint",
  "number": "1.6.2",
  "title": "Exercise: Write your own OSS bio.",
  "body": "Exercise: Write your own OSS bio Find an online wiki provider —  Wikispaces , for example — and create a wiki page that will become your online OSS portfolio. Write a little bit about yourself. Link to content: your resume, your blog, your Twitter account, or anything that might be relevant to potential employers. You will use this portfolio extensively over the course of this book. "
},
{
  "id": "sec_community_global",
  "level": "1",
  "url": "sec_community_global.html",
  "type": "Section",
  "number": "2.1",
  "title": "The Challenges of Global Community",
  "body": " The Challenges of Global Community  Most OSS projects are (or aspire to become) distributed, global communities. This introduces a number of challenges:  Language Any global community will of necessity include participants with different native languages. Large projects usually evolve collaborative subgroups that work on documentation and localization for specific languages, but contributors to code and base documentation need a common language in which they can communicate. In many cases, the common language is English, in part because it is one of the most widely spoken languages today. However, the fact that the reserved keywords and base documentation for many programming languages are in English may also be a critical factor. In Eric S. Raymond's How to Become a Hacker , Linus Torvalds, the original creator of the Linux kernel, is quoted as saying that it never occurred to him to comment the Linux kernel code in any language other than English, despite the fact that English is his third language.  Time and distance The fact that our globe spins introduces some interesting challenges: collaborators in India and the USA, for example, will never be able to collaborate in real time during normal business hours – in fact, they'll hardly be able to collaborate during normal waking hours. Most communities meet face-to-face only once or twice a year, if at all, and the face-to-face meetings usually involve only a small subset of the whole community. These challenges have forced the development of really good asynchronous online communication tools. However, having people in different timezones also has some advantages, making it easier to respond in a variety of threads, follow rapidly-developing security issues, and manage infrastructure 24×7.  Ego Standing out in an ocean of nicknames and e-mail addresses, trusting people you have never met, and accepting criticism from strangers is very difficult. Control freaks, glory-grabbers, bullies, and fear-mongers exist in OSS communities and are poisonous to community-building. Creating and maintaining a fork of a major software project is a significant undertaking that is not usually done except as a last resort, because it divides community attention and requires duplication of resources; however, the simple fact that a fork is possible and the community is essential often provides an effective check on runaway egos.  Knowledge-level Knowledge-level can be tied up in ego. When you are new to any community, you are a novice on the culture of that community even if you are an expert in some of the tools and languages used by that community. As you endeavor to become a new member of an open source community, it is good to remember that you are a novice to the culture. Some good advice is to read the contribution guide (if the project has one), read the community discussions such as in relevant discussion forums and in bug reports. If you first try to get a sense of how the community operates before you violate any implicit or explicit rules, you are much more likely to be welcomed in. For example, it could be frustrating to try to maintain code quality with volunteer contributors who are happy to contribute but who have not tried to understand the existing standards (such as formatting, documentation, or tests).    "
},
{
  "id": "sec_oss_third_culture",
  "level": "1",
  "url": "sec_oss_third_culture.html",
  "type": "Section",
  "number": "2.2",
  "title": "The Synthetic Third Culture",
  "body": " The Synthetic Third Culture  Ruth Hill Useem developed the term Third Culture Kids (TCKs) forty years ago to describe the children of military, diplomatic, missionary, and other families who exist in a twilight world between their passport countries and the countries in which they live. Often, these children are neither at home in their birth culture nor in the culture in which they live day-to-day, a fact that often becomes evident only upon returning to their native country. TCKs usually feel more at home with other TCKs than with other people.  In a somewhat similar way, OSS communities often create their own culture, which is not the native culture of any of the participants. When Chinese developers work with Brazilian colleagues day after day, their communication does not usually reflect much of either Chinese nor Brazilian culture. When joined by colleagues from (say) Morocco, Russia, Canada, and Australia, native culture is made even less significant. Over time, the communities build up shared experiences, humor, social norms, and conventions that define that community, building up a synthetic third culture.  This is not unique – collaborative groups have always developed their own sense of identity. The difference with most OSS communities is that the collaboration is remote, so the participants remain in their native cultural context while participating in the synthetic third culture of the OSS community, and the interaction is high-volume and sustained over a long period of time (decades, in some cases). Obviously, the diversity, intensity, and health of the community play a significant role in the depth and uniqueness of the third culture.  If you are used to being part of a dominant culture, joining a new culture may be an unfamiliar experience, but the best advice is similar to the advice given to anyone traveling to a different part of the world:  Open-mindedness Remember that you are new to the culture, so keep an open mind and pay attention to the interactions of those who are more experienced in the culture. Note both the differences from and the similarities with your expectations, but try not to react to them before you reflect on them.  Gratitude Even if your intentions are good, you are likely to need help learning the culture and the cultural expectations. If people try to help you, be sure to express your gratitude!  Attentiveness Try to understand the culture by doing your homework. Read the materials designed to help novices including not just the README and the contribution guide, but also the interactions on the various communication channels, bug reports, etc.    "
},
{
  "id": "sec_community_qualities",
  "level": "1",
  "url": "sec_community_qualities.html",
  "type": "Section",
  "number": "2.3",
  "title": "Qualities of an OSS Community",
  "body": " Qualities of an OSS Community   Each OSS community has a rich set of defining qualities. Understanding these qualities is essential to evaluating and participating in the community:    Focus  What does the community want to achieve? The stated goals may be broader than the actual interest and focus of the community. For example, a group may state that they're developing a Geographic Information System (GIS), which is a broad goal, but the actual software may be focused on just one particular use of GIS.    Maturity and History  Is the project new or old? Young communities may not have developed effective procedures and rhythms, or may not yet have attracted contributors other than developers (such as documentation writers, artists, testers, and marketers). On the other hand, older communities may have plateaued with a stable, complete product (good) or stagnated (bad). Some of the oldest OSS communities, such as the X Windows community, have gone through multiple periods of rapid development, stable releases, stagnation, and rejuvenation.    Type of Openness  The term open source is broadly applied, but there are many different types and degrees of openness. Some projects are open in a lob-the-software-over-the-wall sense: the code has been released under an open source license, but no community has formed around it; periodically, a new source tarball comes flying over the wall to play with, and it's not obvious how to contribute improvements back to the main source of the code, or if it's even possible at all. Some projects have an active community but a strict management hierarchy anchored by a dictator-for-life or impenetrable core committee, while others have an openness that extends to their management structure. There are also projects where the core source code is tightly controlled, but are extremely open in peripheral areas such translations, documentation, and community support.    Commercial ties  Is there a company (or companies) sponsoring the project? Some sponsors provide only resources (funding, equipment, infrastructure), while others provide technology, legal protection, people, or some combination. It's important to understand how much influence the sponsors have in the overall direction of the project, and whether the community can continue if the sponsor pulls out (or fails).    Subgroups  Does the community operate as a whole, or does it operate as a collection of subgroups? Some large communities have formally-defined subgroups, while others have communities that form, expand, contract, and dissolve in an organic way as needed. Sub-groups may also be defined along technological, use-case, geographic, or functional lines.    Skills  Each community requires and focuses on different sets of skills. In some cases, a community could benefit from having new contributors with skill sets that are not currently represented or even recognized as being needed.    Mentoring and Training  Some communities grow in a haphazard way, others offer guidance for new contributors, still others provide clearly-defined, simple on-ramps with purposeful training and mentorship programs.   Exercise – Explore Community Qualities Go to your chosen project and research the following, providing links as evidence :  Maturity and History Discuss the maturity and the history of the project.  Focus How the focus of the community changed over time? Has it changed greatly or very little? Explain.  Type of Openness Describe the type of openness you witness.  Commercial ties Are there commercial ties? If so, how much influence do the sponsors have?  Subgroups Can you identify any formal or informal subgroups that operate on differing tools or aspects?  Skills Can you identify differentiation of skill sets? Any specific skill sets that are needed?  Mentoring and Training How does the community work to onboard novice members? After researching the above, use just a paragraph to summarize and reflect on the culture and its overall culture.   "
},
{
  "id": "exercise-explore-community-qualities",
  "level": "2",
  "url": "sec_community_qualities.html#exercise-explore-community-qualities",
  "type": "Checkpoint",
  "number": "2.3.1",
  "title": "Exercise –  Explore Community Qualities.",
  "body": "Exercise – Explore Community Qualities Go to your chosen project and research the following, providing links as evidence :  Maturity and History Discuss the maturity and the history of the project.  Focus How the focus of the community changed over time? Has it changed greatly or very little? Explain.  Type of Openness Describe the type of openness you witness.  Commercial ties Are there commercial ties? If so, how much influence do the sponsors have?  Subgroups Can you identify any formal or informal subgroups that operate on differing tools or aspects?  Skills Can you identify differentiation of skill sets? Any specific skill sets that are needed?  Mentoring and Training How does the community work to onboard novice members? After researching the above, use just a paragraph to summarize and reflect on the culture and its overall culture.  "
},
{
  "id": "sec_community_communication",
  "level": "1",
  "url": "sec_community_communication.html",
  "type": "Section",
  "number": "2.4",
  "title": "OSS Community Communication",
  "body": " OSS Community Communication   Communication in an open-source community takes many forms, but all of these break down into two broad categories: synchronous (simultaneous, e.g. in person meetings or video conference meetings) and asynchronous (non-simultaneous, e.g. email or various kinds of messaging services). Due to the geographically-dispersed nature of most communities, most OSS communication makes heavy use of asynchronous technologies. Synchronous communications typically includes various forms of audio\/video chat, which is neither convenient nor efficient for widely dispersed OSS communities. Asynchronous communications are much more varied and most OSS communities use more than one asynchronous form of communication. When a software team is made of full-time people who all work the same hours in the same office building, it is easier to have a higher proportion of synchronous discussion, but when some contributors are sleeping while others are working, it is far harder, so it is not a big surprise that the vast majority of OSS communication is asynchronous.    Websites  The first place where people discover an OSS community is typically a website. To make a website available to all users, it must be hosted on a web server referred to as a host that serves the page. Unfortunately, the nature of traditional HTML pages is that they are often a static, one-to-many form of communication created by a small number of people with write access to the server. This leads to websites that can become quickly outdated and which do not truly reflect the collaborative nature of the community. We will see how OSS communities work around this issue and make their website a collaborative project in the next section.  All OSS communities need to have their code hosted in a place where it can be viewed and potentially contributed to. This is where software engineering collaboration platforms step in.    Software Engineering Collaboration Platforms (SECP)  Virtually every open source community uses a Software Engineering Collaboration Platform (SECP) such as GitHub , Gitea , GitLab , or Bitbucket , each of which provides a comprehensive collection of features that are required for software development in OSS communities. These features arise naturally from the need store code, to discuss issues related to the code, to employ version control, and other needs:   Repositories  It goes without saying that an OSS needs to store the code base in a way that it can be accessed by the community of current and potential contributors. A repository , aka repo , is a file storage location used by a version control system to keep track of not only versions of the code base itself but also to keep track of project documentation, discussions, web pages, and more. Repos are nearly always hosted in a SECP, although they are also sometimes self-hosted by the project.    Issue Trackers   Issue trackers are designed to record, track, and resolve bugs, feature requests, questions, etc. After an issue is posted, discussions on the issue typically occur and are sometimes prolonged. These discussions are most conveniently attached to the issue itself to facilitate the tracking of the discussion, which is particularly important in larger projects. When an issue is posted, it can be discussed by the community to decide on how to proceed with it. The issue can be categorized and linked to other discussions, projects, and engineering work as well. You are definitely advised to read all unresolved issues before posting so you are not duplicating another existing issue.  A number of features exist in most issue trackers that facilitate communication among contributors and potential contributors. These include linking, labelling, mentioning a particular user, etc.  One important feature that exists in issue trackers is the ability to label the issue with one or more of a set of labels. Github, for example, provides the following default labels:    bug : indicates an unexpected problem or unintended behavior.     documentation : indicates a need for improvements or additions to documentation.     duplicate : indicates similar issues, pull requests, or discussions. These related items are then typically linked for convenience.     enhancement : indicates new feature requests.     good first issue : indicates a good issue for first-time contributors. The mere presence of this label indicates an openness to new contributors, so this is a very important label to look for when you are a potential new contributor.      help wanted : indicates that a maintainer wants help on an issue or pull request.     invalid : indicates that an issue, pull request, or discussion is no longer relevant.     question : indicates that an issue, pull request, or discussion needs more information.     wontfix : indicates that work won't continue on an issue, pull request, or discussion.   Note that although the above default labels are included in every new Github repository, maintainers may or may not use all of them, and many maintainers choose to edit or delete some of the default labels and\/or add their own custom labels that make sense for that project.    Merge Requests  Software developers use the term merge request or pull request (PR) to describe a request to initiate the process of requesting an integration of specific code changes into the project repository. Best practice before making a merge request is to have initiated an earlier discussion using one of the forms of communication favored by the project. After this discussion, a (potential) contributor opens a merge request, which may then undergo several iterations of automatic checks, manual code reviews by one or more other contributor, as well as further discussion.  It is important to understand that even in the best of circumstances, the typical merge request initiates further discussion and\/or recommendation(s) for improvements from the core team of the OSS project. To those new to the OSS world, these discussions may come as a surprise, but they should not. Even then the core OSS term is likely to ask for further refinements. This is normal and to be expected.    Project Boards  A project board facilitates organization of project tasks. Project boards typically utilize a visual tool similar to the Kanban scheduling system used in lean manufacturing. SECPs provide such boards, and many projects use the ones provided in their SECP. However, some projects use an external tool like Trello or one of the open source alternatives such as Kanboard or Taiga . These project boards are typically made up of things like issues, merge requests, files, tags, and notes that are categorized as cards which are organized into columns. Most platforms offer a lot of flexibility, so one can add tags, set deadlines, search, reorder columns, reorder cards within a column, move cards from one column to another column, etc. The project boards at: Microsoft VSCode Project Boards and Homebrew Project Boards , and NixOS Project Boards offer good examples of projects that use the SECP's project boards.  If you wonder why some projects don't seem to use project boards, consider that in many OSS projects, there are no paid project leaders who can set goals, organize all of the issues into boards, prioritize tasks, etc. For the majority of OSS projects, there either isn't time to take manage project boards or the project is too small to derive much benefit from their use.    One of the many features these software engineering collaboration platforms (SECP) sometimes offer is web hosting, which when enabled, facilitates structured collaborative editing of the site. As an example, GitHub Pages affords hosting as a website for projects that are managed on GitHub. This means that OSS communities can use their SECP of choice as their a host for their website as well.     Other Asynchronous Communication Tools  Many other communication tools exist in OSS, but the following are some of the most prevalent:    Collaborative Instant Messaging Platforms  In recent times, collaborative instant messaging platforms like Discord , Matrix , Mattermost , Slack , and others have become very heavily leveraged in OSS communities. Each of these platforms has their own flavor, and the choice of which of these to use is largely driven by the OSS community. Discord was originally favored by gamers. Matrix is decentralized, open source, offers end-to-end encryption, and is the primary choice for some larger projects like Firefox . Mattermost is also open source and is most proud of being dedicated to security, so the Mattermost website highlights users like the US Department of Defense. Slack was developed for for professional and organizational communications, and is also very heavily utilized by many OSS projects. Some commonalities across all of these collaborative instant messaging platforms is that communication is carried out in channels which individual users are placed in or choose to join. In addition to human users, various services and bots (programs providing automation) are present in many channels. Nicknames or handles are used, although in some OSS communities, the handles must adhere to the rules of the project (e.g. being identical to your handle on the project's SECP).    Wikis  Although wikis can be created within many of the SECPs, the concept of a wiki is widely used and understood outside of SECPs as well, largely due to the wide popularity of Wikipedia and WikiMedia . Simply stated, a wiki is a website where the pages are a user-editable, easy-to-use, asynchronous way of putting semi-permanent content on the web, so they are useful for documentation, timelines, status reports, meeting minutes, and conversation logs. A wiki provides easy version control, a database backend, simplified markup, and a fast edit-and-post cycle. Having said this, the use of wikis for OSS projects have fallen largely out of favor in place of having markdown files in the code repository since markdown allows using the same tools such as merge requests, which has the additional benefit that changes to the documentation can be part of the merge request that introduces the relevant change.        IRC  IRC stands for Internet Relay Chat. IRC is one of the older means of synchronous communication between people working on a OSS project, and although in the past it was one of the primary OSS communication tools, many projects have abandoned IRC for collaborative instant messaging platforms and other newer communication tools. It's a text-based federated chat system where clients connect to the servers of one or more networks, and the servers relay messages between themselves within each network (hence the name). Communication is done in channels which individual users join, and users are identified by nicks (nicknames). In addition to human users, like collaborative instant messaging platforms, various services and bots are present in many channels. However, it is very lightweight because the focus is solely on the textual content, which means it can work right from your command line. However, there is no formatting, not even new lines, no emojis, no voice or video chat, and unlike most more modern chat technologies where recordings can be automated, messages aren't easily stored, so it is designed to work only for synchronous communication.     Blogs  A blog is in some ways similar to a website in appearance. Websites provide semi-permanent places for content which is updated and replaced as needed. While in a blog, new articles that are published add to the content rather than replacing it (although existing posts can be updated as well if things change). Blogs provide a flow of transient, in-the-moment news, commentary, and technical articles which is posted by date, with past posts still available. Because many open source participants write blogs, it is sometimes difficult to keep up with them on a larger project. The volume of blog postings created within a community can be overwhelming. To help deal with this, RSS feeds enable the receipt of content in a machine-readable format so that it can be used in a variety of different ways through a service called a RSS feed aggregator. A few open-source community also maintain a Planet site which aggregates the feeds from that community into a single page (and the Planet, in turn, provides an aggregated feed). Here are some examples: The Mozilla Planet , The Fedora Planet , and The Document Foundation Planet .  As you get into OSS, you may want to share your news and opinions with others via a blog. Remember to represent your thoughts professionally, bearing in mind that the Internet is semi-permanent. If you don't want a potential future employer to see what you write, don't post it because the Internet Archive and\/or other crawlers may capture it forever.      Mailing Lists and Forums  You likely know that an electronic mailing list is a collection of names and email addresses used to send material to multiple recipients typically given a single email address for the list. Open source communities that use email lists tend to use discussion lists (which allow for replies) rather than announcement lists (which are one way) to engage their communities. An example of an open source project that leverages email lists heavily for discussions is Debian . Note that all emails sent to the Debian lists are distributed both to the list subscribers as well as copied to the public archive, so people to browse or search without the need to be subscribed.  People on an email list typically use their real name. Surprisingly, there is a significant variation from community to community in terms of list etiquette and even the amount of participation on lists.  An open-source participant subscribed to several lists in multiple communities can easily receive thousands of messages a day. For this reason, many people choose to use a separate mailbox or use filtering rules to keep their mail under control or sign up to receive only a regular \"digest\" of the messages.  Email lists are sometimes managed through online list service providers such as Google Groups, but are often managed through private installations of list management software such as the open source GNU Mailman , which provide subscriber management, bounce control, and web-accessible archiving.  Web-based forums have some similarities to email lists because users can subscribe to receive updates via email. However, conversations in forums are typically grouped by discussion topic and are often better-organized than email archives, which makes them easier to browse and search. People on a forum typically have handles or nicknames, rarely using their full real name, unlike in email. Many OSS communities have one or more forums specific to various aspects of the project. There are also forums that span multiple OSS communities. For example, It's FOSS Community is an example of an active forum on FOSS.  Other OSS communities use related communication technologies such as newsgroups and listservs which serve some of the same purposes as mailing lists and forums and often offer e-mail notifications as well.    Exercise: Joining the Discussion Subscribe to at least one communication venue from each of the three open source communities you are observing, and read through the last few months of messages or message archives for each list. Blog your observations of their communication.    Synchronous Communications  Although pretty much all OSS communities use asynchronous communication, there are some OSS communities that also leverage synchronous communication. Sometimes these sessions are for just a small set of core developers, but other times these are open to all. For example, both the open source textbook platform Runestone Academy and the open source authoring language PreText offer video drop in \"office hours\" open to users and contributors alike. However, as mentioned above, these are not going to be convenient from all regions of the globe, so both of these communities also utilize asynchronous communication methods. Runestone Academy uses Discord, while Pretext uses Google Groups for several very active mailing lists.    Drawing Conclusions  We learn to read before we learn to write; in the same way, the best way to start working with an open source community is to observe that community in action. As you have completed the exercises in this chapter, you should have started to form an impression about the communities that you have been observing.   Exercise: Share Your Thoughts Write a blog post summarizing your thoughts about the communities you've been observing. Specifically note your conclusions about the qualities of the community identified earlier.  "
},
{
  "id": "p-137",
  "level": "2",
  "url": "sec_community_communication.html#p-137",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "host "
},
{
  "id": "p-139",
  "level": "2",
  "url": "sec_community_communication.html#p-139",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Software Engineering Collaboration Platform (SECP) repository repo Issue trackers label merge request pull request (PR) project board "
},
{
  "id": "p-159",
  "level": "2",
  "url": "sec_community_communication.html#p-159",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "collaborative instant messaging platforms bots "
},
{
  "id": "p-160",
  "level": "2",
  "url": "sec_community_communication.html#p-160",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "wikis "
},
{
  "id": "p-163",
  "level": "2",
  "url": "sec_community_communication.html#p-163",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "blog "
},
{
  "id": "exercise-10",
  "level": "2",
  "url": "sec_community_communication.html#exercise-10",
  "type": "Checkpoint",
  "number": "2.4.1",
  "title": "Exercise: Joining the Discussion.",
  "body": "Exercise: Joining the Discussion Subscribe to at least one communication venue from each of the three open source communities you are observing, and read through the last few months of messages or message archives for each list. Blog your observations of their communication. "
},
{
  "id": "exercise-11",
  "level": "2",
  "url": "sec_community_communication.html#exercise-11",
  "type": "Checkpoint",
  "number": "2.4.2",
  "title": "Exercise: Share Your Thoughts.",
  "body": "Exercise: Share Your Thoughts Write a blog post summarizing your thoughts about the communities you've been observing. Specifically note your conclusions about the qualities of the community identified earlier. "
},
{
  "id": "sec_licensing_about",
  "level": "1",
  "url": "sec_licensing_about.html",
  "type": "Section",
  "number": "3.1",
  "title": "About Licensing",
  "body": " About Licensing   The primary purpose of licensing is to set rules by which a creative work like software can (or cannot) be used by others.  When you author a creative work, such as code, you automatically hold exclusive copyright to the work by default. Unless you include a license that specifies otherwise, nobody else is permitted to copy, distribute, or modify your work without without opening themselves up to legal action by you. Once the work has other contributors (who then each become a copyright holder), “nobody” includes you.  If that is not a legal mess you want to get into, your code should include specific terms and conditions for what different people are allowed to do with it, in the form of a license.    Important IP Terminology  Here we give a few definitions that are important for the remainder of the chapter. These are intended not as legal definitions but to help in understanding the common usage of these terms.  For the first term, Intellectual Property , you can think \"property\" (like software) that is \"intellectual\" in nature, but it refers to more than just the property itself.  intellectual property    Intellectual property or IP refers both to the \"property\" that is created by efforts of the mind and to the legal rights related to this property.     For the term, copyright , you can think restrictions on things like the \"right\" to \"copy\". The following definition comes from the Copyright Office of the US government . You will note that copyright refers to much more than solely the right to copy or not to copy.    copyright   A copyright is a type of intellectual property that protects original works of authorship as soon as an author fixes the work in a tangible form of expression.   This means that as soon as someone authors a creative piece of work, in code or other tangible form, they hold a copyright to that work.  A copyright offers the copyright owner exclusive rights like:  Private use  Commercial use  Distribution  Modification  Copyright also provides the owner of copyright the exclusive right to authorize others to utilize some or all of these rights, subject to certain stated conditions and limitations.  The next term, copyleft is one that you may not have heard before because it has emerged from the open source movement. It is also a very clear word play on the word copyright and suggests having \"left\" some of the author's \"rights.\" And, that is indeed what it is, but don't assume that all rights have been abandoned by the author, far from it!  The Copyleft Foundation states the following as the essential innovation of copyleft in section 2.2:  copyleft    Copyleft uses the copyright holders’ controls on permission to modify the work to add a conditional requirement. Namely, downstream users may only have permission to modify the work if they pass along the same permissions on the modified version that came originally to them.      Some Country-specific IP Terms    Some countries have a notion of fair use or fair dealing which are somewhat difficult to understand but even so are critically important because in many countries limited, specific uses can be made without permission from the copyright owner.   fair dealing  In many of the common law jurisdictions of the Commonwealth of Nations, fair dealing allows for copying of copyrighted materials if and only if they are used for a purpose that is among a list of purposes that is specific to each country.     For example, in a large number of the countries that permit fair-dealing uses, copying of copyrighted material for the purpose of review and criticism or for the purpose of reporting the news are both considered \"fair dealing.\"     fair use  In the United States (US) and a few other countries a notion called fair use allows copying of copyrighted material if done for a \"limited\" and also “transformative” purpose. For example, in the US, fair use is often used by various types of critics to quote a limited portion of a work and by professors to make a limited portion of a work available to their students.     What do \"limited\" and “transformative” purpose mean? Well, many millions of US dollars have been spent arguing just that question. If you really want to just see how confusing the notion of fair use is in the US, see Google v. Oracle which ultimately ended up in the US Supreme Court battling exactly that question.  Because the notions of fair use and fair dealing vary significantly by country, researching the laws in your specific country is highly advisable.     Disclaimer  These explanations and definitions are not intended to be used in any legal way and are offered without warranty of any type, either expressed or implied. In no event shall the author or other contributors be held liable for any claim, damages, or other liability arising from or in connection with these definitions or explanations.   "
},
{
  "id": "p-182",
  "level": "2",
  "url": "sec_licensing_about.html#p-182",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Intellectual Property Intellectual property IP "
},
{
  "id": "p-184",
  "level": "2",
  "url": "sec_licensing_about.html#p-184",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "copyright "
},
{
  "id": "p-185",
  "level": "2",
  "url": "sec_licensing_about.html#p-185",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "copyright "
},
{
  "id": "p-188",
  "level": "2",
  "url": "sec_licensing_about.html#p-188",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "copyleft "
},
{
  "id": "p-189",
  "level": "2",
  "url": "sec_licensing_about.html#p-189",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Copyleft "
},
{
  "id": "p-192",
  "level": "2",
  "url": "sec_licensing_about.html#p-192",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "fair use fair dealing fair dealing "
},
{
  "id": "p-195",
  "level": "2",
  "url": "sec_licensing_about.html#p-195",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "fair use "
},
{
  "id": "sec_licensing_typical",
  "level": "1",
  "url": "sec_licensing_typical.html",
  "type": "Section",
  "number": "3.2",
  "title": "Typical Open Source Licenses",
  "body": " Typical Open Source Licenses       MIT License  The MIT license is a short and simple permissive license with conditions only requiring preservation of copyright and license notices. Licensed works, modifications, and larger works may be distributed under different terms and without source code.  The following table summarizes this license:  MIT License Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Private use    ⚠ License and  copyright notice    ✗ Liability  ✗ Warranty       The entire text of the MIT license is quite understandable and brief. Note how short and sweet it is: MIT License . Copyright (c) [year] [fullname] Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and\/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.   Examples of open source projects using this license:   Babel    .NET    Rails       Apache License 2.0  The Apache License 2.0 is a permissive license whose main conditions require preservation of copyright and license notices. Contributors provide an express grant of patent rights. Licensed works, modifications, and larger works may be distributed under different terms and without source code.  The following table summarizes this license:  Apache 2.0 License Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Patent use  ✓ Private use    ⚠ License and  copyright notice  ⚠ State changes    ✗ Liability  ✗ Trademark use  ✗ Warranty       The entire text of the Apache License 2.0 is much longer than that of the MIT license. If interested in the details, see Apache License 2.0 .  Examples of open source projects using this license:   Kubernetes    pdf.js    Swift       GNU General Public License v3.0  The GNU General Public License v3.0 is considered a strong copyleft license whose permissions are conditioned on making available complete source code of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved. Contributors provide an express grant of patent rights.  The following table summarizes these conditions:  GNU General Public License v3.0 License Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Patent use  ✓ Private use    ⚠ License and  copyright notice  ⚠ State changes    ✗ Liability  ✗ Warranty       The text of the GNU General Public License v3.0 license is even longer than the full text of Apache License 2.0 is available from .  Examples of open source projects using this license:   Ansible    Bash    Gimp       Section Summary  There are many other licenses all with differing rules in the open source community. For a useful treatment of some more of other open source licenses, see Choose a License by GitHub.   "
},
{
  "id": "table-MIT-summary",
  "level": "2",
  "url": "sec_licensing_typical.html#table-MIT-summary",
  "type": "Table",
  "number": "3.2.1",
  "title": "MIT License Permissions, Conditions, and Limitations",
  "body": " MIT License Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Private use    ⚠ License and  copyright notice    ✗ Liability  ✗ Warranty     "
},
{
  "id": "table-Apachev2-summary",
  "level": "2",
  "url": "sec_licensing_typical.html#table-Apachev2-summary",
  "type": "Table",
  "number": "3.2.2",
  "title": "Apache 2.0 License Permissions, Conditions, and Limitations",
  "body": " Apache 2.0 License Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Patent use  ✓ Private use    ⚠ License and  copyright notice  ⚠ State changes    ✗ Liability  ✗ Trademark use  ✗ Warranty     "
},
{
  "id": "table-GPLv3-summary",
  "level": "2",
  "url": "sec_licensing_typical.html#table-GPLv3-summary",
  "type": "Table",
  "number": "3.2.3",
  "title": "GNU General Public License v3.0 License Permissions, Conditions, and Limitations",
  "body": " GNU General Public License v3.0 License Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Patent use  ✓ Private use    ⚠ License and  copyright notice  ⚠ State changes    ✗ Liability  ✗ Warranty     "
},
{
  "id": "sec_licensing_existing_communities",
  "level": "1",
  "url": "sec_licensing_existing_communities.html",
  "type": "Section",
  "number": "3.3",
  "title": "Existing OSS Communities",
  "body": " Existing OSS Communities   Contributing to Existing Projects  If you’re contributing to or extending an existing project, it almost always makes the most sense to continue using that project’s license. Depending on the original project’s license, using the same license might be a requirement, not just the easiest thing to do. (See the “same license” condition of some licenses.) To find a project's license, look for a file called LICENSE or COPYING, and skim the project’s README. If you can’t find a license, ask the maintainers.  Some open source communities have strong preferences for particular licenses. If you want to participate in one of these communities, it will be easier to use their preferred license, even if you’re starting a brand new project with no existing dependencies. Some examples of such communities include:   Apache requires Apache License 2.0    Cloud Native Computing Foundation requires Apache License 2.0 .   Firefox has an entire guide for helping you choose the right license. For code, they recommend their own license, the Mozilla Public License MPL 2.0 or Apache License 2.0 and the guide offers guidance on choosing which.   GNU recommends GNU GPLv3 for most programs   npm packages overwhelmingly use the MIT or the very similar ISC licenses   OpenBSD prefers the ISC License    Rust crates are overwhelmingly licensed under both MIT and Apache License 2.0    WordPress plugins and themes must be GNU GPLv2 (or later)    Communities come in all shapes and sizes, and more than one community might be pertinent. For example,you must keep in mind the rules of your company if you work for one. The examples above are very well established. If the community you’re building a project for doesn’t have set-in-stone licensing traditions, or you don’t see your project as part of any particular community, that’s fine. Then you will need to make your own choice of a license because not posting any license at all means you implicitly retain all rights and give no permissions to use, share, modify, or improve the software.    Changing Licenses  As an open source software project matures, sometimes the maintainers of the project decide to change open source licenses. This section highlights a case study of one project's change of license and their reasons for that change.  Some people who are new to working in open source software communities may naively think that the best licenses are those that are the most permissive. Unfortunately, there are pitfalls to tho most permissive licenses when anyone can utilize the software for any purpose.   Plausible Analytics is an open source software web analytics project that provides an alternative to Google Analytics, which is more privacy-friendly. Plausible decided to change licenses from the very permissive MIT License to the AGPL license , a GNU copyleft license designed to protect rights when the software is being utilized over a network. Simply stated, the AGPLv3 is basically the GPLv3, but with an additional licensing term that requires that users who interact over a network with modified versions of the program can receive the source code for that program.  In their blog, Plausible explained that they made the change their license to protect against corporations that took their code and then used it to create and sell proprietary software that directly competed with their project. They had also been approached by some large corporations that wanted Plausible to help them so they could sell a version of Plausible Analytics to their own clients without wanting to contribute anything back to the Plausible project. For more details, see Open source licensing and why we're changing Plausible to the AGPL license .  The kind of situation Plausible found themselves in underscores the importance of licensing, and also the importance of the terms of that license.   "
},
{
  "id": "sec_licensing_none",
  "level": "1",
  "url": "sec_licensing_none.html",
  "type": "Section",
  "number": "3.4",
  "title": "No License",
  "body": " No License   In the Absence of a License  Even in the absence of a license file, you may grant some rights in cases where you publish your source code to a site that requires accepting terms of service. For example, if you publish your source code in a public repository on GitHub, you have accepted the Terms of Service , by which you allow others to view and fork your repository. Others may not need your permission if limitations and exceptions to copyright apply to their particular situation. Neither site terms nor jurisdiction-specific copyright limitations are sufficient for the kinds of collaboration that people usually seek on a public code host, such as experimentation, modification, and sharing as fostered by an open source license.  You don’t have to do anything to not offer a license. You may, however, wish to add a copyright notice and statement that you are not offering any license in a prominent place (e.g., your project’s README) so that users don’t assume you made an oversight. If you’re going to accept others’ contributions to your non-licensed project, you may wish to explore adding a contributor agreement to your project with your lawyer so that you maintain copyright permission from contributors, even though you’re not granting the same.  Disallowing use of your code might not be what you intend by posting “no license.” An open source license allows reuse of your code while you retain the copyright. If your goal is to completely opt-out of copyright restrictions, consider a public domain dedication instead using something like the Unlicense . (Note that not all countries recognize public domain, so public domain licensing tries to address this issue.)   The Unlicense    A license with no conditions whatsoever which dedicates works to the public domain. Unlicensed works, modifications, and larger works may be distributed under different terms and without source code.  The following table summarizes this the Unlicense:  The Unlicense Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Private use    ⚠ (None)    ✗ Liability  ✗ Warranty       The entire text of the Unlicense can be found at the Unlicense .  Examples of open source projects using the Unlicense:   kakoune    (Ruby) RDF.rb    react-use        For potential users  If you find software that doesn’t seem to have a license, that generally means you have been granted no permission from the creators of the software at all. Although a code host such as GitHub may allow you to view and even make a copy of the code, this does not imply that you are permitted to use, modify, or share the software for any purpose.  To be clear, if software has no license at all, that means you have been granted no permission from the creators of the software to use, modify, or share the software, so you had best not do so.  If you find software without a posted license, your options are:    Ask the maintainers nicely to add a license Unless the software includes strong indications to the contrary, lack of a license is probably an oversight. If the software is hosted on a site like GitHub, open an issue requesting a license. If you’re bold and it’s fairly obvious what license is most appropriate, open a pull request to add a license.   Don’t use the software Find or create an alternative that is under an open source license.   Negotiate a private license Be sure to bring your lawyer.    "
},
{
  "id": "table-unlicense-summary",
  "level": "2",
  "url": "sec_licensing_none.html#table-unlicense-summary",
  "type": "Table",
  "number": "3.4.1",
  "title": "The Unlicense Permissions, Conditions, and Limitations",
  "body": " The Unlicense Permissions, Conditions, and Limitations       Permissions               Conditions                Limitations                  ✓ Commercial use  ✓ Distribution  ✓ Modification  ✓ Private use    ⚠ (None)    ✗ Liability  ✗ Warranty     "
},
{
  "id": "sec_dev_shell_terms",
  "level": "1",
  "url": "sec_dev_shell_terms.html",
  "type": "Section",
  "number": "4.1",
  "title": "Using the Command Line",
  "body": " Using the Command Line   In this section, we explain some terminology related to the command line, why developers use it, and then get set up to use it ourselves. If you have worked with the command line previously, then this entire section may serve as a review. Otherwise, this section is written with you in mind.    Terminals and Related Terms     What is a terminal ?  The English word terminal means to be situated at the end of something, and the term's meaning in computing has evolved since it was originally coined in the 1960s.  Prior to the development of the first programmable electronic computers, computers were people (mostly women) who used mechanical calculators to compute complex mathematical computations quickly and accurately. The earliest electronic computers, such as Colossus and ENIAC, required specialized technical knowledge and skill to program because programming these machines was a complex process that involved physically entering commands flipping switches, pushing buttons, and manually moving patch cords. The development of the terminal interface in the 1960s marked a significant shift in the way users interacted with computers because the terminal provided a convenient and much more accessible way to provide input and obtain output, allowing users to remotely interact with a computer via a keyboard and screen. Back when the terminal was first used in computing, what we refer to as the terminal today was the only interface available to the user, while now it is used to refer to a specific type of text-based programming interface. In particular, today a terminal simply refers to a text-based interface that allows a user to interact with a computer by entering commands and receiving output on a display screen.    What is a console ?  The English word console comes from the related verb, to console , which means to provide support. In computing, the original meaning of the console was as a physical device that supported input into and output from a computer. The term is still used that way, but it has also come to be synonymous with terminal in some environments. For example, if you search for console on a Windows machine, you may find the terminal program and\/or you may find a security console program.    What is a Command Line Interface (CLI) ?  A CLI refers to any interface that works with text-based commands and text-based output. We will be using a shell , which is an example of a CLI.    What is a shell ?  A shell is a program which parses and interprets the commands you enter in the terminal and then executes them, often using functionality provided directly by the operating system. In other words, a shell is a CLI which serves as the interface between the end-user and the operating system. It is called a shell because it is a user interface layer directly surrounding the kernel , which is the innermost part of the operating system   A terminal\/console will typically seamlessly offer direct access to a shell as well as other CLI programs, so although these terms are distinct from one another as described above, you will often hear people use the terms terminal, CLI, console, and shell almost interchangeably. Don't let it worry you too much because you should almost always be able to understand what is meant from the context.    Why not a GUI?  Given that Graphical User Interfaces (GUIs) came into widespread use decades ago, it may seem surprising that nearly all software developers utilize a non-graphical shell. The primary reasons for this include:   Speed of Use  The speed one can type a command is typically many times faster than the speed at which one can select a command from a menu.    Expressiveness  The shell facilitates features that are unavailable or difficult to access in a GUI. The mouse only allows for picking among the small set of predetermined options from the screen. However, for most systems many more options are actually available.   Automation  If you need to do something that is repetitive or requires combining multiple commands, the shell facilitates this too since shells can be programmed using a scripting language, allowing repetitive and\/or complex tasks to be automated via a script.       Accessing a Terminal Window on your Machine  Regardless of whether you are using macOS, Linux, or Windows, you are able to set up a development environment, open a terminal, and access a shell. Some good news is that all of these OSs offer shells that are largely compatible. This is useful for a variety of reasons,including being able to find find a useful answer when searching on how to accomplish various tasks on the Internet.  On a Mac  If you are on a Mac, you have a couple of good options. With any Mac, the built-in Terminal program allows you to access a shell. If you are looking for a more customizable and feature-rich terminal program, then you might want to consider iTerm2 . Opening the Terminal on a Mac works like opening any other program: you can find it in the Applications folder, you can search for it, you can use the Launchpad, or you can use it's shortcut which is command(⌘)+T.   On a Linux machine  On a machine running Linux, the terminal is often also called the Terminal , although depending upon the Linux environment, the name may differ. Konsole may also be used. Regardless of what it is called, you can typically access the terminal in several ways: search for the keyword Terminal, right-click on your desktop and then select \"Open Terminal\", or use the shortcut Ctrl+Alt+T.   On a Windows machine  If you are on a Windows machine, you have a number of options. On Windows, the terminal\/shell is historically called the command prompt (cmd) , although a newer very different terminal\/shell called PowerShell has also been around for decades. Neither of these terminal\/shells are compatible with the default shell programs available on macOS and Linux. For OSS development, it will be preferable to have access to a shell that is compatible with the macOS and Linux ones.  If you are running Windows 10 or Windows 11, then following the directions from Microsoft on Installing Linux on Windows with WSL2 will give you the best experience. Note that you may first need to update your version of Windows, see . WSL2 provides a full Linux kernel that is integrated into the Windows operating system. Installing the Windows Terminal will further enhance your experience, although it is not strictly necessary. Once you have followed the linked directions to install WSL2, including the installation of Linux (Ubuntu is a good choice), then the shell is most easily accessed by searching for Ubuntu in the search tool next to the Windows Icon and selecting it when you see it. For convenience, consider right-clicking on the Ubuntu icon and pinning it to your Start menu or to your Taskbar.  If you are running an earlier version of Windows, or an outdated version of Windows 10 that you cannot update, then you have several choices. For simpler development environments, using MinGW provides a lightweight solution, so you might try this first. For a more complicated development environment such as one that utilizes virtualization, using a Virtual Machine (VM) environment such as Virtual Box and installing and running Ubuntu inside the VM is advisable. For a cloud option, see below.   Another OS  Although Linux, Mac, and Windows (to a lesser extent) are by far the most typical OSs, developing in another OS environment might also be possible. For example, searching the Internet on \"software development in ChromeOS\" will provide several useful links for how to set up a development environment in ChromeOS. Just be aware that developing in an OS environment other than Linux, Mac, or a modern version of Windows is likely to offer little in the way of support, so you might be better off using a cloud-based development environment or a virtual machine (VM) environment.   Installing Linux in a Virtual Machine (VM) Environment  If you have sufficient RAM and secondary storage available, then you might consider installing Linux in a VM. This may be a particularly good choice if you are on an older Windows machine and want to develop off-line. such as Virtual Box and installing and running Ubuntu in the VM.    In the Cloud  To contribute to most open source projects, you will need to set-up a build environment for local testing. While it is typical to have a local development environment to work in, there has recently been an influx of cloud providers which offer solutions for cloud-based development environments. These have the benefit that they require less setup than a local development environment, but are often only free within constraints and otherwise incur a monthly fee, which might be waived for a trial period or for students.   Cloud Development Environments (CDEs) are full development environments in the cloud. The best known and most feature-rich is GitHub Codespaces. A couple of the other popular cloud development environments include AWS Cloud9 and Gitpod. All of these environments try to help you set up your development environment with ease, and you can mostly likely find a way to at least try them for free.  For the purposes of this chapter, if you cannot quickly set up your local environment or cloud environment, you can practice using a shell at Fabrice Bellard's JSLinux which provides a very small cloud-based virtual machine environment. (Choosing the riscv64 Linux console will work for all of these exercises.) Note that this a free service which has a capped bandwidth of 40 kB\/s. You are asked to please be respectful and don't abuse the service.       Your Shell  Many shells are available for Linux, but the most popular is the Bourne-again shell ( bash ) shell, the next section is focused on bash. If you are using another shell like zsh , which is now the default on macOS and many people's preference over bash, then don't worry. The different shells available on Linux and macOS are largely compatible with each other and you will almost certainly not run into any issues by using zsh.    If you have reached the end of this section, you should be able to open a terminal window to access a shell. In the next section, you will get some practice with some basic shell commands.   "
},
{
  "id": "p-237",
  "level": "2",
  "url": "sec_dev_shell_terms.html#p-237",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "terminal terminal terminal interface terminal console console console Command Line Interface (CLI) CLI shell shell shell kernel "
},
{
  "id": "p-247",
  "level": "2",
  "url": "sec_dev_shell_terms.html#p-247",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "command prompt (cmd) PowerShell Cloud Development Environments (CDEs) "
},
{
  "id": "p-258",
  "level": "2",
  "url": "sec_dev_shell_terms.html#p-258",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "bash zsh "
},
{
  "id": "sec_dev_basic_shell_commands",
  "level": "1",
  "url": "sec_dev_basic_shell_commands.html",
  "type": "Section",
  "number": "4.2",
  "title": "Basic Shell Commands",
  "body": " Basic Shell Commands   In this section, we explore basic shell commands related to files, directories, and navigation.  Disclaimer: It is beyond the scope of this book to cover anything but a small number of shell commands needed for contributions to open source, so the subsections below cover only the essentials.    Files, Directories, and Privileges  This and subsequent subsections are written to be followed as an extended exercise with explanations given as we go.  Exercise: Try shell commands for navigation Try each of the following commands on your own machine.  First, follow the directions given in to open a terminal window so you can use your shell. All of the shell commands will be typed in this terminal window.   Introduction to Shell Commands    Shell commands are simply commands that are typed into the shell. As our very first shell command to try, let's try the echo command which simply echos or displays the argument(s) to the terminal. Try the following with or without the quotes:  echo \"I love open source!\"  You should have seen the text \"I love open source!\" printed in the terminal. Now if that were all the echo command could do, it would be a fairly pointless command. The echo command's real power is in displaying the contents of variables and files as we will soon see.  The shell is designed to work in an OS which is a multi-user environment. Type in the following command to see your username:  whoami  The shell should respond with the username that you created when you set up your system. For me that is pearcej .  Note that your environment might be case sensitive , which means that it might discriminate between uppercase and lowercase letters, where two words that in letter cases only, are not considered equal. This means that Echo , ECHO , WhoAmI , and WHOAMI might not be recognized as commands, so you are in a case sensitive environment and accidentally type one of these, you will elicit a response like:  Command 'WhoAmI' not found  or if you are in a case sensitive environment and you are lucky, you might get something more helpful like:  Command 'Echo' not found, did you mean: command 'echo'  Sometimes it is helpful to be able to remember some information or look up previously stored information. This can be accomplished using environment variables. An environment variable is a value that contains information about the system environment or the currently logged-in user. Having environment variables is a way of keeping track of information about the system environment and serves as a way to pass information about the environment to programs. For example, the operating system sets a bunch of environment variables which store information about the environment. As just one example, you might wonder how the operating system keeps track of its users. For each user, there is a user environment variable called USER that is specific only to the currently logged-in user. The shell will expand environment variables and that `echo` is useful to show us the results of that, so the USER environment variable can be accessed using the echo command that we already saw. Try the following:  echo $USER  You should see the same result as you saw with the whoami command! Note that you must precede the variable name with a dollar sign $ whenever you reference the value it contains. Isn't it interesting to peek inside the environment variable in that way?  In fact, one of the key uses of the echo command is to echo the values of variables, which the shell can expand. Let's see another example:  echo $SHELL  You will likely see something like the following printed:  \/bin\/bash  The reason you see something like this is because the SHELL environment variable stores the location of the shell program. This location, called the file path , is given in the form of the path needed to find the location. We explore how this path is described in the next section.    Files and File Systems    Before computers became popular, a file and a folder referred to a container for a collection of documents. Operating systems use these terms very similarly. A file refers to a document and a folder or, synonymously, a directory refers to a collection of files and sub-directories. The operating system handles how files and directories are represented on a physical storage medium, how they are read from, and written to. You may be most familiar with accessing files through a graphical user interface. Creating a new document corresponds to creating a new file. Often, when opening an application that deals with documents, it will suggest documents you have recently worked with. These each correspond to a file, each of which is stored in a directory somewhere, and knowing where files are in your file directory will be important to working on open source.  You might (or might not) be familiar with using folders to organize our files and to navigate the file system. (On an iphone or Android phone, you make a new folder by dropping one app on top of another app, on a Mac you long press and then choose new folder, and on a Windows machine, you right-click and choose New > folder.) This type of organization is important to understand, and the folder metaphor is useful. In fact, there are two useful metaphors to help with our understanding of file systems.  When using the shell, \"folders\" are more typically called \"directories\", but the two terms are equivalent.  Inside of a directory, we can find files and possibly additional directories. Since directories may contain other directories in addition to files, the directories on your computer form a hierarchy. Each directory is contained within another directory, which we refer to as its parent . The only exception to this rule is the root directory , which can be a parent to other directories, but has no parent itself. It is therefore the top-level directory from which we can reach any other directory. Each file and directory in the file system can be referred to by its unique path . The root directory always has the path \/ , and a file can thus be identified by its path through the file system beginning from the root node. If there is a folder named myfolder located in the root directory, its path would be \/myfolder . If myfolder then contains a file named hello.txt , its path would be \/myfolder\/hello.txt . If \/myfolder contains a directory named \/mydocuments , its path would be \/myfolder\/mydocuments . And so on.\"   root directory symbol    Note that the term root directory shouldn't be confused with the term root user in a Linux-like system. The root user is a user named root , which is a special superuser account in Linux operating systems that has unrestricted read and write privileges to everything. The root directory should also not be confused with the \/root folder which is found on some Linux-based systems and which is the home directory of the root superuser.  Let's get our bearings and see which directory we are currently in. The pwd command stands for print working directory and as the name says it prints the path of the directory you are working in. Try typing:  pwd  When I type this, I see the following (but you will likely see a different path):  \/home\/pearcej  Reading the path from right to left, using the folder metaphor, this means I am in a directory named pearcej which itself is a inside of a directory called home which is itself inside of the root directory, \/ . Note that the position with respect to the forward slash \/ tells us the direction of the relationship – further to the right is further inside. To use the tree terminology, a directory that has a file or second directory directly inside of it is called a parent of the file or second directory that is inside, while the file or second directory is called the child of the parent directory. Hence, pearcej is a child of home and home is a child of the root directory \/ in our example.  Let's try \"moving\" (i.e. changing our working directory) to the root directory. Use the cd command which stands for change directory followed by the \/ :  cd \/  This should transport you to the root directory (if you weren't there already.) Now when you use pwd , you should see \/ echoed back.  Next type the following ls to get a listing of the files and subdirectories in the current working directory .  ls  You should see a listing of files and directories.    Shell Command Options    Many shell commands have options which can be invoked by using a command option , which is also called a flag . Let's try using a command option with ls , the listing command. Try typing the following where the -r option stands for reverse , and it reverses the sorting order:  ls -r  To try another, try typing the following where the -l option stands for long listing format , meaning that instead of output containing only the names of files and directories, the ls command will produce additional information, assuming you have at least one file or directory.  ls -l  You are likely to see some lines that look something like this, each of which corresponds to one file or subdirectory in your current working directory. The exact output you get will vary based on the directory you are in and what files and folders exist on your machine:  drwxr-xr-x 3 root root 4096 Jun 19 10:55 home lrwxrwxrwx 1 root root 7 Mar 24 2022 bin -> usr\/bin -rw-rw-r-- 1 pearcej friends 22 Sep 15 2022 hello.txt  Thus, the -l flag changed how the listing is displayed.    File Permissions    Let's return to the example from the previous section by exploring what we get in a long listing. In particular, let's explore the permissions portions of the lines produced by the ls -l command.  cd ~ ls -l  You should get something that looks similar to the following, of course your files and directories are likely to differ.  drwxr-xr-x 3 pearcej pearcej 4096 Jun 19 10:55 home lrwxrwxrwx 1 root pearcej 7 Mar 24 2022 bin -> usr\/bin -rw-rw-r-- 1 pearcej friends 22 Apr 15 2023 hello.txt  The last item on each of these lines is the filename itself. The first item in each of the lines is a 10 character-long mix of letters and minus signs. The first character of that set indicates the file type where d tells us it is a directory, l indicates it is a symbolic link, and - indicates it is a regular file. (Note that a symbolic link , aka symlink or soft link is a special type of file that acts as a shortcut by pointing to some other file or directory.) The next nine characters display various permissions for the file. The first set of three characters (characters 2-4) are the user's (i.e. the file owner's) permissions, the next three are the group's permissions, and the last three are the permissions for all others. (The user's name is in the third column and the group name is in the fourth column.) In each of these sets of three characters, the three characters refer to read ( r ), write ( w ), and execute ( x ) respectively. If you see a letter then that permission is allowed, and if you see a '-', the permission is disallowed. For example in the last of the three lines shown above, we see that the file hello.txt has permissions of -rw-rw-r-- . This means this is a file that can be read and written (changed) but not executed by the owner pearcej and also by any user who is a member of the friends group, however other users can only read the file.  Occasionally, you need to change permissions of a file. For example, you might need to change permissions to make a file executable. Changing file permissions is done with the chmod command. We will explore this in a bit.    Learning More About Command Options    If you want to see all of the command options for a given command, there are two different methods for many commands. You can often, but not always, use the --help option on the command or you can use the manual which is accessed using the man command. For example, with the ls command, you can use either one of the following, noting that they work a bit differently because the manual may use paging. If it does, to go to the next page use the space bar.  ls --help man ls  Note that since both --help and man are not consistently both available, it is worth knowing both. That way, if one doesn't work, you can try the other.  You may be wondering about the use of one minus sign '-' vs the use of two minus signs '--' in shell options. One minus sign is typically used for single letter commands, while two is typically used for word-length commands, although even this is not a hard and fast rule. You'll occasionally get programs that also use a single `-` for word-length commands. If you look back at the help and\/or manual results for ls , you may see that the options -a and --all both list all files including that begin with a '.', which are the hidden files and directories. Besides brevity, one advantage the single minus sign often offers, is that to run multiple options at the same time, all you often need to do is concatenate them. Note that this is also program-specific; not all programs will allow this, but it is convenient when it is offered! For example, ls -lra returns the result with the -l , -r , and -a option flags all activated. Give it a try!  ls -lra    Creating and Removing Directories    Next, let's go to your home directory which is referenced by the special tilde '~' character as follows:   home directory symbol    cd ~  Then print your working directory and list your files just to see that you have been transported again.  You can make a new directory using the mkdir command. For example, let's say you want to make a new directory with the name newdir , you can type the following:  mkdir newdir  To check that the directory was created as expected, you can get a fresh listing of your files and directories with ls -l . The output should include a line that ends in `newdir`. Try it!  drwxr-xr-x 2 pearcej pearcej 4096 Nov 15 17:00 newdir  Then you can descend into the new directory and see where you are with:  cd newdir pwd  You should note that your working directory has changed! One might expect not to see anything when running the ls command in an empty directory, but try it with the following options:  ls -la  You are likely to see something like the following:  drwxr-xr-x 2 pearcej pearcej 4096 Nov 16 17:00 . drwxr-xr-x 13 pearcej pearcej 4096 Nov 16 17:00 ..  Note the period at the end of the first line where the filename is expected. A period or dot (.) represents the current directory. The double period or double dot (..) represents the parent directory of the current one.   current directory symbol     parent directory symbol    You can use this dot notation as a reference as well, so ls .. , will list all the files and directories in the parent directory relative to where you are so you don't have to change directories to get the listing from another directory. Try it!  You can even use these dots in combination with folder names. For example, if you are inside of the newdir directory and you want to make a sibling directory called newdir2 , you can type the following:  mkdir ..\/newdir2 ls -l ..  Here, the first command creates a new directory named newdir2 as a child of our current parent directory. This makes newdir2 a sibling of the original newdir directory because both have the same parent directory. The second line produces a long listing of all of the files and directories in the directory that is one level up relative to the current working directory. You should see both of the directories that you made listed as subdirectories.  If you want to delete either of these new empty directories, you can use the remove directory command, rmdir followed by the name of the directory you want to remove. Note that there are other ways to remove directories, but remove directory is useful because it refuses to delete a directory that is not empty. Give it a try!  A handy use of the cd command is to use cd - which will take you to your previous working directory. This is handy if you need to move between two distant locations. Try it followed by pwd a couple of times.  cd - pwd    Input and Output Redirection    There are a number of ways one can create a new file. Let's try some. First, use cd to descend into one of your new directories if you are not already in one so that you are in an empty directory. Then let's try the following commands:  touch newfile1.txt echo 'I love open source!' > newfile2.txt echo 'I really love open source!' >> newfile3.txt ls  You should now see three new files named newfile1.txt , newfile2.txt , and newfile3.txt respectively. This particular usage of the touch command simply makes an empty file if no file by that name already exists in the directory. It is a niche use case for the command, but people use it this way with regularity. The intended purpose of the touch changes the last accessed\/modified date. Understanding the result of the first line we typed is pretty straightforward. The second and third lines that we typed require a bit more explanation. As we learned above, the echo command simply outputs (or echoes) the argument(s) to the terminal, but here the echo command has been used in combination with output redirection into a file.  Output redirection is a feature in the shell that allows the user to redirect the output of a command using > or >> . Recall that the echo command normally prints to the screen. What we did above in creating new files with the echo command was to use output redirection to redirect the output of the command into a file of the specified name. So, the command echo 'I love open source!' > newfile2.txt redirected the output of the echo command into the newfile2.txt file. Both > and >> will create a new file with the provided name if one does not already exist. Note that the > is the output redirection operator used for overwriting a file that might or might not already exist, while the >> is an output operator that appends the output to an existing file or creates a new one if one does not already exist. So, > should be used judiciously!  Let's look at the contents of the files that we created. Let's use cat to see the file contents. Type the following one at a time:  cat newfile1.txt cat newfile2.txt cat newfile3.txt  You might be wondering why we are using a command called cat . The cat command, which stands for concatenate , is used to concatenate standard input (typically the keyboard) or file(s) to the standard output. Like the name suggests, you can also use the cat command to concatenate files. For example, if you try:  cat newfile2.txt newfile3.txt > newfile1.txt cat newfile1.txt  You should see that newfile1.txt instead of being empty, now contains the concatenation of newfile2.txt and newfile3.txt   You can also use the cat command in combination with output redirection to create a multi-line file. Try typing the following lines to create a new multi-line file named newfile_multi.txt :  cat > newfile_multi.txt these are multiple lines  You can complete this command sequence by pressing Control+D on your keyboard which will cause the new file to be closed. You should now have a new file called newfile_multi.txt .  Analogous to output redirection, input redirection in the shell using < or << allows you to redirect the input of a command. So, if we want the response from a command to be written to a file instead of to the terminal, we can use output redirection, but if we want the input to a command to come from a file instead of from the keyboard, we use input redirection.  Let's look at an example of input redirection using the shell command wc , which stands for word count . This a command that as the name suggests can be used for counting. However, it does more than count words! It actually provides the line count, the word count, and the character count in the file(s) specified in the file arguments. By default, it displays all this in four-columnar output with the file name in the final column.  Let's try the following:  wc < newfile2.txt  The shell should reply with 1 4 20 newfile2.txt because newfile2.txt contains 'I love open source!' which is 1 line, 4 words, and 20 characters. If you only want to count the number of words, you could use the -w flag to display only the word count as follows:  wc -w < newfile2.txt   Let's practice with input and output redirection using a temporary file. Let's redirect the output of the ls command into a temporary file, and then use input redirection with wc -w to get the word count of this file. (This is one way to count the number of files in your current directory.) Let's try the following:  ls > temp.txt wc -w < temp.txt  If you are wondering if there is a better way than using a temporary file, there is. A pipe (|) in the shell allows you to redirect (aka to pipe) the output of one command into the input of another command. Let's see an example:  ls | wc -w  Try it! This is an improvement because it is faster and avoids the use of a temporary file.    Scripts    It is possible to use what we have learned thus far to make an executable script. A script is a text file that contains a sequence of commands for the operating system. Shell scripts can be useful to bring together common sets of tasks and to make repetitive tasks faster and easier.  Let's try it! Typing cat >> helloworld.sh will tell the shell to open a new file named helloworld.sh and to expect multiple lines of input from the keyboard. Type the following lines:  cat >> helloworld.sh # This is a comment in a script typically used to explain the purpose echo 'Hello World!'  End the cat >> helloworld.sh command sequence by pressing Ctrl+D on your keyboard. This will cause the file named helloworld.sh to be completed and closed.  You should now have new file named helloworld.sh . However, we would like to make it executable so we can run it as a script. To make it executable, we use the chmod command. The chmod stands for change file mode bits . To add execution, we will need the +x option, which stands for 'add execution' and will change it to being executable. So, run the following in your shell to make it an executable file for all users:  chmod +x helloworld.sh  To execute this script, you need to indicate the directory where to find it, which is the current directory. So, to run it, you can type the following:  .\/helloworld.sh  We can create a more interactive script using the read command which reads text from the keyboard. It is frequently used to make scripts interactive. However, we need a variable to store the result. In the shell, some variables, like environment variables, always exist and you can always access them. However, you can also create your own variables. As we have seen, you can use echo to ask the shell to provide the value of a variable, but you must precede the variable name with the dollar sign ($). Let's see how all this works by trying the following, finishing by pressing Control+D :  cat >> hellouser.sh # Says hello to the user by name. echo 'What is your first name?' # In the next line, USERNAME is dynamically created as a new variable read USERNAME echo \"Hello \" $USERNAME  To run this new script, you will again need to make it executable. Then you can run it.  chmod +x hellouser.sh .\/hellouser.sh    File Management    We can move files around, make copies of files, or remove (delete) files from the filesystem using mv , cp , and rm respectively. Let's see how these work. First, list your files. You should have newfile1.txt , newfile2.txt , and newfile3.txt in your directory from the previous exercise.  Let's make a new directory named subdir below our current directory and move one of our files there.  mkdir subdir mv newfile3.txt subdir\/newfile3.txt ls ls subdir  Note that the command ls subdir provides a listing of the subdirectory named subdir . You should see that newfile3.txt is now not in the current directory, but it is instead in the subdirectory subdir .  In addition to moving files around in the directory structure, we can also use the mv command to rename files as follows:  mv newfile1.txt newfile4.txt ls  One important thing to watch out for with the mv command is that if the destination filename already exists, it might get overwritten. For this reason, you might want to use the -i flag which stands for interactive. Try it.  mv -i newfile1.txt newfile2.txt  You should see a question like, \"overwrite 'newfile2.txt'?\"If you respond with \"n\", then the file will not be overwritten.  The cp command works as you might expect:  cp newfile2.txt newfile2_cp.txt cat newfile2_cp.txt  Just like with the mv command, the cp command will overwrite the destination file if it already exists. For this reason, you might want to use the -i flag which stands for interactive here too. Try it.  cp -i newfile4.txt newfile2_cp.txt  You should see a question like, \"overwrite 'newfile2_cp.txt'?\" If you respond with \"n\", the command will not be overwritten, so using the -i flag seems a wise safeguard.  The rm command is a useful, but another dangerous command. Let's try it:  rm newfile2_cp.txt  Just as with cp , and mv , you are probably wise to use the -i option.  rm -i newfile4.txt  And, if you respond with \"n\", then the removal will not happen.    A few time-saving shell commands    The up arrow key retrieves the previous shell command. If you press it multiple times, it will take you back through multiple commands in your shell history. This is a useful way to repeat a command. For example, if you had a typo, you can use the up arrow, edit the command, and push enter to fix the command. Analogously, the down arrow will move you in the reverse direction through the shell command history. For more useful shell commands, type man bash for hints on how to search your shell history, re-execute commands, and much more.  This paragraph is intended to alert you to some useful search features. A couple examples of very common search patterns are using wildcards for zero or more characters or for a single character. The asterisk (*) specifies zero or more characters to match. In bash the question mark (?) is used for matching exactly one single character.  For example, if we type the following:  rm -i newfile?.txt  Then the question mark will match with any single character, and we will see the following prompts:  rm: remove regular file 'newfile2.txt'? rm: remove regular file 'newfile4.txt'?  If we instead type:  rm -i newfile*.txt  Then the asterisk will match with any number of characters (including zero), and we will see the following prompts:  rm: remove regular file 'newfile2.txt'? rm: remove regular file 'newfile4.txt'? rm: remove regular file 'newfile2_cp.txt'?  As you can see, these search patterns give you a lot of power and control.     Conclusion  Hopefully, you now feel a bit more comfortable using the shell. The shell commands discussed above are summarized in Appendix .   "
},
{
  "id": "exercise-try-cli",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#exercise-try-cli",
  "type": "Checkpoint",
  "number": "4.2.1",
  "title": "Exercise: Try shell commands for navigation.",
  "body": "Exercise: Try shell commands for navigation Try each of the following commands on your own machine. "
},
{
  "id": "p-270",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-270",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "case sensitive "
},
{
  "id": "p-272",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-272",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "environment variable "
},
{
  "id": "p-276",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-276",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "file path "
},
{
  "id": "p-278",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-278",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "file folder directory "
},
{
  "id": "p-281",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-281",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "parent root directory path \/ "
},
{
  "id": "p-282",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-282",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "root user "
},
{
  "id": "p-285",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-285",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "parent child "
},
{
  "id": "p-287",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-287",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "root directory "
},
{
  "id": "p-291",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-291",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "command option flag "
},
{
  "id": "p-298",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-298",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "symbolic link symlink soft link "
},
{
  "id": "p-301",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-301",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "manual "
},
{
  "id": "p-305",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-305",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "home "
},
{
  "id": "p-316",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-316",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "remove directory remove directory "
},
{
  "id": "p-321",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-321",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Output redirection "
},
{
  "id": "p-327",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-327",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "input redirection "
},
{
  "id": "p-332",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-332",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "pipe (|) "
},
{
  "id": "p-335",
  "level": "2",
  "url": "sec_dev_basic_shell_commands.html#p-335",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "script "
},
{
  "id": "sec_dev_editors",
  "level": "1",
  "url": "sec_dev_editors.html",
  "type": "Section",
  "number": "4.3",
  "title": "We All Need an Editor!",
  "body": " We All Need an Editor!   Text editors are programs that help the user create and edit text files. Popular editors like Microsoft Word do not have the features that are needed by software developers and can not easily be used for editing source code because they can cause problems with the code itself due to the way they store formatted text. In short, Microsoft word is not a text editor and should never be used to edit source code because source code is a text file.  Professional software developers use text editors that are specifically designed to work with source code. These are sometimes called source code editors , code editors or just editors . Code editors typically include many special features for writing and editing code that go well beyond the typical uses such as finding and replacing, undoing, deleting, etc. It is worth noting that some professional developers prefer to use a text editor cofigured for working with code while others prefer to use an Integrated Development Environment (IDE) which is a tool that in addition to having source code editor functionality combines other commonly used developer tools in a single application. Because some text editors are so highly configurable using a variety of plug-ins and extensions, the line between text editors and IDEs has become quite blurred in recent years. Nevertheless, some of the main tools found in IDEs include:     code editor - which in addition to the standard find, replace, undo, redo, delete, etc, typically has block features like block indentation and dedentation, and block commenting and uncommenting.     code debugger - offers built-in tools to detect and diagnose errors in the code, including features such as variable inspection, stepping over and into code during execution, and setting break-points.     file explorer - a visual representation of the file system for easy navigation.     compiler or interpreter integration - Is able to convert the programming language to machine code and run the code from within the IDE.     search - the ability to search through an entire codebase for a search term.     syntax highlighting - where different colors and\/or styles of text are used to differentiate between comments, keywords, strings, etc.     terminal integration - offers access to the shell directly from within the IDE.     version control integration - facilitates the tracking and management of all code changes without leaving the IDE.    Professional developers all have their favorite editor, and searching for something like \"best editor to use for software development\" will bring up a host of answers and lists of popular editors. In addition to the code editor, code interpreter\/compiler, code debugger, integrated terminal, and tools for version control, the following is a list of other popular features in IDEs:     code completion - offering suggestions based on the context of the code being written.     code folding - the ability to collapse sections of code to better focus the workspace.     code refactoring - which is improving or updating code without changing its functional attributes.     code snippets - which are pre-written code blocks that can inserted into the code quickly.     multi-language support - the ability to work effectively with a variety of programming languages and their varying syntaxes.     profiling support - helps to analyze the performance of the code.     testing support - facilitates the running of tests and the use of text-suites, sometimes in an automated fashion during the editing process.    The most popular editors used by contributors to open source projects include Emacs , Vim , and Visual Studio Code aka VSCode . (Warning, VSCode, which is formally named Visual Studio Code, is not the same software as as Visual Studio. This rightfully causes a lot of confusion!) For novices contributors to open source, VSCode is recommended as a first choice because it is cross-platform and has reasonably shallow learning curve. It also happens to be open-source!  If you are interested in getting started with VSCode, you might begin with VSCode's Getting Started Videos and Guide.   "
},
{
  "id": "p-364",
  "level": "2",
  "url": "sec_dev_editors.html#p-364",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Text editors "
},
{
  "id": "p-365",
  "level": "2",
  "url": "sec_dev_editors.html#p-365",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "source code editors code editors editors Integrated Development Environment (IDE) "
},
{
  "id": "sec_dev_virtualization",
  "level": "1",
  "url": "sec_dev_virtualization.html",
  "type": "Section",
  "number": "4.4",
  "title": "Virtualization",
  "body": " Virtualization   In this section, we introduce several types of virtualization. You may run across these technologies while you are setting up a development environment to contribute to an open source project. The goal of this section is just one of familiarization with the terminology because a strong open source community that is welcoming to new contributors will have a README file that you can follow that will help you to get set up.    The What and Why of Virtualization   Virtualization is a technique that allows for one or more virtual (or simulated) environments to run on a given physical hardware system. Virtualization refers to the creation of virtual versions of system resources, such as operating systems, CPU cores, memory, storage devices, etc. In a virtualized system, each virtualized environment shares the actual system resources while operating as if it has dedicated resources such as memory, processing power, and storage. In part, because we can create just the right environment for a given application without running into conflicts when different applications have conflicting requirements, virtualization can provide cost-savings, flexibility, and increased efficiency.  You may encounter an open source community that uses some of these virtualization techniques because doing so provides benefits to them, perhaps the most important of which is portability. VM images and container images, for example, can typically be easily be moved between different environments, making it easier to develop and test software in a consistent environment.    Virtual Machines  A virtual machine (VM) is a simulation of a physical computer that runs its own operating system and applications as if it were a completely separate physical computer. VMs rely on a hypervisor (aka a virtualizer ) which is a type of computer software, firmware or hardware that creates and runs virtual machines. When using a VM, the physical computer is called the host machine and the virtual machine is called the guest machine . Virtual machines are managed by a software component called a hypervisor which makes sure that each virtual machine gets the needed resources without interfering with any real or other virtual systems.  If you are running an older version of Windows that does not support WSL2, and you are planning to set-up a development environment, then you are advised to use a VM running Ubuntu Linux. In the absence of other recommendations, VirtualBox is a very well-respected and popular open source multi-platform VM environment, so if you are running an older version of Windows, VirtualBox is a recommended VM.    Containerization  A container leverages virtualization at the level of the operating system where every application is provided with its own view of the operating system. Containerization packages an application and its dependencies into a single self-contained unit called a container image , which can be run on almost any host machine with the appropriate software.  Containers are lightweight and fast because they share the host machine's operating system and do not require their own operating system to be installed like VMs do. This makes containers highly portable, as well as easier to manage and deploy.  Some key concepts behind of containerization are:    Standardization: Containers provide a standard way to package and distribute applications, making it easier for open source projects to share and reuse code.     Isolation: Containers provide a way to isolate applications and their dependencies from the host operating system, which reduces the risk of software conflicts.     Portability: Containers are designed to be portable, which means they can be moved between different environments and different systems without modification.     Reproducibility: Containers make it easier to consistently recreate an environment and ensure that an application behaves the same way in development, testing, and production environments.     If you are following a README and you are asked to do any of the following installations, then you will be installing a containerized environment: Docker , Containerd , CRI-O >, LXC (Linux Container) >, Podman , rkt (Rocket) . Don't panic! The containerization should ultimately make it easier to set up the environment.   "
},
{
  "id": "p-385",
  "level": "2",
  "url": "sec_dev_virtualization.html#p-385",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Virtualization "
},
{
  "id": "p-387",
  "level": "2",
  "url": "sec_dev_virtualization.html#p-387",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "virtual machine (VM) hypervisor virtualizer host machine guest machine hypervisor "
},
{
  "id": "p-389",
  "level": "2",
  "url": "sec_dev_virtualization.html#p-389",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "container container image "
},
{
  "id": "git-why-version-control",
  "level": "1",
  "url": "git-why-version-control.html",
  "type": "Section",
  "number": "5.1",
  "title": "Why Version Control?",
  "body": " Why Version Control?   Have you ever experienced something like this the following scenario?  You create an important document.  Because its important you email it to some friends or family or colleagues for feedback on it.  You re-read it yourself create a new edited version.  Then you get back feedback from someone you sent it to, but the feedback is on your original version.  You then have to merge the two versions by hand .    After doing a lot of merging of documents by hand, you might have a folder that looks like the following:  mydoc.odt mydoc2.odt mydoc-moms-edits.odt mydoc2-plus-moms-combined.odt  Or maybe you have experienced this on a larger scale... For example, three of your friends comment on different versions, and then they each share their edits with the whole group via email. Some comment on the original version, some comment on your mom's version, others comment on your brother's version, etc.  If you have experienced this, you have used version control, which according to Wikipedia version control “is the management of changes to documents, programs, and other information stored as computer files.” But, if you have experienced anything like this, then you have also have come to deeply understand the need for a better and easier way to merge in any changes that come on an earlier version. Formal software systems that are designed for version control have many advantages over the kind of informal system that we just described.  A version control system (VCS) is a system that stores all of the versions of a project along with comments on those version that explain the reasons for the changes. A system that manages version control for software development is sometimes called a source code management (SCM) system, but we will typically use the more general term. In this chapter, you will learn the basics of version control.    Version Control Systems  The OSS world has developed many excellent ways of managing a software project, including not only a history of changes, but also who did what when and why.  You may want to start your own project someday, and you will have to choose an VCS. When you work with existing projects, the VCS has been chosen for you. The following five VCSs have been popular over the past few decades:    Subversion (svn)    Bazaar (bzr)    Concurrent Version System (cvs)    Git (git)    Mercurial (hg)      What has happened in the recent decade in version control systems has been truly remarkable because Git has come to completely dominate not just the open source world, but also much of the rest of the proprietary software community as well.   "
},
{
  "id": "p-402",
  "level": "2",
  "url": "git-why-version-control.html#p-402",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "version control system (VCS) "
},
{
  "id": "sec_git_getting_started",
  "level": "1",
  "url": "sec_git_getting_started.html",
  "type": "Section",
  "number": "5.2",
  "title": "Getting Started with Git",
  "body": " Getting Started with Git   Types of Version Control   Using a formal version control system (VCS) has many advantages over using just an informal system of version control like the one we described in the last section. Some of the important advantages of VCSs include:   Versioning  They allow users to track changes to a codebase over time. Users can see why changes were made and can go back to a previous version of the code if needed.    Collaboration  They allow multiple people to work on the same project at the same time, make changes to the code, and track the changes made by others. This facilitates collaboration.    Branching and Merging  They allow users to create different branches of the codebase, which enables developers to work on separate features or fixes without affecting the main codebase. Once changes are completed and approved, the branches can be merged back into the main codebase.   For the examples in this chapter, we will use software source code as the files being version controlled, although in reality you can do this with nearly any type of file or set of files. For example, if you are a web site designer and want to keep every version of the site, a VCS is a very wise thing to use. It allows you to revert selected files back to a previous state, revert the entire project back to a previous state, compare changes over time, see who last modified something that might be causing a problem, who introduced an issue and when, and more. Using a VCS also generally means that if you mess things up or lose files, you can easily recover.    Local VCSs    Many people’s first personal version-control method of choice is an informal one such as copying files into another directory or up into the cloud. These informal approaches are common because they are simple, but they are also error prone. It is easy to forget which directory you’re in and accidentally write to the wrong file or copy over files you don’t mean to.  To deal with this issue, programmers long ago developed a more formal system of version control. Local VCSs provide a more automatic, less error-prone and more structured way of keeping all the changes to files under revision control on the local computer. Local VCSs typically operate quickly because they do not have to communicate with a remote server. With a local system, developers have access to the entire history of the codebase on their local machine, and they can work on the codebase offline, without an internet connection.  However, there are significant disadvantages to using local VCSs. For example, local VCSs do not support collaboration because multiple developers cannot easily work on the same codebase at the same time. So. local VCSs are more suited for individual developers who are working on their own projects. Local VCSs store code data locally, which increases the risk of data loss due to machine failure or corruption because whenever you have the entire history of a project in a single place, you risk losing everything. In addition, local systems are not scalable, so as the codebase grows in size, the performance of the local system may degrade.    Centralized VCSs    Many developers need to collaborate with other developers on other systems. To deal with this, centralized VCss) were developed. These systems (such as CVS, Subversion, and Perforce) have a single server that contains all the versioned files, and a number of clients check out files from that central server. For many years, this was the standard for version control.  Centralized VCSs offer many advantages local VCSs. For example, everyone knows or can see to a certain degree what everyone else on the project is doing. Administrators have fine-grained control over who can do what.  However, centralized VCSs also have some serious downsides. Conflict resolution can be a challenge because if individual copies of the repository diverge significantly from one another, conflicts can arise when merging changes is attempted. This lead to a process of resolving the conflicts, which can be time-consuming even when using conflict resolution tools. In fact, resolution of conflicts can delay the development process. To mitigate this, developers must communicate regarding direction and must also synchronize copies of the codebase regularly by merging changes often. Effective communication and frequent updating can help prevent significant divergence and reduce the risk of conflicts in centralized VCSs.  Another obvious is that like local VCSs, the centralized server represents a single point of failure. If that server goes down for an time, then during that downtime nobody can collaborate at all and no one can save versioned changes to anything they’re working on. If the disk of the central server becomes corrupted, and proper backups haven’t been kept, the project could lose absolutely everything — the entire history of the project except whatever single snapshots people happen to have on their local machines.    Distributed VCSs    This is where distributed VCSs step in. In a distributed VCS (such as Git, Mercurial, Bazaar or Darcs), clients don’t just check out the latest snapshot of the files; rather, they fully mirror the repository, including its full history. Thus, if any server dies, and these systems were collaborating via that server, any of the client repositories can be copied back up to the server to restore it. Every clone is really a full backup of all the data.   Distributed Version Control    Furthermore, many of these distributed systems deal pretty well with having several remote repositories they can work with, so you can collaborate with different groups of people in different ways simultaneously within the same project. This allows you to set up several types of workflows that aren’t possible in centralized systems, such as hierarchical models.     A Short History of Git     As with many great things in life, Git began with a bit of creative destruction and fiery controversy.   The bridge of communication in a Linux system between the user applications and the underlying hardware is called the kernel, and the Linux kernel is an open source software project of fairly large scope. During the early years of kernel maintenance (1991–2002), changes to the software were passed around by email as descriptions of the differences in source files. In 2002, the Linux kernel project began using a proprietary distributed VCS called BitKeeper.   In 2005, the relationship between the community that developed the Linux kernel and the commercial company that developed BitKeeper broke down, and the tool’s free-of-charge status was revoked. This prompted the Linux development community (and in particular Linus Torvalds, the creator of Linux) to develop their own tool based on some of the lessons they learned while using BitKeeper. Some of the goals of the new system were as follows:     Speed    Simple design    Strong support for non-linear development (supports new\/separate versions called branches that do not conflict with one another during development)    Fully distributed    Able to handle large projects like the Linux kernel efficiently (speed and data size)     Since its birth in 2005, Git has evolved and matured to be easy to use and yet retain these initial qualities. It’s amazingly fast, it’s very efficient with large projects, and it has an incredible branching system for non-linear development     What is Git?     So, what is Git in a nutshell? This is an important topic to absorb, because if you understand what Git is and the fundamentals of how it works, then using Git effectively will probably be much easier for you.     Snapshots, Not Differences     The major difference between Git and most other VCSs is the way Git thinks about its data. Conceptually, most other systems store information as a list of file-based changes. These other systems (CVS, Subversion, Perforce, Bazaar, and so on) think of the information they store as a set of files and the changes made to each file over time (This is commonly described as delta-based version control).     Storing data as changes to a base version of each file    Git doesn’t think of or store its data this way. Instead, Git thinks of its data more like a series of snapshots of a miniature filesystem. With Git, every time you commit, or save the state of your project, Git basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. To be efficient, if files have not changed, Git doesn’t store the file again, just a link to the previous identical file it has already stored. Git thinks about its data more like a stream of snapshots .   Storing data as snapshots of the project over time    This is an important distinction between Git and nearly all other VCSs. It makes Git reconsider almost every aspect of version control that most other systems copied from the previous generation. This makes Git more like a mini filesystem with some incredibly powerful tools built on top of it, rather than simply a VCS. We’ll explore some of the benefits you gain by thinking of your data this way when we cover Git branching in Git Branching.     Nearly Every Operation Is Local     Most operations in Git need only local files and resources to operate — generally no information is needed from another computer on your network. Because you have the entire history of the project right there on your local disk, most operations seem almost instantaneous.   For example, to browse the history of the project, Git doesn’t need to go out to the server to get the history and display it for you — it simply reads it directly from your local repository. This means you see the project history almost instantly. If you want to see the changes introduced between the current version of a file and the file a month ago, Git can look up the file a month ago and do a local difference calculation, instead of having to either ask a remote server to do it or pull an older version of the file from the remote server to do it locally.   This also means that there is very little you can’t do if you’re offline. If you get on an airplane or a train and want to do a little work, you can commit happily (to your local copy, remember?) until you get to a network connection to upload.     Git Has Integrity     Everything in Git is stored via a unique digital fingerprint of the data. This means it’s impossible to change the contents of any file or directory without Git knowing about it. This functionality is built into Git at the lowest levels and is integral to its philosophy. You can’t lose information in transit or get file corruption without Git being able to detect it.   The mechanism that Git uses for creating this unique digital fingerprint of the data is called a SHA-1 hash . This is a 40-character string composed of hexadecimal characters (0–9 and a–f) and calculated based on the contents of a file or directory structure in Git. A SHA-1 hash looks something like this:    24b9da6552252987aa493b52f8696cd6d3b00373   You will see these hash values all over the place in Git because it uses them so much. In fact, Git stores everything in its repository not by file name but by the hash value of its contents. Because they are a long incomprehensible strings, they look strange, but try not to let that bother you.     Git Generally Only Adds Data     During ordinary use of Git, nearly all of your actions only add data. It is intended to be hard to get Git to do anything that is not undoable or to make it erase data in any way. As with any VCS, you can lose or mess up changes you haven’t committed yet, but after you commit a snapshot into Git, it is more difficult to lose, specially if you regularly push the state of your repository to a remote. Having said this, novices can get themselves into a mess. Some advice is to always make sure you are working on a branch other than main or master , and always check to be sure you are on the intended branch before you begin working.      The Three File States     Pay attention now — here is the main set of concepts to remember about files in Git if you want the rest of your learning process to go smoothly. Git has three main states that your files can reside in, modified , staged , and committed :      Modified means that you have changed the file but have not committed it to your repository yet.     Staged means that you have marked a modified file in its current version to go into your next commit snapshot.     Committed means that the data is safely stored in your local repository.   As a metaphor for better understanding these concepts, let's imagine you are shopping for a shirt and some other items online. You find a page with a shirt you are considering, and you make several choices by clicking on things like the style (long-sleeved vs short-sleeved, for example), the size, the color, etc. The state of your browser has been modified from the default state, but you haven't completely decided if you want it, so you have not put it into your shopping cart. That is analogous to modifying your codebase before staging in Git.  Next, maybe you decide that you like these shirt choices enough that you don't want to lose them, so you put the style, size, and color shirt you like into your shopping cart. That is analogous to staging — you have not yet completely committed to buying the shirt, but you are ready to do so, and you are still able to change your mind and make additional changes to your choices or remove the shirt from the shopping cart altogether. You can also keep shopping and postpone making a decision about buying while you continue shopping.  Once you have made all of your shopping choices and are ready to commit to paying for the items in your shopping cart, you go through the process of paying. This is analogous to committing — you have made a commitment to receive the items that you paid for, and the online store keeps a record of your purchase. Of course, once you receive the shirt and it isn't quite what you had hoped for, you can still return the shirt, but it is more complicated to do so than before you made the purchase and a record will be made of the return as well. This is also analogous to how Git works.  The concepts of modified, staged, and committed describe the different stages that files can go through as they are modified and committed to the repository. Next, let's discuss how Git is organized.    How Git is Organized     A Git repository is more than just a set of files. It is also more than just a set of snapshots of files. It's a complete history of a project's development, which includes information about who made what changes, when those changes were made, and why they were made because the repository includes not only the committed snapshots of files, but also the metadata that accompanies those snapshots, such as commit messages and author information. Additionally, the repository includes information about the branches and tags that have been created to manage the development of the project.  This leads us to three key components of a Git VCS: the Git working tree, the Git staging area, and the Git directory.   Git working tree, Git staging area, and Git directory    The Git working tree refers to the set of files and directories that are currently being worked on in a local repository, but it is more than just the set of files and directories. It is also a service that continuously monitors the resource status of the files and the file system in that local repository. For example, the Git working tree logs when a new file is added or deleted or modified.  When you use stage changes, Git copies the changes from the modified files that are in the working tree to the staging area.   The Git staging area , also known as the Git index , is a file where the changes to files that have been staged are stored and stand ready to be committed.  Once changes have been staged in the staging area, you can create a new commit. This then takes the staged changes and creates a new snapshot of the files in the Git directory.   The Git directory is where all the committed snapshots of the project are stored along with the associated metadata, such as commit messages and author information. This is the most important part of Git. Along with the files and file directory, the Git directory is copied when you clone a repository from another computer.   The basic Git workflow goes something like this:     You modify files in your working tree.    You selectively stage just those changes you want to be part of your next commit, which adds only those changes to the staging area.    You then do a commit, which takes the files as they are in the staging area and stores that snapshot permanently to your local Git directory (on your computer). Note that in , we will learn how to push your work to a remote copy of the repository.     If a particular version of a file is in the Git directory, it’s considered committed . If it has been modified and was added to the staging area, it is staged . And if it was changed since it was checked out but has not been staged, it is modified . In  you’ll learn more about these states and how you can either take advantage of them or skip the staged part entirely.     The Command Line   There are a lot of different ways to use Git. There are the original command-line tools, and there are many graphical user interfaces of varying capabilities. For this chapter, we will be using Git on the command line. For one, the command line is the only place you can run all Git commands — most of the GUIs implement only a partial subset of Git functionality for simplicity. If you know how to run the command-line version, you can probably also figure out how to run the GUI version, while the opposite is not necessarily true. Also, while your choice of graphical client is a matter of personal taste, all users will have the command-line tools installed and available.   So you will need to to know how to open the Terminal in macOS or Linux or the Command Prompt or PowerShell in Windows. If you don’t remember what we’re talking about here, please review .     Installing Git   Before you start using Git, you have to make it available on your computer. Even if it’s already installed, it’s probably a good idea to update to the latest version. You can either install it as a package or via another installer, or download the source code and compile it yourself. If you are a beginner, we strongly recommend using an installer.      Installing on Linux     Using your Linux distribution's preferred package manager is the simplest process for installing Git on Linux.  If you’re on a Debian-based distribution, such as Ubuntu, try apt :  $ sudo apt install git-all  If you’re on Fedora (or any closely-related RPM-based distribution, such as RHEL or CentOS), you can use dnf :    $ sudo dnf install git-all    For more options, there are instructions for installing on many different Linux distributions on the Git website, at https:\/\/git-scm.com\/download\/linux .     Installing on MacOS     There are several ways to install Git on a Mac.  One way is to install homebrew if you don't already have it. Go to and follow the directions. Then open a Terminal and type:  brew install git  Another excellent way is to install the Xcode Command Line Tools, which is an Apple package with useful developer tools that run on the command line. Apply has made this very easy to do simply by trying to run Git from the Terminal the very first time. If you open a terminal and type the following:  $ git --version   When you run that command, if you don’t have Git installed already, it will prompt you to install it.   For these and additional options visit https:\/\/git-scm.com\/download\/mac .     Installing on Windows     There are also a few ways to install Git on Windows that depend upon where your development environment is.  If you are using WSL2 or are developing in a VM, then open a terminal in that environment and follow the directions for installing Git in Ubuntu from the Linux section above.  If you are working in WSL2, Git for Windows might also be useful. Git for Windows provides a native set of tools that bring the full feature set of the Git SCM to Windows as well as bash emulation which can be used to run Git from the command line. To install go to https:\/\/gitforwindows.org . Not that Git for Windows will not be useful to you if you are developing in a VM running Ubuntu.      Getting Help   If you ever need help while using Git, there are three equivalent ways to get help for any of the Git commands:    $ git help <verb> $ git <verb> --help $ man git-<verb>   For example, you can get help for the git config command by running this:    $ git help config   If you don’t need the full-blown manpage help, but just need a quick refresher on the available options for a specific Git command, you can ask for the more concise “help” output with the -h option, as in the following for the Git add command: :    $ git add -h    Conclusion  You should now have a basic understanding of different types of VCSs, as well as some of their advantages and disadvantages. You should also now know what Git is and should also now have a working version of Git set-up on your system. In the next section, we will learn some Git basics.   "
},
{
  "id": "p-407",
  "level": "2",
  "url": "sec_git_getting_started.html#p-407",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "version control system (VCS) "
},
{
  "id": "git-distributed",
  "level": "2",
  "url": "sec_git_getting_started.html#git-distributed",
  "type": "Figure",
  "number": "5.2.1",
  "title": "",
  "body": " Distributed Version Control   "
},
{
  "id": "git-deltas",
  "level": "2",
  "url": "sec_git_getting_started.html#git-deltas",
  "type": "Figure",
  "number": "5.2.2",
  "title": "",
  "body": " Storing data as changes to a base version of each file   "
},
{
  "id": "p-437",
  "level": "2",
  "url": "sec_git_getting_started.html#p-437",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "stream of snapshots "
},
{
  "id": "git-snapshots",
  "level": "2",
  "url": "sec_git_getting_started.html#git-snapshots",
  "type": "Figure",
  "number": "5.2.3",
  "title": "",
  "body": " Storing data as snapshots of the project over time   "
},
{
  "id": "p-445",
  "level": "2",
  "url": "sec_git_getting_started.html#p-445",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "SHA-1 hash "
},
{
  "id": "p-451",
  "level": "2",
  "url": "sec_git_getting_started.html#p-451",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Modified Staged Committed "
},
{
  "id": "git-areas",
  "level": "2",
  "url": "sec_git_getting_started.html#git-areas",
  "type": "Figure",
  "number": "5.2.4",
  "title": "",
  "body": " Git working tree, Git staging area, and Git directory   "
},
{
  "id": "p-461",
  "level": "2",
  "url": "sec_git_getting_started.html#p-461",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Git working tree "
},
{
  "id": "p-463",
  "level": "2",
  "url": "sec_git_getting_started.html#p-463",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Git staging area Git index "
},
{
  "id": "p-465",
  "level": "2",
  "url": "sec_git_getting_started.html#p-465",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Git directory "
},
{
  "id": "sec_git_basics",
  "level": "1",
  "url": "sec_git_basics.html",
  "type": "Section",
  "number": "5.3",
  "title": "Git Basics",
  "body": " Git Basics   If you could read only one section to get going with Git, this would be the one to read. This section covers every basic command you need to do the vast majority of the things you’ll eventually spend your time doing with Git. By the end of this section, you should be able to configure and initialize a repository, begin and stop tracking files, and stage and commit changes. You will also learn how to set up Git to ignore certain files and file patterns, how to undo mistakes quickly and easily, how to browse the history of your project and view changes between commits, and how to push and pull from remote repositories.    Getting a Git Repository   You typically obtain an existing Git repository in one of two ways:     You can take an existing local directory that is currently not under version control, and turn it into a Git repository, or    You can clone an existing Git repository from elsewhere.     In either case, you end up with a Git repository on your local machine, ready for work.    Initializing a Repository in an Existing Directory   If you have a project directory that is currently not under version control and you want to start controlling it with Git, you first need to go to that project’s directory. If you’ve never done this, it looks a little different depending on which system you’re running:   for Linux:    $ cd \/home\/user\/my_project   for macOS:    $ cd \/Users\/user\/my_project   for Windows:    $ cd C:\/Users\/user\/my_project   and type:    $ git init   This creates a new subdirectory named .git that contains all of your necessary repository files — a Git repository skeleton. At this point, nothing in your project is tracked yet.   If you want to start version-controlling existing files (as opposed to an empty directory), you should probably begin tracking those files and do an initial commit. You can accomplish that with a few git add commands that specify the files you want to track, followed by a git commit :    $ git add *.c $ git add LICENSE $ git commit -m 'Initial project version'   We’ll go over what these commands do in just a minute. At this point, you have a Git repository with tracked files and an initial commit.     Cloning an Existing Repository   If you want to get a copy of an existing Git repository — for example, a project you’d like to contribute to — the command you need is git clone . If you’re familiar with other VCSs such as Subversion, you’ll notice that the command is \"clone\" and not \"checkout\". This is an important distinction — instead of getting just a working copy, Git receives a full copy of nearly all data that the server has. Every version of every file for the history of the project is pulled down by default when you run git clone .   You clone a repository with git clone <url> . For example, if you want to clone the Git linkable library called libgit2 , you can do so like this:    $ git clone https:\/\/github.com\/libgit2\/libgit2   That creates a directory named libgit2 , initializes a .git directory inside it, pulls down all the data for that repository, and checks out a working copy of the latest version. If you go into the new libgit2 directory that was just created, you’ll see the project files in there, ready to be worked on or used.   If you want to clone the repository into a directory named something other than libgit2 , you can specify the new directory name as an additional argument:    $ git clone https:\/\/github.com\/libgit2\/libgit2 mylibgit   That command does the same thing as the previous one, but the target directory is called mylibgit .   Git has a number of different transfer protocols you can use. The previous example uses the https:\/\/ protocol, but you may also see git:\/\/ or user@server:path\/to\/repo.git , which uses the SSH transfer protocol.     Recording Changes to the Repository   At this point, you should have a bona fide Git repository on your local machine, and a checkout or working copy of all of its files in front of you. Typically, you’ll want to start making changes and committing snapshots of those changes into your repository each time the project reaches a state you want to record.   Remember that each file in your working directory can be in one of two states: tracked or untracked . Tracked files are files that were in the last snapshot, as well as any newly staged files; they can be unmodified, modified, or staged. In short, tracked files are files that Git knows about.   Untracked files are everything else — any files in your working directory that were not in your last snapshot and are not in your staging area. When you first clone a repository, all of your files will be tracked and unmodified because Git just checked them out and you haven’t edited anything.   As you edit files, Git sees them as modified, because you’ve changed them since your last commit. As you work, you selectively stage these modified files and then commit all those staged changes, and the cycle repeats.     The lifecycle of the status of your files        Checking the Status of Your Files   The main tool you use to determine which files are in which state is the git status command. If you run this command directly after a clone, you should see something like this:    $ git status On branch main Your branch is up-to-date with 'origin\/main'. nothing to commit, working tree clean   This means you have a clean working directory; in other words, none of your tracked files are modified. Git also doesn’t see any untracked files, or they would be listed here. Finally, the command tells you which branch you’re on and informs you that it has not diverged from the same branch on the server. That branch is typically main , which is the current default. It could also be main , which was the default until October 1, 2020. Don't worry about it here. The next section on Git Branching will go over branches and references in detail.   Let’s say you add a new file to your project, a simple README file. If the file didn’t exist before, and you run git status , you see your untracked file like so:    $ echo 'My Project' > README $ git status On branch main Your branch is up-to-date with 'origin\/main'. Untracked files: (use \"git add <file>...\" to include in what will be committed) README nothing added to commit but untracked files present (use \"git add\" to track)   You can see that your new README file is untracked, because it’s under the “Untracked files” heading in your status output. Untracked basically means that Git sees a file you didn’t have in the previous snapshot (commit), and which hasn’t yet been staged; Git won’t start including it in your commit snapshots until you explicitly tell it to do so. It does this so you don’t accidentally begin including generated binary files or other files that you did not mean to include. You do want to start including README , so let’s start tracking the file.     Tracking New Files   In order to begin tracking a new file, you use the command git add . To begin tracking the README file, you can run this:    $ git add README   If you run your status command again, you can see that your README file is now tracked and staged to be committed:    $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git restore --staged <file>...\" to unstage) new file: README   You can tell that it’s staged because it’s under the “Changes to be committed” heading. If you commit at this point, the version of the file at the time you ran git add is what will be in the subsequent historical snapshot. You may recall that when you ran git init earlier, you then ran git add <files>  — that was to begin tracking files in your directory. The git add command takes a path name for either a file or a directory; if it’s a directory, the command adds all the files in that directory recursively.     Staging Modified Files   Let’s change a file that was already tracked. If you change a previously tracked file called CONTRIBUTING.md and then run your git status command again, you get something that looks like this:    $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) new file: README Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   The CONTRIBUTING.md file appears under a section named “Changes not staged for commit” — which means that a file that is tracked has been modified in the working directory but not yet staged. To stage it, you run the git add command. git add is a multipurpose command — you use it to begin tracking new files, to stage files, and to do other things like marking merge-conflicted files as resolved. It may be helpful to think of it more as “add precisely this content to the next commit” rather than “add this file to the project”. Let’s run git add now to stage the CONTRIBUTING.md file, and then run git status again:    $ git add CONTRIBUTING.md $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) new file: README modified: CONTRIBUTING.md   Both files are staged and will go into your next commit. At this point, suppose you remember one little change that you want to make in CONTRIBUTING.md before you commit it. You open it again and make that change, and you’re ready to commit. However, let’s run git status one more time:    $ vim CONTRIBUTING.md $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) new file: README modified: CONTRIBUTING.md Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   What the heck? Now CONTRIBUTING.md is listed as both staged and unstaged. How is that possible? It turns out that Git stages a file exactly as it is when you run the git add command. If you commit now, the version of CONTRIBUTING.md as it was when you last ran the git add command is how it will go into the commit, not the version of the file as it looks in your working directory when you run git commit . If you modify a file after you run git add , you have to run git add again to stage the latest version of the file:    $ git add CONTRIBUTING.md $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) new file: README modified: CONTRIBUTING.md     Short Status   While the git status output is pretty comprehensive, it’s also quite wordy. Git also has a short status flag so you can see your changes in a more compact way. If you run git status -s or git status --short you get a far more simplified output from the command:    $ git status -s M README MM Rakefile A lib\/git.rb M lib\/simplegit.rb ?? LICENSE.txt   New files that aren’t tracked have a ?? next to them, new files that have been added to the staging area have an A , modified files have an M and so on. There are two columns to the output — the left-hand column indicates the status of the staging area and the right-hand column indicates the status of the working tree. So for example in that output, the README file is modified in the working directory but not yet staged, while the lib\/simplegit.rb file is modified and staged. The Rakefile was modified, staged and then modified again, so there are changes to it that are both staged and unstaged.     Ignoring Files   Often, you’ll have a class of files that you don’t want Git to automatically add or even show you as being untracked. These are generally automatically generated files such as log files or files produced by your build system. In such cases, you can create a file listing patterns to match them named .gitignore . Here is an example .gitignore file:    $ cat .gitignore *.[oa] *~   The first line tells Git to ignore any files ending in “.o” or “.a” — object and archive files that may be the product of building your code. The second line tells Git to ignore all files whose names end with a tilde ( ~ ), which is used by some text editors to mark temporary files. You may also include a log, tmp, or pid directory; automatically generated documentation; and so on. Setting up a .gitignore file for your new repository before you get going is generally a good idea so you don’t accidentally commit files that you really don’t want in your Git repository.   The rules for the patterns you can put in the .gitignore file are as follows:     Blank lines or lines starting with # are ignored.    Standard glob patterns work, and will be applied recursively throughout the entire working tree.    You can start patterns with a forward slash ( \/ ) to avoid recursivity.    You can end patterns with a forward slash ( \/ ) to specify a directory.    You can negate a pattern by starting it with an exclamation point ( ! ).     Glob patterns are like simplified regular expressions that shells use. An asterisk ( * ) matches zero or more characters; [abc] matches any character inside the brackets (in this case a, b, or c); a question mark ( ? ) matches a single character; and brackets enclosing characters separated by a hyphen ( [0-9] ) matches any character between them (in this case 0 through 9). You can also use two asterisks to match nested directories; a\/**\/z would match a\/z , a\/b\/z , a\/b\/c\/z , and so on.   Here is another example .gitignore file:    # ignore all .a files *.a # but do track lib.a, even though you're ignoring .a files above !lib.a # only ignore the TODO file in the current directory, not subdir\/TODO \/TODO # ignore all files in any directory named build build\/ # ignore doc\/notes.txt, but not doc\/server\/arch.txt doc\/*.txt # ignore all .pdf files in the doc\/ directory and any of its subdirectories doc\/**\/*.pdf   Tip: GitHub maintains a fairly comprehensive list of good .gitignore file examples for dozens of projects and languages at https:\/\/github.com\/github\/gitignore if you want a starting point for your project.   Note: In the simple case, a repository might have a single .gitignore file in its root directory, which applies recursively to the entire repository. However, it is also possible to have additional .gitignore files in subdirectories. The rules in these nested .gitignore files apply only to the files under the directory where they are located. The Linux kernel source repository has 206 .gitignore files.   It is beyond the scope of this book to get into the details of multiple .gitignore files; see man gitignore for the details.     Viewing Your Staged and Unstaged Changes   If the git status command is too vague for you — you want to know exactly what you changed, not just which files were changed — you can use the git diff command. We’ll cover git diff in more detail later, but you’ll probably use it most often to answer these two questions: What have you changed but not yet staged? And what have you staged that you are about to commit? Although git status answers those questions very generally by listing the file names, git diff shows you the exact lines added and removed — the patch, as it were.   Let’s say you edit and stage the README file again and then edit the CONTRIBUTING.md file without staging it. If you run your git status command, you once again see something like this:    $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) modified: README Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   To see what you’ve changed but not yet staged, type git diff with no other arguments:    $ git diff diff --git a\/CONTRIBUTING.md b\/CONTRIBUTING.md index 8ebb991..643e24f 100644 --- a\/CONTRIBUTING.md +++ b\/CONTRIBUTING.md @@ -65,7 +65,8 @@ branch directly, things can get messy. Please include a nice description of your changes when you submit your PR; if we have to read the whole diff to figure out why you're contributing in the first place, you're less likely to get feedback and have your change -merged in. +merged in. Also, split your changes into comprehensive chunks if your patch is +longer than a dozen lines. If you are starting to work on a particular area, feel free to submit a PR that highlights your work in progress (and note in the PR title that it's   That command compares what is in your working directory with what is in your staging area. The result tells you the changes you’ve made that you haven’t yet staged.   If you want to see what you’ve staged that will go into your next commit, you can use git diff --staged . This command compares your staged changes to your last commit:    $ git diff --staged diff --git a\/README b\/README new file mode 100644 index 0000000..03902a1 --- \/dev\/null +++ b\/README @@ -0,0 +1 @@ +My Project   It’s important to note that git diff by itself doesn’t show all changes made since your last commit — only changes that are still unstaged. If you’ve staged all of your changes, git diff will give you no output.   For another example, if you stage the CONTRIBUTING.md file and then edit it, you can use git diff to see the changes in the file that are staged and the changes that are unstaged. If our environment looks like this:    $ git add CONTRIBUTING.md $ echo '# test line' >> CONTRIBUTING.md $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) modified: CONTRIBUTING.md Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   Now you can use git diff to see what is still unstaged:    $ git diff diff --git a\/CONTRIBUTING.md b\/CONTRIBUTING.md index 643e24f..87f08c8 100644 --- a\/CONTRIBUTING.md +++ b\/CONTRIBUTING.md @@ -119,3 +119,4 @@ at the ## Starter Projects See our [projects list](https:\/\/github.com\/libgit2\/libgit2\/blob\/development\/PROJECTS.md). +# test line   and git diff --cached to see what you’ve staged so far ( --staged and --cached are synonyms):     $ git diff --cached diff --git a\/CONTRIBUTING.md b\/CONTRIBUTING.md index 8ebb991..643e24f 100644 --- a\/CONTRIBUTING.md +++ b\/CONTRIBUTING.md @@ -65,7 +65,8 @@ branch directly, things can get messy. Please include a nice description of your changes when you submit your PR; if we have to read the whole diff to figure out why you're contributing in the first place, you're less likely to get feedback and have your change -merged in. +merged in. Also, split your changes into comprehensive chunks if your patch is +longer than a dozen lines. If you are starting to work on a particular area, feel free to submit a PR that highlights your work in progress (and note in the PR title that it is so.   Note: Git Diff in an External Tool  We will continue to use the git diff command in various ways throughout the rest of the book. There is another way to look at these diffs if you prefer a graphical or external diff viewing program instead. If you run git difftool instead of git diff , you can view any of these diffs in software like emerge, vimdiff and many more (including commercial products). Run git difftool --tool-help to see what is available on your system.     Committing Your Changes   Now that your staging area is set up the way you want it, you can commit your changes. Remember that anything that is still unstaged — any files you have created or modified that you haven’t run git add on since you edited them — won’t go into this commit. They will stay as modified files on your disk. In this case, let’s say that the last time you ran git status , you saw that everything was staged, so you’re ready to commit your changes. The simplest way to commit is to type git commit :    $ git commit   Doing so launches your editor of choice.  Note: This is set by your shell’s EDITOR environment variable, although you can configure it with whatever you want using the git config - -global core.editor command as you saw in the previous section.   The editor displays the following text (this example is a Vim screen):    # Please enter the commit message for your changes. Lines starting # with '#' will be ignored, and an empty message aborts the commit. # On branch main # Your branch is up-to-date with 'origin\/main'. # # Changes to be committed: # new file: README # modified: CONTRIBUTING.md # ~ ~ ~ \".git\/COMMIT_EDITMSG\" 9L, 283C   You can see that the default commit message contains the latest output of the git status command commented out and one empty line on top. You can remove these comments and type your commit message, or you can leave them there to help you remember what you’re committing.  Note: For an even more explicit reminder of what you’ve modified, you can pass the -v option to git commit . Doing so also puts the diff of your change in the editor so you can see exactly what changes you’re committing.   When you exit the editor, Git creates your commit with that commit message (with the comments and diff stripped out).   Alternatively, you can type your commit message inline with the commit command by specifying it after a -m flag, like this:    $ git commit -m \"Story 182: fix benchmarks for speed\" [main 463dc4f] Story 182: fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README   Now you’ve created your first commit! You can see that the commit has given you some output about itself: which branch you committed to ( main ), what SHA-1 checksum the commit has ( 463dc4f ), how many files were changed, and statistics about lines added and removed in the commit.   Remember that the commit records the snapshot you set up in your staging area. Anything you didn’t stage is still sitting there modified; you can do another commit to add it to your history. Every time you perform a commit, you’re recording a snapshot of your project that you can revert to or compare to later.     Skipping the Staging Area   Although it can be amazingly useful for crafting commits exactly how you want them, the staging area is sometimes a bit more complex than you need in your workflow. If you want to skip the staging area, Git provides a simple shortcut. Adding the -a option to the git commit command makes Git automatically stage every file that is already tracked before doing the commit, letting you skip the git add part:    $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md no changes added to commit (use \"git add\" and\/or \"git commit -a\") $ git commit -a -m 'Add new benchmarks' [main 83e38c7] Add new benchmarks 1 file changed, 5 insertions(+), 0 deletions(-)   Notice how you don’t have to run git add on the CONTRIBUTING.md file in this case before you commit. That’s because the -a flag includes all changed files. This is convenient, but be careful; sometimes this flag will cause you to include unwanted changes.     Removing Files   To remove a file from Git, you have to remove it from your tracked files (more accurately, remove it from your staging area) and then commit. The git rm command does that, and also removes the file from your working directory so you don’t see it as an untracked file the next time around.   If you simply remove the file from your working directory, it shows up under the “Changes not staged for commit” (that is, unstaged ) area of your git status output:    $ rm PROJECTS.md $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes not staged for commit: (use \"git add\/rm <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) deleted: PROJECTS.md no changes added to commit (use \"git add\" and\/or \"git commit -a\")   Then, if you run git rm , it stages the file’s removal:    $ git rm PROJECTS.md rm 'PROJECTS.md' $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) deleted: PROJECTS.md   The next time you commit, the file will be gone and no longer tracked. If you modified the file or had already added it to the staging area, you must force the removal with the -f option. This is a safety feature to prevent accidental removal of data that hasn’t yet been recorded in a snapshot and that can’t be recovered from Git.   Another useful thing you may want to do is to keep the file in your working tree but remove it from your staging area. In other words, you may want to keep the file on your hard drive but not have Git track it anymore. This is particularly useful if you forgot to add something to your .gitignore file and accidentally staged it, like a large log file or a bunch of .a compiled files. To do this, use the --cached option:    $ git rm --cached README   You can pass files, directories, and file-glob patterns to the git rm command. That means you can do things such as:    $ git rm log\/\\*.log   Note the backslash ( \\ ) in front of the * . This is necessary because Git does its own filename expansion in addition to your shell’s filename expansion. This command removes all files that have the .log extension in the log\/ directory. Or, you can do something like this:    $ git rm \\*~   This command removes all files whose names end with a ~ .     Moving Files   Unlike many other VCSs, Git doesn’t explicitly track file movement. If you rename a file in Git, no metadata is stored in Git that tells it you renamed the file. However, Git is pretty smart about figuring that out after the fact — we’ll deal with detecting file movement a bit later.   Thus it’s a bit confusing that Git has a mv command. If you want to rename a file in Git, you can run something like:    $ git mv file_from file_to   and it works fine. In fact, if you run something like this and look at the status, you’ll see that Git considers it a renamed file:    $ git mv README.md README $ git status On branch main Your branch is up-to-date with 'origin\/main'. Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) renamed: README.md -> README   However, this is equivalent to running something like this:    $ mv README.md README $ git rm README.md $ git add README   Git figures out that it’s a rename implicitly, so it doesn’t matter if you rename a file that way or with the mv command. The only real difference is that git mv is one command instead of three — it’s a convenience function. More importantly, you can use any tool you like to rename a file, and address the add \/ rm later, before you commit.     Viewing the Commit History   After you have created several commits, or if you have cloned a repository with an existing commit history, you’ll probably want to look back to see what has happened. The most basic and powerful tool to do this is the git log command.   These examples use a very simple project called “simplegit”. To get the project, run:    $ git clone https:\/\/github.com\/schacon\/simplegit-progit   When you run git log in this project, you should get output that looks something like this:    $ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon <schacon@gee-mail.com> Date: Mon Mar 17 21:52:11 2008 -0700 Change version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon <schacon@gee-mail.com> Date: Sat Mar 15 16:40:33 2008 -0700 Remove unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon <schacon@gee-mail.com> Date: Sat Mar 15 10:31:28 2008 -0700 Initial commit   By default, with no arguments, git log lists the commits made in that repository in reverse chronological order; that is, the most recent commits show up first. As you can see, this command lists each commit with its SHA-1 checksum, the author’s name and email, the date written, and the commit message.   A huge number and variety of options to the git log command are available to show you exactly what you’re looking for. If interested, see git-log - Show commit logs for the details, but don't worry about the overwhelming number of options — be reassured that you don't need them right now.  Here, we’ll show you only the most popular.   One of the more helpful options is -p or --patch , which shows the difference (the patch output) introduced in each commit. You can also limit the number of log entries displayed, such as using -2 to show only the last two entries.    $ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon <schacon@gee-mail.com> Date: Mon Mar 17 21:52:11 2008 -0700 Change version number diff --git a\/Rakefile b\/Rakefile index a874b73..8f94139 100644 --- a\/Rakefile +++ b\/Rakefile @@ -5,7 +5,7 @@ require 'rake\/gempackagetask' spec = Gem::Specification.new do |s| s.platform = Gem::Platform::RUBY s.name = \"simplegit\" - s.version = \"0.1.0\" + s.version = \"0.1.1\" s.author = \"Scott Chacon\" s.email = \"schacon@gee-mail.com\" s.summary = \"A simple gem for using Git in Ruby code.\" commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon <schacon@gee-mail.com> Date: Sat Mar 15 16:40:33 2008 -0700 Remove unnecessary test diff --git a\/lib\/simplegit.rb b\/lib\/simplegit.rb index a0a60ae..47c6340 100644 --- a\/lib\/simplegit.rb +++ b\/lib\/simplegit.rb @@ -18,8 +18,3 @@ class SimpleGit end end - -if $0 == __FILE__ - git = SimpleGit.new - puts git.show -end   This option displays the same information but with a diff directly following each entry. This is very helpful for code review or to quickly browse what happened during a series of commits that a collaborator has added.    Working with Remotes   To be able to collaborate on any Git project, you need to know how to manage your remote repositories. Remote repositories are versions of your project that are hosted on the Internet or network somewhere. You can have several of them, each of which generally is either read-only or read\/write for you. Collaborating with others involves managing these remote repositories and pushing and pulling data to and from them when you need to share work. Managing remote repositories includes knowing how to add remote repositories, remove remotes that are no longer valid, manage various remote branches and define them as being tracked or not, and more. In this section, we’ll cover some of these remote-management skills.    Remote repositories can be on your local machine. It is entirely possible that you can be working with a “remote” repository that is, in fact, on the same host you are. The word “remote” does not necessarily imply that the repository is somewhere else on the network or Internet, only that it is elsewhere. Working with such a remote repository would still involve all the standard pushing, pulling and fetching operations as with any other remote.    Showing Your Remotes   To see which remote servers you have configured, you can run the git remote command. It lists the shortnames of each remote handle you’ve specified. If you’ve cloned your repository, you should at least see origin  — that is the default name Git gives to the server you cloned from:    $ git clone https:\/\/github.com\/schacon\/ticgit Cloning into 'ticgit'... remote: Reusing existing pack: 1857, done. remote: Total 1857 (delta 0), reused 0 (delta 0) Receiving objects: 100% (1857\/1857), 374.35 KiB | 268.00 KiB\/s, done. Resolving deltas: 100% (772\/772), done. Checking connectivity... done. $ cd ticgit $ git remote origin   You can also specify -v , which shows you the URLs that Git has stored for the shortname to be used when reading and writing to that remote:    $ git remote -v origin https:\/\/github.com\/schacon\/ticgit (fetch) origin https:\/\/github.com\/schacon\/ticgit (push)   If you have more than one remote, the command lists them all. For example, a repository with multiple remotes for working with several collaborators might look something like this.    $ cd grit $ git remote -v bakkdoor https:\/\/github.com\/bakkdoor\/grit (fetch) bakkdoor https:\/\/github.com\/bakkdoor\/grit (push) cho45 https:\/\/github.com\/cho45\/grit (fetch) cho45 https:\/\/github.com\/cho45\/grit (push) defunkt https:\/\/github.com\/defunkt\/grit (fetch) defunkt https:\/\/github.com\/defunkt\/grit (push) koke git:\/\/github.com\/koke\/grit.git (fetch) koke git:\/\/github.com\/koke\/grit.git (push) origin git@github.com:mojombo\/grit.git (fetch) origin git@github.com:mojombo\/grit.git (push)   This means we can pull contributions from any of these users pretty easily. We may additionally have permission to push to one or more of these, though we can’t tell that here.     Adding Remote Repositories   We’ve mentioned and given some demonstrations of how the git clone command implicitly adds the origin remote for you. Here’s how to add a new remote explicitly. To add a new remote Git repository as a shortname you can reference easily, run git remote add <shortname> <url> :    $ git remote origin $ git remote add pb https:\/\/github.com\/paulboone\/ticgit $ git remote -v origin https:\/\/github.com\/schacon\/ticgit (fetch) origin https:\/\/github.com\/schacon\/ticgit (push) pb https:\/\/github.com\/paulboone\/ticgit (fetch) pb https:\/\/github.com\/paulboone\/ticgit (push)   Now you can use the string pb on the command line in lieu of the whole URL. For example, if you want to fetch all the information that Paul has but that you don’t yet have in your repository, you can run git fetch pb :    $ git fetch pb remote: Counting objects: 43, done. remote: Compressing objects: 100% (36\/36), done. remote: Total 43 (delta 10), reused 31 (delta 5) Unpacking objects: 100% (43\/43), done. From https:\/\/github.com\/paulboone\/ticgit * [new branch] main -> pb\/main * [new branch] ticgit -> pb\/ticgit   Paul’s main branch is now accessible locally as pb\/main  — you can merge it into one of your branches, or you can check out a local branch at that point if you want to inspect it. We’ll go over what branches are and how to use them in much more detail in the next subsection on Git Branching.     Fetching and Pulling from Your Remotes   As you just saw, to get data from your remote projects, you can run:    $ git fetch <remote>   The command goes out to that remote project and pulls down all the data from that remote project that you don’t have yet. After you do this, you should have references to all the branches from that remote, which you can merge in or inspect at any time.   If you clone a repository, the command automatically adds that remote repository under the name “origin”. So, git fetch origin fetches any new work that has been pushed to that server since you cloned (or last fetched from) it. It’s important to note that the git fetch command only downloads the data to your local repository — it doesn’t automatically merge it with any of your work or modify what you’re currently working on. You have to merge it manually into your work when you’re ready.   If your current branch is set up to track a remote branch (see the next section on Git Branching for more information), you can use the git pull command to automatically fetch and then merge that remote branch into your current branch. This may be an easier or more comfortable workflow for you; and by default, the git clone command automatically sets up your local main branch to track the remote main branch (or whatever the default branch is called) on the server you cloned from. Running git pull generally fetches data from the server you originally cloned from and automatically tries to merge it into the code you’re currently working on.  Note: From git version 2.27 onward, git pull will give a warning if the pull.rebase variable is not set. Git will keep warning you until you set the variable.   If you want the default behavior of git (fast-forward if possible, else create a merge commit): git config --global pull.rebase \"false\"    If you want to rebase when pulling: git config --global pull.rebase \"true\"      Pushing to Your Remotes   When you have your project at a point that you want to share, you have to push it upstream. The command for this is simple: git push <remote> <branch> . If you want to push your main branch to your origin server (again, cloning generally sets up both of those names for you automatically), then you can run this to push any commits you’ve done back up to the server:    $ git push origin main   This command works only if you cloned from a server to which you have write access and if nobody has pushed in the meantime. If you and someone else clone at the same time and they push upstream and then you push upstream, your push will rightly be rejected. You’ll have to fetch their work first and incorporate it into yours before you’ll be allowed to push. See the next section on Git Branching for more detailed information on how to push to remote servers.      Section Summary  At this point, you can do all the basic local Git operations — creating or cloning a repository, making changes, staging and committing those changes, and viewing the history of all the changes the repository has been through. Next, we’ll cover Git’s killer feature: its branching model.   "
},
{
  "id": "git-lifecycle",
  "level": "2",
  "url": "sec_git_basics.html#git-lifecycle",
  "type": "Figure",
  "number": "5.3.1",
  "title": "",
  "body": " The lifecycle of the status of your files   "
},
{
  "id": "sec_git_branching",
  "level": "1",
  "url": "sec_git_branching.html",
  "type": "Section",
  "number": "5.4",
  "title": "Git Branching",
  "body": " Git Branching   Nearly every VCS has some form of branching support. Branching means you diverge from the main line of development and continue to do work without messing with that main line. In many VCS tools, this is a somewhat expensive process, often requiring you to create a new copy of your source code directory, which can take a long time for large projects.  Some people refer to Git’s branching model as its “killer feature,” and it certainly sets Git apart in the VCS community. Why is it so special? The way Git branches is incredibly lightweight, making branching operations nearly instantaneous, and switching back and forth between branches generally just as fast. Unlike many other VCSs, Git encourages workflows that branch and merge often, even multiple times in a day. Understanding and mastering this feature gives you a powerful and unique tool and can entirely change the way that you develop.    Branches in a Nutshell   To really understand the way Git does branching, we need to take a step back and examine how Git stores its data.   As you may remember from , Git doesn’t store data as a series of changesets or differences, but instead as a series of snapshots .   When you make a commit, Git stores a commit object that contains a pointer to the snapshot of the content you staged. This object also contains the author’s name and email address, the message that you typed, and pointers to the commit or commits that directly came before this commit (its parent or parents): zero parents for the initial commit, one parent for a normal commit, and multiple parents for a commit that results from a merge of two or more branches.   To visualize this, let’s assume that you have a directory containing three files, and you stage them all and commit. Staging the files computes a checksum for each one (the SHA-1 hash we mentioned in , , stores that version of the file in the Git repository (Git refers to them as blobs ), and adds that checksum to the staging area:    $ git add README test.rb LICENSE $ git commit -m 'Initial commit'   When you create the commit by running git commit , Git checksums each subdirectory (in this case, just the root project directory) and stores them as a tree object in the Git repository. Git then creates a commit object that has the metadata and a pointer to the root project tree so it can re-create that snapshot when needed.   Your Git repository now contains five objects: three blobs (each representing the contents of one of the three files), one tree that lists the contents of the directory and specifies which file names are stored as which blobs, and one commit with the pointer to that root tree and all the commit metadata.     A commit and its tree     If you make some changes and commit again, the next commit stores a pointer to the commit that came immediately before it.   Commits and their parents    A branch in Git is simply a lightweight movable pointer to one of these commits. The initial branch name (which is also by default the default branch) in Git was master until more recent versions of Git when it became main . As you start making commits, you’re given a main branch that points to the last commit you made. Every time you commit, the main branch pointer moves forward automatically.  Note: The “master” or \"main\" branch in Git is not a special branch. It is exactly like any other branch. The only reason nearly every repository has one or the other is that the git init command creates one by default and most people don’t bother to change its name. However, Git 2.28.0, released in July 2020, introduced the init.defaultBranch configuration option, which allows Git users to define and configure a default branch name other than the one chosen by Git.  Note: For the rest of this chapter, we will use both \"main\" and \"master\" interchangably because open-source contributors are likely to see one or the other, but not both, depending at least partially on the age of the project.     A branch and its commit history       Creating a New Branch   What happens when you create a new branch? Well, doing so creates a new pointer for you to move around. Let’s say you want to create a new branch called testing . You do this with the git branch command:    $ git branch testing   This creates a new pointer to the same commit you’re currently on.     Two branches pointing into the same series of commits     How does Git know what branch you’re currently on? It keeps a special pointer called HEAD . Note that this is a lot different than the concept of HEAD in other VCSs you may be used to, such as Subversion or CVS. In Git, this is a pointer to the local branch you’re currently on. In this case, you’re still on master . The git branch command only created a new branch — it didn’t switch to that branch.     HEAD pointing to a branch     You can easily see this by running a simple git log command that shows you where the branch pointers are pointing. This option is called --decorate .    $ git log --oneline --decorate f30ab (HEAD -> master, testing) Add feature #32 - ability to add new formats to the central interface 34ac2 Fix bug #1328 - stack overflow under certain conditions 98ca9 Initial commit   You can see the master and testing branches that are right there next to the f30ab commit.     Switching Branches   To switch to an existing branch, you run the git checkout command. Let’s switch to the new testing branch:    $ git checkout testing   This moves HEAD to point to the testing branch.     HEAD points to the current branch        What is the significance of that? Well, let’s do another commit:    $ vim test.rb $ git commit -a -m 'made a change'     The HEAD branch moves forward when a commit is made      This is interesting, because now your testing branch has moved forward, but your master branch still points to the commit you were on when you ran git checkout to switch branches. Let’s switch back to the master branch:    $ git checkout master Note that git log doesn’t show all the branches all the time   If you were to run git log right now, you might wonder where the \"testing\" branch you just created went, as it would not appear in the output.   The branch hasn’t disappeared; Git just doesn’t know that you’re interested in that branch and it is trying to show you what it thinks you’re interested in. In other words, by default, git log will only show commit history below the branch you’ve checked out.   To show commit history for the desired branch you have to explicitly specify it: git log testing . To show all of the branches, add --all to your git log command.     HEAD moves when you checkout     That command did two things. It moved the HEAD pointer back to point to the master branch, and it reverted the files in your working directory back to the snapshot that master points to. This also means the changes you make from this point forward will diverge from an older version of the project. It essentially rewinds the work you’ve done in your testing branch so you can go in a different direction.  Note: Switching branches changes files in your working directory    It’s important to note that when you switch branches in Git, files in your working directory will change. If you switch to an older branch, your working directory will be reverted to look like it did the last time you committed on that branch. If Git cannot do it cleanly, it will not let you switch at all.   Let’s make a few changes and commit again:    $ vim test.rb $ git commit -a -m 'made other changes'   Now your project history has diverged. You created and switched to a branch, did some work on it, and then switched back to your main branch and did other work. Both of those changes are isolated in separate branches: you can switch back and forth between the branches and merge them together when you’re ready. And you did all that with simple branch , checkout , and commit commands.     Divergent history    You can also see this easily with the git log command. If you run git log --oneline --decorate --graph --all it will print out the history of your commits, showing where your branch pointers are and how your history has diverged.    $ git log --oneline --decorate --graph --all * c2b9e (HEAD, master) Made other changes | * 87ab2 (testing) Made a change |\/ * f30ab Add feature #32 - ability to add new formats to the central interface * 34ac2 Fix bug #1328 - stack overflow under certain conditions * 98ca9 initial commit of my project   Because a branch in Git is actually a simple file that contains the 40 character SHA-1 checksum of the commit it points to, branches are cheap to create and destroy. Creating a new branch is as quick and simple as writing 41 bytes to a file (40 characters and a newline).   This is in sharp contrast to the way most older VCS tools branch, which involves copying all of the project’s files into a second directory. This can take several seconds or even minutes, depending on the size of the project, whereas in Git the process is always instantaneous. Also, because we’re recording the parents when we commit, finding a proper merge base for merging is automatically done for us and is generally very easy to do. These features help encourage developers to create and use branches often.   Let’s see why you should do so.  Note: Creating a new branch and switching to it at the same time. It’s typical to create a new branch and want to switch to that new branch at the same time — this can be done in one operation with git checkout -b <newbranchname> .  Note: From Git version 2.23 onwards you can use git switch instead of git checkout to:     Switch to an existing branch: git switch testing-branch .    Create a new branch and switch to it: git switch -c new-branch . The -c flag stands for create, you can also use the full flag: --create .    Return to your previously checked out branch: git switch - .     Learning Git Branching For a superb interactive tutorial on Git branching, go to Learn Git Branching and try at least the four tutorials in the interactive sequence. Then blog about what you learned.    Section Summary  We’ve covered basic branching and merging in Git. You should feel comfortable creating and switching to new branches, switching between branches and merging local branches together. You should also be able to share your branches by pushing them to a shared server, working with others on shared branches and rebasing your branches before they are shared. Next, we’ll cover what you’ll need to run your own Git repository-hosting server.   "
},
{
  "id": "git-commit-tree",
  "level": "2",
  "url": "sec_git_branching.html#git-commit-tree",
  "type": "Figure",
  "number": "5.4.1",
  "title": "",
  "body": " A commit and its tree   "
},
{
  "id": "git-commit-parents",
  "level": "2",
  "url": "sec_git_branching.html#git-commit-parents",
  "type": "Figure",
  "number": "5.4.2",
  "title": "",
  "body": " Commits and their parents   "
},
{
  "id": "git-branch-and-commit-hostory",
  "level": "2",
  "url": "sec_git_branching.html#git-branch-and-commit-hostory",
  "type": "Figure",
  "number": "5.4.3",
  "title": "",
  "body": " A branch and its commit history   "
},
{
  "id": "git-two-branches",
  "level": "2",
  "url": "sec_git_branching.html#git-two-branches",
  "type": "Figure",
  "number": "5.4.4",
  "title": "",
  "body": " Two branches pointing into the same series of commits   "
},
{
  "id": "git-HEAD-branch",
  "level": "2",
  "url": "sec_git_branching.html#git-HEAD-branch",
  "type": "Figure",
  "number": "5.4.5",
  "title": "",
  "body": " HEAD pointing to a branch   "
},
{
  "id": "git-HEAD-current-branch",
  "level": "2",
  "url": "sec_git_branching.html#git-HEAD-current-branch",
  "type": "Figure",
  "number": "5.4.6",
  "title": "",
  "body": " HEAD points to the current branch   "
},
{
  "id": "git-HEAD-moves",
  "level": "2",
  "url": "sec_git_branching.html#git-HEAD-moves",
  "type": "Figure",
  "number": "5.4.7",
  "title": "",
  "body": " The HEAD branch moves forward when a commit is made   "
},
{
  "id": "git-HEAD-moves-checkout",
  "level": "2",
  "url": "sec_git_branching.html#git-HEAD-moves-checkout",
  "type": "Figure",
  "number": "5.4.8",
  "title": "",
  "body": " HEAD moves when you checkout   "
},
{
  "id": "git-divergent-history",
  "level": "2",
  "url": "sec_git_branching.html#git-divergent-history",
  "type": "Figure",
  "number": "5.4.9",
  "title": "",
  "body": " Divergent history   "
},
{
  "id": "exercise-13",
  "level": "2",
  "url": "sec_git_branching.html#exercise-13",
  "type": "Checkpoint",
  "number": "5.4.10",
  "title": "Learning Git Branching.",
  "body": "Learning Git Branching For a superb interactive tutorial on Git branching, go to Learn Git Branching and try at least the four tutorials in the interactive sequence. Then blog about what you learned. "
},
{
  "id": "sec_git_undoing",
  "level": "1",
  "url": "sec_git_undoing.html",
  "type": "Section",
  "number": "5.5",
  "title": "\"Undoing\" in Git",
  "body": " \"Undoing\" in Git   At any stage, you may want to undo something. Here, we’ll review a few tools for undoing changes that you’ve made. Be careful though. This is one of the areas in Git where you may lose some work if you do it wrong, because you can’t always undo some of these undos.    Undoing Changes   One of the common undos takes place when you commit too early and possibly forget to add some files, or you mess up your commit message. If you want to redo that commit, make the additional changes you forgot, stage them, and commit again using the --amend option:    $ git commit --amend   This command takes your staging area and uses it for the commit. If you’ve made no changes since your last commit (for instance, you run this command immediately after your previous commit), then your snapshot will look exactly the same, and all you’ll change is your commit message.   The same commit-message editor fires up, but it already contains the message of your previous commit. You can edit the message the same as always, but it overwrites your previous commit.   As an example, if you commit and then realize you forgot to stage the changes in a file you wanted to add to this commit, you can do something like this:    $ git commit -m 'Initial commit' $ git add forgotten_file $ git commit --amend   You end up with a single commit — the second commit replaces the results of the first.  Note: It’s important to understand that when you’re amending your last commit, you’re not so much fixing it as replacing it entirely with a new, improved commit that pushes the old commit out of the way and puts the new commit in its place. Effectively, it’s as if the previous commit never happened, and it won’t show up in your repository history.  The obvious value to amending commits is to make minor improvements to your last commit, without cluttering your repository history with commit messages of the form, “Oops, forgot to add a file” or “Darn, fixing a typo in last commit”.  Note: Only amend commits that are still local and have not been pushed somewhere. Amending previously pushed commits and force pushing the branch will cause problems for your collaborators.     Unstaging a Staged File   The next two sections demonstrate how to work with your staging area and working directory changes. The nice part is that the command you use to determine the state of those two areas also reminds you how to undo changes to them. For example, let’s say you’ve changed two files and want to commit them as two separate changes, but you accidentally type git add * and stage them both. How can you unstage one of the two? The git status command reminds you:    $ git add * $ git status On branch main Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) renamed: README.md -> README modified: CONTRIBUTING.md   Right below the “Changes to be committed” text, it says use git reset HEAD <file>…​ to unstage. So, let’s use that advice to unstage the CONTRIBUTING.md file:    $ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) renamed: README.md -> README Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   The command is a bit strange, but it works. The CONTRIBUTING.md file is modified but once again unstaged.  Note: It’s true that git reset can be a dangerous command, especially if you provide the --hard flag. However, in the scenario described above, the file in your working directory is not touched, so it’s relatively safe.   For now this magic invocation is all you need to know about the git reset command.     Unmodifying a Modified File   What if you realize that you don’t want to keep your changes to the CONTRIBUTING.md file? How can you easily unmodify it — revert it back to what it looked like when you last committed (or initially cloned, or however you got it into your working directory)? Luckily, git status tells you how to do that, too. In the last example output, the unstaged area looks like this:    Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   It tells you pretty explicitly how to discard the changes you’ve made. Let’s do what it says:    $ git checkout -- CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \"git reset HEAD <file>...\" to unstage) renamed: README.md -> README   You can see that the changes have been reverted.  Important: It’s important to understand that git checkout -- <file> is a dangerous command. Any local changes you made to that file are gone — Git just replaced that file with the last staged or committed version. Don’t ever use this command unless you absolutely know that you don’t want those unsaved local changes.   If you would like to keep the changes you’ve made to that file but still need to get it out of the way for now, we’ll go over stashing and branching in the following section on Git Branching; these are generally better ways to go.   Remember, anything that is committed in Git can almost always be recovered. Even commits that were on branches that were deleted or commits that were overwritten with an --amend commit can be recovered. However, anything you lose that was never committed is likely never to be seen again.     Undoing things with git restore   Git version 2.23.0 introduced a new command: git restore . It’s basically an alternative to git reset which we just covered. From Git version 2.23.0 onwards, Git will use git restore instead of git reset for many undo operations.   Let’s retrace our steps, and undo things with git restore instead of git reset .     Unstaging a Staged File with git restore   The next two sections demonstrate how to work with your staging area and working directory changes with git restore . The nice part is that the command you use to determine the state of those two areas also reminds you how to undo changes to them. For example, let’s say you’ve changed two files and want to commit them as two separate changes, but you accidentally type git add * and stage them both. How can you unstage one of the two? The git status command reminds you:    $ git add * $ git status On branch main Changes to be committed: (use \"git restore --staged <file>...\" to unstage) modified: CONTRIBUTING.md renamed: README.md -> README   Right below the “Changes to be committed” text, it says use git restore --staged <file>…​ to unstage. So, let’s use that advice to unstage the CONTRIBUTING.md file:    $ git restore --staged CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \"git restore --staged <file>...\" to unstage) renamed: README.md -> README Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git restore <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   The CONTRIBUTING.md file is modified but once again unstaged.     Unmodifying a Modified File with git restore   What if you realize that you don’t want to keep your changes to the CONTRIBUTING.md file? How can you easily unmodify it — revert it back to what it looked like when you last committed (or initially cloned, or however you got it into your working directory)? Luckily, git status tells you how to do that, too. In the last example output, the unstaged area looks like this:    Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git restore <file>...\" to discard changes in working directory) modified: CONTRIBUTING.md   It tells you pretty explicitly how to discard the changes you’ve made. Let’s do what it says:    $ git restore CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \"git restore --staged <file>...\" to unstage) renamed: README.md -> README  Important: It’s important to understand that git restore <file> is a dangerous command. Any local changes you made to that file are gone — Git just replaced that file with the last staged or committed version. Don’t ever use this command unless you absolutely know that you don’t want those unsaved local changes.  Read External Git Undoing Summary For a humorous summary of undoing in Git, go to Oh Shit, Git!?!      Section Summary  As you have learned from this section, Git provides several tools for undoing changes that you have made. One of the most common undos is when you commit too early and forget to add some files, or you mess up your commit message or if you accidentally stage a file that you didn't mean to. However, it's important to be careful when using these commands because you can't always undo some of these undos.   "
},
{
  "id": "ex_git_oh_shit_git",
  "level": "2",
  "url": "sec_git_undoing.html#ex_git_oh_shit_git",
  "type": "Checkpoint",
  "number": "5.5.1",
  "title": "Read External Git Undoing Summary.",
  "body": "Read External Git Undoing Summary For a humorous summary of undoing in Git, go to Oh Shit, Git!?!  "
},
{
  "id": "sec_git_github",
  "level": "1",
  "url": "sec_git_github.html",
  "type": "Section",
  "number": "5.6",
  "title": "GitHub - Git in the Cloud",
  "body": " GitHub - Git in the Cloud    The most popular SECPs include GitHub , Gitea , GitLab , and Bitbucket . All of these use Git for version control and all provide cloud storage space for Git repositories. Of these, GitHub is the single largest host for Git repositories and is the central point of collaboration for millions of developers and projects. A large percentage of all Git repositories are hosted on GitHub, and many open-source projects use it for Git hosting, issue tracking, code review, and other things. So while it’s not a direct part of the Git open source project, there’s a good chance that you’ll want or need to interact with GitHub at some point while using Git professionally. Other hosting services work similarly.  Watch the following video from Github to learn more.   What is Github?    Obviously, the first thing you need to do is set up a free user account. If you do not already have one, simply visit https:\/\/github.com and follow the directions.     Contributing to a Project   Next, let’s walk through some details that could be useful in helping you contribute to an existing open source project.    Forking Projects   If you want to contribute to an existing project to which you don’t have write access (aka push access), you can fork the project. When you “fork” a project, GitHub will make a copy of the project that is entirely yours; it lives in your namespace, and you can push to it.   In GitHub, a “fork” is simply a copy of the project in your own namespace, allowing you to make changes to a project publicly as a way to contribute in an open manner. Note: Historically, the term “fork” has sometimes had a negative connotation if it meant that someone took an open source project in a different direction, creating a competing project and splitting the contributors.   This way, projects don’t have to worry about adding users as collaborators to give them push access. People can fork a project, push to it, and contribute their changes back to the original repository by creating a merge request which in GitHub is called a pull request . We’ll cover this next. Making a pull request opens up a discussion thread with code review, and the owner and the contributor can then communicate about the change until the owner is happy with it, at which point the owner can merge it in.   To fork a project, visit the project page and click the “Fork” button at the top-right of the page. This gives you a copy of the project in the Github cloud.  Once you have your own fork on Github, you need to clone a local copy down to a place where you can edit it, most typically your own local computer. Note that while you can make small changes in Github, it is not a good practice to do so.   Let's try this!  Exercise – Fork a Repo Go to Github: Fork a Repo and complete the provided exercise with the octocat\/Spoon-Knife repository.     The GitHub Flow   GitHub is designed around a particular collaboration workflow, centered on pull requests and idea of a branches as covered in .. This flow works whether you’re collaborating with a tightly-knit team in a single shared repository, or a globally-distributed company or network of strangers contributing to a project through dozens of forks.   After you read the project's README contributor's page and get a sense of the community norms, here’s how the Git workflow generally works:     Fork the project.    Create your own topic branch from main (or master or another branch name, depending upon the project).    Make some commits to improve the project, being sure to follow community expectations, such as linking the issue that you are fixing.    Push this branch to your GitHub fork.    Open a Pull Request on GitHub.    Discuss, and optionally continue committing.    Hopefully, the project owner eventually merges or closes the Pull Request.    Sync the updated main (or master) back to your fork.     Let’s walk through an example of proposing a change to an open source project hosted on GitHub using this flow.  Exercise – Github Flow Go to Github Flow and complete the provided exercise with one of your own repositories.   Creating a Pull Request  You can always go to the “Branches” page at https:\/\/github.com\/<user>\/<project>\/branches to locate your branch and open a new Pull Request from there.   You can also see a list of the commits in our topic branch that are “ahead” of the main or master branch (in this case, just the one) and a unified diff of all the changes that will be made should this branch get merged by the project owner.   When you hit the 'Create pull request' button on this screen, the owner of the project you forked will get a notification that someone is suggesting a change and will link to a page that has all of this information on it.   Note: Though Pull Requests are used commonly for public projects when the contributor has a complete change ready to be made, it’s also often used in internal projects at the beginning of the development cycle. Since you can keep pushing to the topic branch even after the Pull Request is opened, it’s often opened early and used as a way to iterate on work as a team within a context, rather than opened at the very end of the process.  Let's give this a try!  Introduction to Github Introduction to Github     Iterating on a Pull Request   At this point, the project owner can look at the suggested change and merge it, reject it or comment on it. Let’s say that he likes the idea, but would prefer a slightly longer time for the light to be off than on.   Where this conversation may take place over email in the workflows presented in Distributed Git , on GitHub this happens online. The project owner can review the unified diff and leave a comment by clicking on any of the lines.   Once the maintainer makes a comment, the person who opened the Pull Request (and indeed, anyone else watching the repository) will get a notification.     Note that anyone can also leave general comments on the Pull Request.   Now the contributor can see what they need to do in order to get their change accepted. Luckily this is very straightforward. With GitHub you simply commit to the same topic branch again and push, which will automatically update the Pull Request.   Adding commits to an existing Pull Request doesn’t trigger a notification, so once you push corrections you might want to to leave a comment to inform the project owner that you made the requested change.   An interesting thing to notice is that if you click on the “Files Changed” tab on any Pull Request, you’ll get a “unified” diff — that is, the total aggregate difference that would be introduced the main branch if this topic branch was merged in. In git diff terms, it basically automatically shows you git diff main<branch> for the branch this Pull Request is based on.   GitHub always checks to see if the Pull Request merges cleanly and provides a button to do the merge for you on the server. This button only shows up if you have write access to the repository and a trivial merge is possible. If you click it GitHub will perform a “non-fast-forward” merge, meaning that even if the merge could be a fast-forward, it will still create a merge commit.   If you prefer, you can simply pull the branch down and merge it locally. If you merge this branch into the main branch and push it to GitHub, the Pull Request will automatically be closed.   This is the basic workflow that most GitHub projects use. Topic branches are created, Pull Requests are opened on them, a discussion ensues, possibly more work is done on the branch and eventually the request is either closed or merged.   Note: It’s important to note that you can also open a Pull Request between two branches in the same repository. If you’re working on a feature with someone and you both have write access to the project, you can push a topic branch to the repository and open a Pull Request on it to the main branch of that same project to initiate the code review and discussion process. No forking necessary.      Advanced Pull Requests   Now that we’ve covered the basics of contributing to a project on GitHub, let’s cover a few interesting tips and tricks about Pull Requests so you can be more effective in using them.    Pull Requests as Patches   It’s important to understand that many projects don’t really think of Pull Requests as queues of perfect patches that should apply cleanly in order, as most mailing list-based projects think of patch series contributions. Most GitHub projects think about Pull Request branches as iterative conversations around a proposed change, culminating in a unified diff that is applied by merging.   This is an important distinction, because generally the change is suggested before the code is thought to be perfect. This depends wholely on the community. In communities where it is used, it enables an earlier conversation with the maintainers so that arriving at the proper solution is more of a community effort. When code is proposed with a Pull Request and the maintainers or community suggest a change, the patch series is generally not re-rolled, but instead the difference is pushed as a new commit to the branch, moving the conversation forward with the context of the previous work intact.   This way if you go back and look at this Pull Request in the future, you can easily find all of the context of why decisions were made. Pushing the “Merge” button on the site purposefully creates a merge commit that references the Pull Request so that it’s easy to go back and research the original conversation if necessary.     Keeping up with Upstream   If your Pull Request becomes out of date or otherwise doesn’t merge cleanly, you will want to fix it so the maintainer can easily merge it. GitHub will test this for you and let you know at the bottom of every Pull Request if the merge is trivial or not.   If your Pull Request does not merge cleanly you’ll want to fix your branch so that it turns green.   You have two main options in order to do this. You can either rebase your branch on top of whatever the target branch is (normally the main branch of the repository you forked), or you can merge the target branch into your branch.   Most developers on GitHub will choose to do the latter, for the same reasons we just went over in the previous section. What matters is the history and the final merge, so rebasing isn’t getting you much other than a slightly cleaner history and in return is far more difficult and error prone.   If you want to merge in the target branch to make your Pull Request mergeable, you would add the original repository as a new remote, fetch from it, merge the main branch of that repository into your topic branch, fix any issues and finally push it back up to the same branch you opened the Pull Request on.     Add the original repository as a remote named upstream .    Fetch the newest work from that remote.    Merge the main branch of that repository into your topic branch.    Fix the conflict that occurred.    Push back up to the same topic branch.     Once you do that, the Pull Request will be automatically updated and re-checked to see if it merges cleanly.   One of the great things about Git is that you can do that continuously. If you have a very long-running project, you can easily merge from the target branch over and over again and only have to deal with conflicts that have arisen since the last time that you merged, making the process very manageable.   If you absolutely wish to rebase the branch to clean it up, you can certainly do so, but it is highly encouraged to not force push over the branch that the Pull Request is already opened on. If other people have pulled it down and done more work on it, you will run into major problems! Instead, push the rebased branch to a new branch on GitHub and open a brand new Pull Request referencing the old one, then close the original.     References   Your next question may be “How do I reference the old Pull Request?”. It turns out there are many, many ways to reference other things almost anywhere you can write in GitHub.   Let’s start with how to cross-reference another Pull Request or an Issue. All Pull Requests and Issues are assigned numbers and they are unique within the project. For example, you can’t have Pull Request #3 and Issue #3. If you want to reference any Pull Request or Issue from any other one, you can simply put #<num> in any comment or description. You can also be more specific if the Issue or Pull request lives somewhere else; write username#<num> if you’re referring to an Issue or Pull Request in a fork of the repository you’re in, or username\/repo#<num> to reference something in another repository.   In addition to issue numbers, you can also reference a specific commit by SHA-1. You have to specify a full 40 character SHA-1, but if GitHub sees that in a comment, it will link directly to the commit. Again, you can reference commits in forks or other repositories in the same way you did with issues.      GitHub Flavored Markdown   Linking to other Issues is just the beginning of interesting things you can do with almost any text box on GitHub. In Issue and Pull Request descriptions, comments, code comments and more, you can use what is called “GitHub Flavored Markdown”. Markdown is like writing in plain text but which is rendered richly.   The GitHub flavor of Markdown adds more things you can do beyond the basic Markdown syntax. These can all be really useful when creating useful Pull Request or Issue comments or descriptions.    Task Lists   A useful GitHub specific Markdown feature, especially for use in Pull Requests, is the Task List . A task list is a list of checkboxes of things you want to get done. Putting them into an Issue or Pull Request normally indicates things that you want to get done before you consider the item complete.   These are often used in Pull Requests to indicate what all you would like to get done on the branch before the Pull Request will be ready to merge. The really cool part is that you can simply click the checkboxes to update the comment — you don’t have to edit the Markdown directly to check tasks off.   What’s more, GitHub will look for task lists in your Issues and Pull Requests and show them as metadata on the pages that list them out. For example, if you have a Pull Request with tasks and you look at the overview page of all Pull Requests, you can see how far done it is. This helps people break down Pull Requests into subtasks and helps other people track the progress of the branch.   These are incredibly useful when you open a Pull Request early and use it to track your progress through the implementation of the feature.     Code Snippets   You can also add code snippets to comments. This is especially useful if you want to present something that you could try to do before actually implementing it as a commit on your branch. This is also often used to add example code of what is not working or what this Pull Request could implement.   To add a snippet of code you have to “fence” it in backticks.    ```java for(int i=0 ; i < 5 ; i++) { System.out.println(\"i is : \" + i); } ```   If you add a language name like we did there with 'java', GitHub will also try to syntax highlight the snippet. In the case of the above example, it would end up rendering like Rendered fenced code example .     Quoting   If you’re responding to a small part of a long comment, you can selectively quote out of the other comment by preceding the lines with the > character. In fact, this is so common and so useful that there is a keyboard shortcut for it. If you highlight text in a comment that you want to directly reply to and hit the r key, it will quote that text in the comment box for you.   The quotes look something like this:    > Whether 'tis Nobler in the mind to suffer > The Slings and Arrows of outrageous Fortune, How big are these slings and in particular, these arrows?      Keep your GitHub public repository up-to-date   Once you’ve forked a GitHub repository, your repository (your \"fork\") exists independently from the original. In particular, when the original repository has new commits, GitHub informs you by a message like:    This branch is 5 commits behind progit:main.   But your GitHub repository will never be automatically updated by GitHub; this is something that you must do yourself. Fortunately, this is very easy to do.      Maintaining a Project   Now that we’re comfortable contributing to a project, let’s look at the other side: creating, maintaining and administering your own project.    Creating a New Repository   Let’s create a new repository to share our project code with. Start by clicking the “New repository” button on the right-hand side of the dashboard, or from the + button in the top toolbar next to your username as seen in The “New repository” dropdown .   All you really have to do here is provide a project name; the rest of the fields are completely optional. For now, just click the “Create Repository” button, and boom – you have a new repository on GitHub, named <user>\/<project_name> .   Since you have no code there yet, GitHub will show you instructions for how to create a brand-new Git repository, or connect an existing Git project. We won’t belabor this here; if you need a refresher, check out Git Basics .   Now that your project is hosted on GitHub, you can give the URL to anyone you want to share your project with. Every project on GitHub is accessible over HTTPS as https:\/\/github.com\/<user>\/<project_name> , and over SSH as git@github.com:<user>\/<project_name> . Git can fetch from and push to both of these URLs, but they are access-controlled based on the credentials of the user connecting to them.   Note: It is often preferable to share the HTTPS based URL for a public project, since the user does not have to have a GitHub account to access it for cloning. Users will have to have an account and an uploaded SSH key to access your project if you give them the SSH URL. The HTTPS one is also exactly the same URL they would paste into a browser to view the project there.     Adding Collaborators   If you’re working with other people who you want to give commit access to, you need to add them as “collaborators”. If Ben, Jeff, and Louise all sign up for accounts on GitHub, and you want to give them push access to your repository, you can add them to your project. Doing so will give them “push” access, which means they have both read and write access to the project and Git repository.   Click the “Settings” link at the bottom of the right-hand sidebar.  Then select “Collaborators” from the menu on the left-hand side. Then, just type a username into the box, and click “Add collaborator.” You can repeat this as many times as you like to grant access to everyone you like. If you need to revoke access, just click the “X” on the right-hand side of their row.     Managing Pull Requests   Now that you have a project with some code in it and maybe even a few collaborators who also have push access, let’s go over what to do when you get a Pull Request yourself.   Pull Requests can either come from a branch in a fork of your repository or they can come from another branch in the same repository. The only difference is that the ones in a fork are often from people where you can’t push to their branch and they can’t push to yours, whereas with internal Pull Requests generally both parties can access the branch.    Email Notifications   Someone comes along and makes a change to your code and sends you a Pull Request. You should get an email notifying you about the new Pull Request.   There are a few things to notice about this email. It will give you a small diffstat — a list of files that have changed in the Pull Request and by how much. It gives you a link to the Pull Request on GitHub. It also gives you a few URLs that you can use from the command line. gblock\">-->     Collaborating on the Pull Request   As we covered above, you can now have a conversation with the person who opened the Pull Request. You can comment on specific lines of code, comment on whole commits or comment on the entire Pull Request itself, using GitHub Flavored Markdown everywhere.   Every time someone else comments on the Pull Request you will continue to get email notifications so you know there is activity happening. They will each have a link to the Pull Request where the activity is happening and you can also directly respond to the email to comment on the Pull Request thread.  Once the code is in a place you like and want to merge it in, you can either pull the code down and merge it locally, either with the git pull <url> <branch> syntax we saw earlier, or by adding the fork as a remote and fetching and merging.   If the merge is trivial, you can also just hit the “Merge” button on the GitHub site. This will do a “non-fast-forward” merge, creating a merge commit even if a fast-forward merge was possible. This means that no matter what, every time you hit the merge button, a merge commit is created. As you can see in Merge button and instructions for merging a Pull Request manually , GitHub gives you all of this information if you click the hint link.   If you decide you don’t want to merge it, you can also just close the Pull Request and the person who opened it will be notified.     Pull Requests on Pull Requests   Not only can you open Pull Requests that target the main or main branch, you can actually open a Pull Request targeting any branch in the network. In fact, you can even target another Pull Request.   If you see a Pull Request that is moving in the right direction and you have an idea for a change that depends on it or you’re not sure is a good idea, or you just don’t have push access to the target branch, you can open a Pull Request directly to it.   When you go to open a Pull Request, there is a box at the top of the page that specifies which branch you’re requesting to pull to and which you’re requesting to pull from. If you hit the “Edit” button at the right of that box you can change not only the branches but also which fork.      Mentions and Notifications   GitHub also has a pretty nice notifications system built in that can come in handy when you have questions or need feedback from specific individuals or teams.   In any comment you can start typing a @ character and it will begin to autocomplete with the names and usernames of people who are collaborators or contributors in the project.   You can also mention a user who is not in that dropdown, but often the autocompleter can make it faster.   Once you post a comment with a user mention, that user will be notified. This means that this can be a really effective way of pulling people into conversations rather than making them poll. Very often in Pull Requests on GitHub people will pull in other people on their teams or in their company to review an Issue or Pull Request.   If someone gets mentioned on a Pull Request or Issue, they will be “subscribed” to it and will continue getting notifications any time some activity occurs on it. You will also be subscribed to something if you opened it, if you’re watching the repository or if you comment on something. If you no longer wish to receive notifications, there is an “Unsubscribe” button on the page you can click to stop receiving updates on it.   The Notifications Page   When we mention “notifications” here with respect to GitHub, we mean a specific way that GitHub tries to get in touch with you when events happen and there are a few different ways you can configure them. If you go to the “Notification center” tab from the settings page, you can see some of the options you have.   The two choices are to get notifications over “Email” and over “Web” and you can choose either, neither or both for when you actively participate in things and for activity on repositories you are watching.    Web Notifications   Web notifications only exist on GitHub and you can only check them on GitHub. If you have this option selected in your preferences and a notification is triggered for you, you will see a small blue dot over your notifications icon at the top of your screen.   If you click on that, you will see a list of all the items you have been notified about, grouped by project. You can filter to the notifications of a specific project by clicking on its name in the left hand sidebar. You can also acknowledge the notification by clicking the checkmark icon next to any notification, or acknowledge all of the notifications in a project by clicking the checkmark at the top of the group. There is also a mute button next to each checkmark that you can click to not receive any further notifications on that item.   All of these tools are very useful for handling large numbers of notifications. Many GitHub power users will simply turn off email notifications entirely and manage all of their notifications through this screen.    Email Notifications   Email notifications are the other way you can handle notifications through GitHub. If you have this turned on you will get emails for each notification. The emails will also be threaded properly, which is nice if you’re using a threading email client.   There is also a fair amount of metadata embedded in the headers of the emails that GitHub sends you, which can be really helpful for setting up custom filters and rules.   There are a couple of interesting things here. If you want to highlight or re-route emails to this particular project or even Pull Request, the information in Message-ID gives you all the data in <user>\/<project>\/<type>\/<id> format. If this were an issue, for example, the <type> field would have been “issues” rather than “pull”.   The List-Post and List-Unsubscribe fields mean that if you have a mail client that understands those, you can easily post to the list or “Unsubscribe” from the thread. That would be essentially the same as clicking the “mute” button on the web version of the notification or “Unsubscribe” on the Issue or Pull Request page itself.   It’s also worth noting that if you have both email and web notifications enabled and you read the email version of the notification, the web version will be marked as read as well if you have images allowed in your mail client.        Special Files   There are a number of special files that GitHub will notice if they are present in your repository. We detail a few of the most common ones. Note that these can typically be written in any format that Github recognizes as prose.     LICENSE  The first is the LICENSE file, which can be of nearly any prose format. For example, it could be LICENSE, LICENSE.md, LICENSE.asciidoc, etc.  The license file explains the respostory's legal license, including any legal rights, any copyright restrictions, etc. When you include a detectable license in your repository, people who visit your repository will see it at the top of the repository page.  For more information on how to add a license, see Adding a license to a repository     README   The README file explains your project, what it does, why it is useful, etc. If GitHub detects a README file in your source, it will render it on the landing page of the project, so this file is often the first item a visitor will see when visiting your repository.   Many teams use this file to hold all the relevant project information for someone who might be new to the repository or project. This generally includes things like:     What the project is for    How to configure and install it    An example of how to use it or get it running    The license that the project is offered under    How to contribute to it     Since GitHub will render this file, you can embed images or links in it for added ease of understanding.     CODE_OF_CONDUCT  The CODE_OF_CONDUCT explains how one is expected to engage in that particular community. It is typically used to ensure an inclusive environment that respects all people and also typically describes how to address any problems among members of the project's community.    CONTRIBUTING   Another special file that GitHub recognizes is the CONTRIBUTING file. If you have a file named CONTRIBUTING with any file extension, GitHub will show Opening a Pull Request when a CONTRIBUTING file exists when anyone starts opening a Pull Request.     The idea here is that you can specify specific things you want or don’t want in a Pull Request sent to your project. This way people may actually read the guidelines before opening the Pull Request.     Project Administration   Generally there are not a lot of administrative things you can do with a single project, but there are a couple of items that might be of interest.    Changing the Default Branch   If you are using a branch other than “main” or “master” as your default branch that you want people to open Pull Requests on or see by default, you can change that in your repository’s settings page under the “Options” tab.   Simply change the default branch in the dropdown and that will be the default for all major operations from then on, including which branch is checked out by default when someone clones the repository.       Section Summary Now you’re a GitHub user. You know how to create an account, manage an organization, create and push to repositories, contribute to other people’s projects and accept contributions from others.  "
},
{
  "id": "video-what-is-github",
  "level": "2",
  "url": "sec_git_github.html#video-what-is-github",
  "type": "Figure",
  "number": "5.6.1",
  "title": "",
  "body": " What is Github?   "
},
{
  "id": "p-684",
  "level": "2",
  "url": "sec_git_github.html#p-684",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "fork "
},
{
  "id": "p-686",
  "level": "2",
  "url": "sec_git_github.html#p-686",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "pull request "
},
{
  "id": "p-688",
  "level": "2",
  "url": "sec_git_github.html#p-688",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "clone "
},
{
  "id": "exercise-github-forking",
  "level": "2",
  "url": "sec_git_github.html#exercise-github-forking",
  "type": "Checkpoint",
  "number": "5.6.2",
  "title": "<dfn class=\"terminology\">Exercise – Fork a Repo<\/dfn>.",
  "body": "Exercise – Fork a Repo Go to Github: Fork a Repo and complete the provided exercise with the octocat\/Spoon-Knife repository. "
},
{
  "id": "exercise-github-flow",
  "level": "2",
  "url": "sec_git_github.html#exercise-github-flow",
  "type": "Checkpoint",
  "number": "5.6.3",
  "title": "<dfn class=\"terminology\">Exercise – Github Flow<\/dfn>.",
  "body": "Exercise – Github Flow Go to Github Flow and complete the provided exercise with one of your own repositories. "
},
{
  "id": "p-707",
  "level": "2",
  "url": "sec_git_github.html#p-707",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "after "
},
{
  "id": "ex-intro-github",
  "level": "2",
  "url": "sec_git_github.html#ex-intro-github",
  "type": "Checkpoint",
  "number": "5.6.4",
  "title": "Introduction to Github.",
  "body": "Introduction to Github Introduction to Github "
},
{
  "id": "p-716",
  "level": "2",
  "url": "sec_git_github.html#p-716",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "could "
},
{
  "id": "p-727",
  "level": "2",
  "url": "sec_git_github.html#p-727",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "far "
},
{
  "id": "p-743",
  "level": "2",
  "url": "sec_git_github.html#p-743",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "task list "
},
{
  "id": "sec_docu_scope",
  "level": "1",
  "url": "sec_docu_scope.html",
  "type": "Section",
  "number": "6.1",
  "title": "Documentation Matters!",
  "body": " Documentation Matters!   Quality documentation is essential to open source communities because decisions and processes need to be communicated to a distributed team of developers as well as to future developers. In addition, even seasoned developers might write some complicated code, and if they come back to it six months later, even they might not easily remember why a particular change was made or understand precisely how it works without good documentation. But, these are just two of the many reasons documentation matters in open source.  Any time you want to understand why a page in Wikipedia is edited a certain way, the  history  and  discussion  buttons reveal a rich level of information and interaction that are the backbone of what makes it a useful and reliable source. Look at each of the following links that serve to document changes to the Wikipedia page on software documentation:   History of the Wikipedia page on ‘software documentation’    Discussion or talk page on ‘software documentation’    History of ‘Talk:Software_documentation’     In open source projects, documentation is essential. It is much more than developer documentation in code and README files.  Every technical effort has requirements for different types of documentation. The project’s ability to make writing, editing, and publishing as easy as possible is the main key to attracting and retaining contributors.  According to Mozilla, developer contributions to documentation greatly increased along with a new community of writers, editors, and translators. This all resulted from reducing the barriers to success that made even experienced developers too frustrated to document properly.  In open source communities documentation is a key tool. Documentation needs to exist to explain why decisions were made, how to get things running, how the code is organized and works, and what steps must be taken to contribute. You have to document everything that you do in a open source project, and this is not just with the code. Next year when you need to remember why a technical decision was made, the answer should be readily available in the documentation.    The Purpose of Documentation  What do you think of when you think of documentation in OSS? Do you think of the README or LICENSE or CODE_OF_CONDUCT or other files often found in the root of the main code repository? Do you think of source code documentation? Do you think of documentation made by documentation generators such as Doxygen, Javadoc, NDoc, or others? Do you think of tutorials or user manuals? Do you think of the list of open merge requests and related discussions for a project? Do you think of release notes or other documentation accompanying specific versions of the software? If you think of these, then you are on the right track, but documentation in a typical OSS project often includes even more.  Because many projects have widely distributed, volunteer developers and other contributors, documentation is key to keeping the project on course. Note that the specific documentation included in a project repository can vary widely depending on the project and its goals.  In addition to source code, each OSS project typically contains a set of specifically named documentation files. The following are often included:   README  Arguably the most important file in any open source project, the README file typically contains an overview of the project, instructions on how to get started, information on how to contribute, and many other pieces of information that are important to that particular OSS project.    CHANGELOG  Documenting changes to the project over time, the CHANGELOG usually includes a list of all releases and a summary of the changes that were made in each one.    CODE_OF_CONDUCT  Outlining the behavior expected of all contributors and users of the project, the CODE_OF_CONDUCT is intended to ensure that the project is welcoming and respectful to all. If you are interested in getting involved in an OSS project, be sure to read this file not only so you know how you should behave, but also so you know how you can expect to be treated.    CONTRIBUTING  If you are at all interested in getting involved in a new OSS project, the CONTRIBUTING file is key because it provides guidelines for contributors, including how to report bugs, how to submit proposed code changes, and how to get help.    FAQ  As is typical outside of OSS, FAQ provides answers to frequently asked questions about the project.    INSTALL  Containing instructions on how to install and set up the project, note that the INSTALL files is often not the same as how to set up the development environment to contribute to the project.    LICENSE  As explained in , the LICENSE file specifies the terms under which the project is licensed. It outlines what others are and are not allowed to do with the code.    TUTORIALS  The TUTORIALS file contains or links to tutorials or guides that help users understand how to use the project.    ROADMAP  Outlining the project's plans for future releases, the ROADMAP is useful to new contributors to understand the direction of the project.     Some types of documentation utilize a particular structure often provided by the repository platform. We have discussed some of these earlier. Some very common kinds of documentation of this type are:   Automation of Builds and Publishing  While not used in all projects, larger OSS projects typically use CI\/CD (continuous integration, delivery, and deployment) tools and processes in order to provide ongoing automation and continuous monitoring throughout the software lifecycle, from integration and testing phases to delivery and deployment.    Bug and\/or Issue Tracking  Bug and\/or issue trackers provide tracking information for bugs or issues that have been identified in the project. They typically include related reports with steps to reproduce the issue or bug, the expected behavior, and the actual behavior. More about bug and issue trackers is covered in .    Editing and Review  As we learned in , Software Engineering Collaboration Platforms like Github provide a forum for code reviews, proposed edits, proposed updates, and discussions of these via merge or pull requests. These are also a dedicated forum for discussing a proposed feature or bug fix.    Project Management  Certain project management tools, such as Kanban boards, GitHub Projects, Trello Boards, etc. are often be used to organize and track the progress of documentation-related tasks and issues. These tools typically provide a visual and flexible way to manage the workflow of creating, updating, and maintaining documentation within a OSS repository.    Version control  Version control is documented through git or another VCS. See for more detail.     Depending on the project, many other types of documentation might be found the project repository including documentation that is not easily contained in a single file or a single tool. This type of documentation includes:   Design documents  Design documents provide detailed information on the design and architecture of the project. They often include diagrams, flowcharts, and other visual aids to help developers understand the project's structure.    Developer documentation  Developer documentation provides information that is useful to developers working on the project. They often include coding conventions, APIs, and other technical information.    Feature specifications  Similar in purpose to a ROADMAP file, feature specification documents provide detailed descriptions of the features that the project is expecting to implement. They often include use cases, functional requirements, and technical specifications.    Help documents  Help documents provide information on how to get help if you are having problems with the project. They often include contact information for the project's support team, as well as troubleshooting tips and frequently asked questions.    Release notes  Release notes provide information on the changes made in a particular release of the project. They often include a list of bug fixes, new features, and other changes.    Test plans  Describing the test cases that are used to test the project's functionality, test plans often include test scenarios, expected results, and test data.    User manuals  Providing instructions on how to use the project, user manuals often include step-by-step instructions, screenshots, and troubleshooting tips.       Effective Documentation  Part of your journey is learning how to navigate the project's documentation to understand such things as how to get your development environment set-up, how to conduct yourself, as well as how you to contribute if you are so inclined. If you do want to contribute, you will be contributing not only to code, but to the historical documentation of that commit.  Documentation is a sanity-preserving tool for users of and potential contributors to your project, including your future self and perhaps your future boss or coworker.  If you needed to find out who had made a particular commit to the code in version control and why they did it, you would want the project to use tools and processes with effective documentation.  Exercise: Navigating poorly documented code Consider the following function for two minutes to see how far you can get just by looking at the code snippet alone. def findAllPrevious(self, name=None, attrs={}, text=None, limit=None, **kwargs): return self._findAll(name, attrs, text, limit, self.previousGenerator, **kwargs) Was two minutes sufficient to understand it? Even if you had written this code yourself six months ago, how likely would you be to remember what it does now? Briefly explain. Now consider the prototype with a docstring. def findAllPrevious(self, name=None, attrs={}, text=None, limit=None, **kwargs): \"\"\"Returns all items that match the given criteria and appear before this Tag in the document.\"\"\" return self._findAll(name, attrs, text, limit, self.previousGenerator, **kwargs) Now go to the following link: Documentation Example and consider it. Which of the above methods gives you the quickest idea of how to use this particular function? If you had to figure out how to use this function from an XML parsing library, which level of documentation do you hope the code would have? Explain.  Exercise: Practice good code commenting Throughout all the exercises in this book practice doing good commit messages as well as effective commenting and documentation for your coding efforts.   Write thorough comments in all your source code.  Trade sources with another student and attempt to make sense of the source from the documentation alone.     "
},
{
  "id": "exercise-18",
  "level": "2",
  "url": "sec_docu_scope.html#exercise-18",
  "type": "Checkpoint",
  "number": "6.1.1",
  "title": "Exercise: Navigating poorly documented code.",
  "body": "Exercise: Navigating poorly documented code Consider the following function for two minutes to see how far you can get just by looking at the code snippet alone. def findAllPrevious(self, name=None, attrs={}, text=None, limit=None, **kwargs): return self._findAll(name, attrs, text, limit, self.previousGenerator, **kwargs) Was two minutes sufficient to understand it? Even if you had written this code yourself six months ago, how likely would you be to remember what it does now? Briefly explain. Now consider the prototype with a docstring. def findAllPrevious(self, name=None, attrs={}, text=None, limit=None, **kwargs): \"\"\"Returns all items that match the given criteria and appear before this Tag in the document.\"\"\" return self._findAll(name, attrs, text, limit, self.previousGenerator, **kwargs) Now go to the following link: Documentation Example and consider it. Which of the above methods gives you the quickest idea of how to use this particular function? If you had to figure out how to use this function from an XML parsing library, which level of documentation do you hope the code would have? Explain. "
},
{
  "id": "exercise-practice-good-code-commenting",
  "level": "2",
  "url": "sec_docu_scope.html#exercise-practice-good-code-commenting",
  "type": "Checkpoint",
  "number": "6.1.2",
  "title": "Exercise: Practice good code commenting.",
  "body": "Exercise: Practice good code commenting Throughout all the exercises in this book practice doing good commit messages as well as effective commenting and documentation for your coding efforts.   Write thorough comments in all your source code.  Trade sources with another student and attempt to make sense of the source from the documentation alone.   "
},
{
  "id": "sec_docu_involvement",
  "level": "1",
  "url": "sec_docu_involvement.html",
  "type": "Section",
  "number": "6.2",
  "title": "Documentation as Involvement",
  "body": " Documentation as Involvement     How Documentation Suffers  Getting set up to contribute to an open source project ranges from being technically fairly easy to requiring a long series of steps including many interconnected software installations and several interconnected codebases.  Repairing or improving documentation has a reputation as being an easy way to begin contributing to a project. Newcomers can often make improvements to the documentation for such things as how to get a thing to run\/compile because they will be going through that process and might run into an issue or outdated part of documentation. They are then in a great position to improve it based on their experience.  When developers resist documenting, it is usually around several themes:   Developers often don't like technical writing for think that writing is not a principal skill.  Developers want to get on with new engineering problems instead. In OSS, developers are volunteers and writing documentation takes up more of their free time.  For commercial projects, priorities may be on releasing new features and there may be little to no time to write documentation as it is not viewed by management as valuable.   The techniques for creating an OSS community that attracts contributions from project developers are mirrored answers to the above-mentioned problems.  Dumping down words in to a text editor is not very hard; many developers write copiously in email, for example. The documentor’s challenge is finding this content wherever it is (mailing lists, IRC discussions, random wiki pages) and editing it in to something comprehensive that reveals content holes for filling. The documentation project’s success hinges on the ability to restructure rambling content and make all of that accessible to new writing contributors, so they can begin meaningful work from the very start.  A metric of this success is when any random experienced contributor is asked a question by a new contributor, and in answering, insists that the answer be documented, for example, on the project wiki using existing templates, etc. In this way new contributors are turned in to documentors who share the work burden from the existing contributors.    Getting Involved Through Documentation  Once you have identified an OSS project with an active and welcoming community, what steps should you take to become involved? Communication is the key to a healthy community, so here are some steps you can take to begin:   The first step is to learn to use the software. For web-based applications, this is often trivial. We all know how to use the Firefox browser, for example. For software that requires installation, you will likely follow directions on the website or in an INSTALL file from the repo. If needed, check out the examples and tutorials. Seeing an example of how the software works will help your understanding of the overall project.    Asynchronous Communication Channels  Familiarize yourself with the communication channels employed by the community. If they have a Discord or Slack Channel, Google Group or other mailing list, sign up and read through other recent posts there. If this is a community, you want to stay engaged with, turn on notifications for some of the most relevant channels.    Starting with the README, CONTRIBUTING, and CODE_OF_CONDUCT, read the documentation that seems most relevant to your goals.    Following the Documentation  Because opening issues about unclear, incorrect, or out-of-date documentation is an excellent place to begin contributing, if you want to start contributing, follow the documentation very slowly and deliberately, taking note of places where you experience confusion.    Synchronous Communication  Some groups also have IRC and\/or drop in video conferences that are open to all. Once you have a sense of the community, you can drop into these which will help you to become more integrated into the community.    Once you have something you want to contribute to the community, with the goal of setting up your development environment (see ), slowly and deliberately follow the directions provided by the community to set up your development environment. Here again, take note of places where you experience confusion.    Open an Issue  Once you have identified a place that documentation is confusing, wrong, etc, you are ready to open an issue. In opening an issue, most projects will have a standard format that you will want to be sure to follow.       Exercise: Getting involved    Take a technical document content plan and prepare it to show to developers.   For example, create a personal user namespace on an open source project’s wiki “User:Username\/New_page”.  Alternately, prepare it for inclusion in email.    Join the documentation mailing list; if there is no specific documentation list, join the main developer list.  Send an email with your content plan and any work done so far, request comments on content and where you are getting information from.  Proceed with writing a first draft of the content based on your plan and comments received.  If you get stuck, return to the mailing list or ask on their preferred communication channel. Your earlier introduction and content plan makes this part easier.  Return with your next draft to the mailing list, asking for a review and comments. Provide enough time, several days to a week, and be sure to engage in discussion about the content in a timely way (at least once per day.) The goal of this step is to improve the content’s accuracy.     "
},
{
  "id": "exercise-getting-involved",
  "level": "2",
  "url": "sec_docu_involvement.html#exercise-getting-involved",
  "type": "Checkpoint",
  "number": "6.2.1",
  "title": "Exercise: Getting involved.",
  "body": "Exercise: Getting involved    Take a technical document content plan and prepare it to show to developers.   For example, create a personal user namespace on an open source project’s wiki “User:Username\/New_page”.  Alternately, prepare it for inclusion in email.    Join the documentation mailing list; if there is no specific documentation list, join the main developer list.  Send an email with your content plan and any work done so far, request comments on content and where you are getting information from.  Proceed with writing a first draft of the content based on your plan and comments received.  If you get stuck, return to the mailing list or ask on their preferred communication channel. Your earlier introduction and content plan makes this part easier.  Return with your next draft to the mailing list, asking for a review and comments. Provide enough time, several days to a week, and be sure to engage in discussion about the content in a timely way (at least once per day.) The goal of this step is to improve the content’s accuracy.   "
},
{
  "id": "sec_docu_build",
  "level": "1",
  "url": "sec_docu_build.html",
  "type": "Section",
  "number": "6.3",
  "title": "Build Documentation",
  "body": " Build Documentation   You learned how version control works in . What you do with it is the topic of this section.    What is Building, Exactly?   The process of turning source code into executable binary code can be complicated. The larger the project and the more source code you have, the more complicated that process is. Almost every serious piece of software has its own build process, that every developer must follow — and woe be unto the developer who repeatedly breaks the build for everyone else.  Where do you find build directions?   There are many steps in the process of turning source code into a binary executable. Some examples of tasks that you might encounter during a typical build process:     Compiling the code.  Source code must somehow become machine code, ultimately. Sometimes this is handled in real-time by an interpreter, as in the case of scripting languages such as Perl or Javascript. For more complex applications, though, this work is usually handled by a compiler. Therefore, you must ensure that you have a proper compiler installed, and that you are calling the compiler properly with the correct compiler options.   Linking object files and libraries.  In the modern world, it’s crazy to write all of the code yourself. When you want to write output to the screen, you don’t write code that talks directly to the monitor; you use a library that handles input and output. When you want to play audio, you don’t handcode the waveforms yourself; you use audio codecs. When you compile the code, you almost always need to include libraries of one kind or another — which means you must know which libraries you need, and you must ensure that the libraries are where the compiler expects them to be, and that the libraries are all of the right version.   Determining build order and dependencies.  In complex software projects, it’s vital to keep track of dependencies. A change to code in a single library can have effects across your entire project, and might require some or all of your code to be recompiled — and often in a particular order. Keeping track of dozens of libraries, and references to those libraries by hundreds of source files, can be an ugly business.   Testing the build results.  It’s essential to know when you’ve introduced bugs sooner rather than later; new bugs are often easy to fix, and old bugs are often not so easy to fix. Also, it frequently happens that bugs, once fixed, creep back into code. Running basic tests on a project every time it’s built can be a good way to ensure that bugs get fixed and stay fixed.   Packaging and\/or Deploying.  Sometimes you want to install the program you just compiled so that it can be run from anywhere on the system, and other programs or users can find it. Or sometimes you want to bundle it up into a format that allows anyone to take your executable and install it easily for themselves. You don’t want to do this for every build, but when you know that your build is good, one of the important final steps is to put the executable, and all documentation, in a central location.    Performing all of these tasks by hand would be time-consuming and difficult. Build automation tools allow the developer to handle all of these tasks automatically — and thus, to manage projects with a much higher degree of complexity.    Living With Complexity  Fair warning: sometimes code doesn’t compile. Sometimes you follow all the instructions, and it still doesn’t work. What then?  If this is your first experience dealing with a large codebase written by someone else, then welcome to the real world. As you run your first build, you may have very little idea of what’s actually going on. Don’t get discouraged. Have patience; you’ll soon begin to figure it all out.  You are about to walk through a software build process. The typical build command might return hundreds, or even thousands, of log entries, all of which scroll across the screen at lightning speed. You may understand all, some, or none of those entries.  That’s okay. Everyone starts somewhere.  Here are some points to keep in mind.   Start with the README.   Start with the README file which serves to explain the project, what it does, why it is useful, etc. If GitHub detects a README file in the source, it will render it on the landing page of the project, so this file is typically the first item one will see when visiting the repository. Although build instructions are sometimes found elsewhere, the README will likely at least link to the page that details how to get set up to locally build the project.   Read instructions carefully.  Almost every sizable OSS project has a README or an INSTALL file that provides instructions for how to build and install the software. Read those instructions, and do your best to follow them carefully. Understand that even the best instructions may leave out a step or two — and if you encounter a missing step, it is an opportunity to improve the project.   Don’t expect to understand every word.  Very few developers understand every single word of every build log they encounter. Don’t be intimidated.   Read logs carefully and thoughtfully.  When you see an error, read back and think about what it could mean. Does the error say “couldn’t find something”? That probably means you didn’t install a library dependency properly. Was the error you first saw the only error in the log? In a 1000-line build log, the error at the end could be the result of another error dozens, or hundreds, of lines earlier. If your build doesn’t end happily, don’t panic. Relax and work your way through the problem from the first problem that was encountered.   Search engines are your friends.  If you don’t understand an error message, search for it! Googling an error message can be a surprisingly effective method for determining what’s gone wrong. There’s a decent chance that someone before you has run into the same error, and someone has posted the solution to your problem on a message board or mailing list. Even if the answer isn’t obvious, there will frequently be clues. The Internet is a gigantic resource. Use it.   Ask for help.  If you’ve done your homework and still can’t figure out why your program isn’t building, get on the project’s mailing list or message board, and ask for help. The more you’ve dug into the problem, and the more information you provide, the more likely it is that developers will help you figure out the problem.    "
},
{
  "id": "p-884",
  "level": "2",
  "url": "sec_docu_build.html#p-884",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Start with the README. Read instructions carefully. Don’t expect to understand every word. Read logs carefully and thoughtfully.  Search engines are your friends. Ask for help. "
},
{
  "id": "sec_issues_bugs",
  "level": "1",
  "url": "sec_issues_bugs.html",
  "type": "Section",
  "number": "6.4",
  "title": "Issue and Bug Documentation",
  "body": " Issue and Bug Documentation   Open source software communities use documentation to enhance the software they produce in part via issue and\/or bug trackers. When software doesn't perform as you'd expect, users might file a report. They can report inaccurate documentation, suggest new software features, report a bug, or note a potential security hole in a piece of software by filing an issue report.  Issue trackers are a common component of platforms like Github for working together on open source software projects. Other stand-alone bug trackers and issue trackers include Bugzilla , Redmine , and Trac . All serve the same purpose, namely tracking bugs and issues like new feature requests.   Issues and Bugs, Oh My!  In any given OSS project, you might encounter terms like, issue, bug, defect, etc. In the broader context of OSS, these terms are often used interchangeably, but they can have slightly different connotations depending on the specific project and its development practices.  An issue typically refers to any problem, request, or task that is tracked and managed within the project's issue tracking system. While issues can include bugs and defects, they are not limited to technical problems alone. Issues can encompass a wide range of things, including feature requests, bug reports, documentation improvements, or even general discussions about the project. They serve as a centralized way for contributors and maintainers to communicate and collaborate on various aspects of the project.  A bug is when software produces problematic results. Bugs cause unintended behaviors that deviate from the expected or specified functionality. Bugs can arise due to programming mistakes, logical errors, compatibility issues, or unexpected interactions between different components of the software. In open source projects, bug reports are often filed as issues, and developers work to identify, reproduce, and fix them.  Some projects also differentiate defect , from bug. A defect refers to a flaw or problem in software that leads to undesired behavior. However, the term defect is sometimes used in a broader sense to encompass not only software errors but also issues related to design, architecture, documentation, or other aspects of the software development process. Defects can be thought of as any deviation from the expected quality standards or requirements of the project. They can include functional or non-functional issues that impact the overall performance, usability, security, or reliability of the software.    Issue and Bug Trackers   Take a closer look at the issues in an OSS project’s issue tracker. In particular, spend some time looking through those that are in the  open  state.  It’s certain that some of these reports are not be very useful for a variety of reasons.  For software to improve over time, good issue and bug reports are absolutely essential. Users who file issues, while almost always well-meaning, frequently don’t know how to write good issue reports — which is a problem, but also an opportunity for others to make positive contributions. Turning a bad issue or bug report into a good issue or bug report doesn’t require special developer knowledge; it just requires patience, persistence, a solid understanding of how the software works, and an understanding of what good issue and bug reports look like.  So what does a good issue or bug report look like? Look at some of the characteristics.   Any project worth your time utilizes an issue tracker of some kind.  It would be foolhardy to try to teach the practice of software quality assurance in one chapter. It’s a vast field, and there are plenty of places to learn about the difference between  white-box  and  black-box  testing, or how to write the best possible  regression tests . Those are all worthy fields of study, and you should pursue them — but they are far beyond the scope of this section.  Besides, the simple fact is that for most software projects, issues and bugs are not so uncommon that you need to go looking for them. They find you.  What makes open source interesting, and different, is that  you can actually do something about the issues and bugs .  Eric S. Raymond once said that “with enough eyes, all bugs are shallow.” This aphorism has become one of the central tenets of OSS — but it’s only half of the story. The real strength of open source lies in the ability of motivated individuals to record, research, and resolve those bugs. Seeing bugs is one thing; reporting them is another; fixing them is something else.  In this section, you learn some of the practical techniques that OSS developers use to find, report, investigate, and fix bugs — and you can begin to contribute to real OSS projects. You will join the global collaborative effort to solve real problems, for real users, in real software.    What is an Issue Tracker, Exactly?  A bug or issue tracker for a open source project is a web application that allows users to enter bug reports about a software project. These bug reports then go into a database, where they can be tracked and managed as the developers work to fix them.  There are many different issue trackers available for use by open source projects. Most of them collect very similar information:    Summary, a short description of the issue or bug. For example: “Toaster always burns toast”. This short phrase is usually what the developer sees in his or her list of bugs.   Description, a more detailed description of the issue or bug, ideally with lots of detail. This is where the reporter explains what they were doing, what was expected to happen, and what happened instead. For example, “I have a BreadNuke toaster model XZ-38, and it never works. I expect it to brown my toast nicely; but it always burns my toast instead. I’ve tried setting the knob from 0 to 9, and the toast always comes out completely black!”   Comments, which allow other users or developers to add information to the bug. For example, a user might say “it burns my toast too!” Or, a developer might respond “the docs for the XZ-38 specify that it’s for creating Blackened Toast”. For a complex bug, there can be literally hundreds of comments attached to the bug report.   Reporter  is the username or email address or account name of the user who reported the bug. This is often collected automatically.   Owner  is the username or email address or of the developer assigned to fix the bug.   Version . When there are multiple versions of the software, it’s obviously important to know which version the issue or bug report is referencing.   Severity  and  Priority . Severity, usually set initially by the user, indicates the impact that an issue or bug has. Priority, usually set initially by the developer, indicates which issues or bugs receive attention first.   Status , which describes the state a bug is in. Bugs start with a  new   or open status, and then they become  assigned  when a developer is tasked to work on them. The ultimate goal is to move a bug’s status to  closed .   Resolution , which is particular to closed bugs.  Fixed  means just that: the bug was fixed.   Nextrelease  indicates that a bug has been fixed, but the fix won’t be available to users until the next release of the software. Users often file bugs that aren’t actually bugs, but are the result of user error; such bugs are closed as  invalid  or  notabug . Lots of bugs are duplicates of one another, so bugs are often closed as  duplicate  with a reference to a single authoritative bug report. Occasionally, a bug is just not worth the work required to close it; these bugs are closed  wontfix .   Because all of this data is collected in a structured way, it becomes much easier to sort through the bugs for meaningful data — which becomes essential as the project grows, and the bugs multiply.    Sorting through the Issues  Much of a software developer’s time is spent fixing bugs, and there are almost always more bugs than there is time to fix those bugs — which means that having a good way of deciding which bugs are important, at any given time, is crucial.  All issue and bug trackers have functionality for searching by detailed criteria. Some common searches that developers might run, for instance:   “What’s new and broken today?” Find every bug with a status of  new .  “What should I work on first today?” Find every high priority bug assigned to the developer.  “What bugs did we close that should go in the notes for our upcoming release?” Find all of the bugs with the latest version, that have a status of  closed  and a resolution of  fixed  or  nextrelease .   And so on.  Exercise – Find the Oldest Bug Find the oldest bug that’s still open in your chosen project. Write a blog entry describing the problem, with a theory about why the bug hasn’t been resolved yet. (Bonus points if you can actually resolve the bug.)  Exercise – Identify the Issue Tracker Identify the issue tracker of your chosen project.    The Anatomy of a Good Bug Report   What makes a useful bug report?    Take a closer look at the bugs in your project’s issue or bug tracker. In particular, spend some time looking through bugs in the  new  state.  It’s certain that some of these bug reports are not be very useful.  For software to improve over time, good bug reports are absolutely essential. Users who file bugs, while almost always well-meaning, frequently don’t know how to write good bug reports — which is a problem, but also an opportunity for others to make positive contributions. Turning a bad bug report into a good bug report doesn’t require special developer knowledge; it just requires patience, persistence, a solid understanding of how the software works, and an understanding of what good bug reports look like.  So what does a good bug report look like? Look at some of the characteristics of good bug reports.    Good bugs reports have descriptive summaries   Bad: Audio player hangs Good: Audio Player stutters when playing some kinds of audio files Best: Audio Player stutters when playing .mp3\/.wav files > 35Mb, patch attached   Software developers, like most people, are busy and lazy in roughly equal parts. When a developer has decided to spend a day “fixing bugs,” that developer likely starts by scanning the bug list. If she sees a bug summary that says “your program is broken,” it’s unlikely to provoke a favorable response. Summaries matter. The goal is to pack as much information into a single line of text. The more information the developer sees in a bug summary, the more likely she is to dig into that bug.    Good bugs reports refer to the version of the software.   Bad: Zombie-buster version... two-something? Good: Zombie-buster-1.2.4 Best: Zombie-buster-1.2.4 and confirmed in HEAD, git commit 1361   Most of the time, the bug tracker you use has a predefined field for version. That field is a good start, but sometimes the entries can be outdated, and even if there’s an entry for  HEAD  (i.e. the very latest code in the SCM), it’s still important to provide the most detailed version information that you can possibly provide. What you absolutely must NOT do: ignore this field. If you can’t figure out what version of the software you’re running, then you probably shouldn’t even file a bug.    Good bugs reports provide relevant system information   Bad: I'm running Linux, if that matters. Good: I'm running Gnome 2.28 on Fedora 12. Best: Gnome 2.28, Fedora 12, nVidia Corporation G70 GeForce 7800 GTX (rev a1)   It’s easy to provide way too much of this kind of information, but that’s a forgivable sin: it’s certainly better than providing none at all, which is too frequently the case. Over time, you develop a feel for which information to provide — and if you become a trusted contributor to a project, developers feel more comfortable asking for precisely the information they need. Until developers say otherwise, it’s usually best to err on the side of providing too much info. (Within reason. Dumping the entire contents of gigantic log files into a bug report is clearly bad form, but a relevant log file may be attached to a bug report.)    Good bugs reports only report a single issue   Bad: When I load the latest Foomail client, it crashes. Also, I'm getting screen lockups in Barchat. I think they're related. Good: Bug 1: Foomail client crashes. Bug 2: Lockups in Barchat. Best: Bug 1: Foomail client crashes. I think it may be related to lockups in Barchat (and here's some evidence). Bug 2: Lockups in Barchat. I think it might be related to Foomail client crashes (and here's some evidence).   It’s tempting sometimes to see multiple issues, convince yourself that they are related, and then file a single bug on the whole thing.  Don’t do that. You may very well be right that the issues are related — but you may also be wrong, and in either case, two different issues deserve two different bug reports. In our example above, it may be that the issues with Foomail and Barchat  are actually related to a problem with Bazlib , which is a shared component of Foomail and  Barchat . Each bug must be fixed and tested in its own context, and that won’t work if they’re all stuffed in the same bug report.    Good bugs reports are followed by people who care about a solution   Bad: What, you said file a bug report, I filed a bug report. I don't care if you fix it. How do I turn off these email notifications? Good: Hey, I checked the latest version like you asked, and it still isn't fixed. Do you need more info? Best: I kept poking at this bug, and this log entry makes me think it's somewhere in libfoo. I'll keep digging.   Never underestimate the power of attention. The more you care about a particular bug, the more likely it is that the developer will care about it. The more work you do to chase it down, the more obligated the developer feels to spend some time on it also, and the more appreciative he or she is. If you file a bug that no one cares enough to follow up on, not even you, then why should the developer care enough to fix it? Especially if there are other bugs that people do care about?    Good bugs reports are reproducible with the fewest possible steps   Bad: start it and click around for a while and then it crashes Good: Start the application. Click the mouse button and type on the keyboard. Within 45 seconds or less, the application will always crash. Best: Start the application. Click the mouse five times, and the application crashes with the following error message in \"\/var\/log\/foo.err\"...   Anybody can break software. People break software all the time. But it takes a bit of practice and skill to break things predictably, over and over — and if there’s no one exercising this skill on a project’s behalf, it’s much more difficult to improve that project over time. That’s why software companies hire testers (although they almost never hire as many as they should.)  Reproducing bugs is one of the best ways to learn how software actually works. A tester who has explored a bug thoroughly, and who can confidently say “this bug only happens when these three conditions are met,” is much more likely to be able to take the next step: namely, to dig in and find the code that actually creates those three conditions.  Sometimes it’s not possible to reproduce a bug 100% of the time. Intermittent bugs are extremely frustrating for both testers and developers; they are frequently the result of complex software interactions, and reproducing the bug is actually the hardest part of fixing it. In such cases, testers should do their best to provide as much information as possible, and be ready to answer a developer’s questions.    Exercise: Reproduce a Bug Go through your project’s bug tracker and find a bug that you think you might be able to reproduce — and then try to reproduce it in the latest build. Take careful notes. Report your experiences as a comment to the bug. If you can reproduce the bug, great! Give as much information as you can. If you can’t reproduce the bug, great! Give as much information as you can, and ask the original reporter if there are other steps you might be able to take to reproduce the bug.   Bug Triage  Some projects receive a handful of bug reports. Some projects receive tens of thousands of bug reports. Most active projects have overworked developers. In software projects, there are almost always more bugs than time to fix them.  Bug triage is needed!  The title  triage  is borrowed from the medical profession, in which patients are stabilized and prioritized based on the severity of their condition. In the same way that patients are prioritized, bugs can be prioritized. Bug triage saves critical time for developers, and moves the project forward. It’s one of the most useful and instructive activities in which a newbie can engage.  Some projects have entire teams devoted to bug triage. A couple examples:    The GNOME Bug Squad    Ubuntu Bug triage    There are many more examples of bug triage teams — but even those projects that don’t have a dedicated team can still benefit greatly from bug triage.  Triaging a bug generally means:    Letting the user know that someone has looked at it  This simple courtesy is frequently overlooked. Bug trackers send emails to the original reporter whenever the state of a bug changes in any way — and when a user files a bug and never hears any response at all, it’s discouraging and makes it less likely that the user will bother to file another bug. A response such as, “thanks for reporting, I’ll try to reproduce today” can be very helpful.   Looking for other similar bugs  A large percentage of bugs filed against open source projects are duplicates; users frequently report bugs without searching to see if similar bugs have already been filed. Finding duplicates becomes easier with a bit of practice; the more familiar you are with a program, and the more you communicate with its developers, and the more bugs you see coming through the bug tracker, the more likely it is that you know when a bug is a duplicate. Still, even an inexperienced triager can spot obvious duplicates.   Guaranteeing proper severity and\/or priority  Users tend to think that their bugs are the most important issues in the world. Sometimes, they’re right. Often, they’re not. Part of the triager’s job is to make a good faith estimate of a bug’s severity and priority. It’s an imperfect process, so triagers are also be wrong sometimes — but experienced bug triagers are much less wrong.   Ensuring that the bug is sensible and helpful to developers  A poorly written bug report should never even make its way into the developer’s queue. If a bug report is filed with absolutely no information, it’s the triager’s job to get that information — with a politely worded comment in the bug, something like this: “Thanks for filing the bug, but there isn’t much information here. Could you help by telling us what version of Barchat you’re running, and if possible, attach the last 100 lines of ~\/.barchatlog?”   Ensuring that the bug is filed against the correct component, with the correct version  Sometimes, bugs are simply filed with the wrong information in some of the fields and it is obviously wrong. When a bug report about foomail accidentally gets filed against foomatic, reassiging that bug to the right component is simple — but vital.    Take note! If you can do these things well, you are building job references with real developers, right now.  If you are doing it right at this point, you may be setting yourself up for a job down the line.  Exercise: Bug Triage Find five bug reports in the  new  state, and attempt to triage them according to the rules above. Your goal is to do as much as you possibly can, in a short period of time, to make those bug reports as useful as possible to the developer to whom they are assigned. (Note: be sure to follow any triage rules that your project may have defined. If there are no set triage rules, be sure to announce your intentions on the project’s mailing list, so that developers can provide you some guidelines if they choose.)  Exercise: Find the leading Bug-Zapper Find the developer to whom the most bugs are assigned. Find all bugs in the  new  state that have not been reproduced, and try to reproduce them.  Exercise: Get bug notifications Figure out how to get yourself put on the default  Cc:  of a particular bug or component, so that you see new bug reports in your email.    More Advice on Bug Reports   The Fedora project has good guidelines for bug reporters at  How to file a bug report . A bit specific to Fedora in places, but very instructive.  The Mozilla project also has a set of  bug reporting guidelines , and a great  etiquette guide  as well. Specific to Mozilla, but instructive.  Simon Tatham’s  How to Report Bugs Effectively  is a truly outstanding work. Strongly recommended.    "
},
{
  "id": "p-888",
  "level": "2",
  "url": "sec_issues_bugs.html#p-888",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "issue "
},
{
  "id": "p-889",
  "level": "2",
  "url": "sec_issues_bugs.html#p-889",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "bug "
},
{
  "id": "p-890",
  "level": "2",
  "url": "sec_issues_bugs.html#p-890",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "defect "
},
{
  "id": "exercise-find-the-oldest-bug",
  "level": "2",
  "url": "sec_issues_bugs.html#exercise-find-the-oldest-bug",
  "type": "Checkpoint",
  "number": "6.4.1",
  "title": "Exercise – Find the Oldest Bug.",
  "body": "Exercise – Find the Oldest Bug Find the oldest bug that’s still open in your chosen project. Write a blog entry describing the problem, with a theory about why the bug hasn’t been resolved yet. (Bonus points if you can actually resolve the bug.) "
},
{
  "id": "exercise-identify-the-issue-tracker",
  "level": "2",
  "url": "sec_issues_bugs.html#exercise-identify-the-issue-tracker",
  "type": "Checkpoint",
  "number": "6.4.2",
  "title": "Exercise – Identify the Issue Tracker.",
  "body": "Exercise – Identify the Issue Tracker Identify the issue tracker of your chosen project. "
},
{
  "id": "p-924",
  "level": "2",
  "url": "sec_issues_bugs.html#p-924",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Foomail Barchat Bazlib Foomail Barchat "
},
{
  "id": "exercise-reproduce-a-bug",
  "level": "2",
  "url": "sec_issues_bugs.html#exercise-reproduce-a-bug",
  "type": "Checkpoint",
  "number": "6.4.3",
  "title": "<dfn class=\"terminology\">Exercise: Reproduce a Bug<\/dfn>.",
  "body": "Exercise: Reproduce a Bug Go through your project’s bug tracker and find a bug that you think you might be able to reproduce — and then try to reproduce it in the latest build. Take careful notes. Report your experiences as a comment to the bug. If you can reproduce the bug, great! Give as much information as you can. If you can’t reproduce the bug, great! Give as much information as you can, and ask the original reporter if there are other steps you might be able to take to reproduce the bug. "
},
{
  "id": "exercise-bug-triage",
  "level": "2",
  "url": "sec_issues_bugs.html#exercise-bug-triage",
  "type": "Checkpoint",
  "number": "6.4.4",
  "title": "Exercise: Bug Triage.",
  "body": "Exercise: Bug Triage Find five bug reports in the  new  state, and attempt to triage them according to the rules above. Your goal is to do as much as you possibly can, in a short period of time, to make those bug reports as useful as possible to the developer to whom they are assigned. (Note: be sure to follow any triage rules that your project may have defined. If there are no set triage rules, be sure to announce your intentions on the project’s mailing list, so that developers can provide you some guidelines if they choose.) "
},
{
  "id": "exercise-25",
  "level": "2",
  "url": "sec_issues_bugs.html#exercise-25",
  "type": "Checkpoint",
  "number": "6.4.5",
  "title": "Exercise: Find the leading Bug-Zapper.",
  "body": "Exercise: Find the leading Bug-Zapper Find the developer to whom the most bugs are assigned. Find all bugs in the  new  state that have not been reproduced, and try to reproduce them. "
},
{
  "id": "exercise-26",
  "level": "2",
  "url": "sec_issues_bugs.html#exercise-26",
  "type": "Checkpoint",
  "number": "6.4.6",
  "title": "Exercise: Get bug notifications.",
  "body": "Exercise: Get bug notifications Figure out how to get yourself put on the default  Cc:  of a particular bug or component, so that you see new bug reports in your email. "
},
{
  "id": "list_of_symbols",
  "level": "1",
  "url": "list_of_symbols.html",
  "type": "Appendix",
  "number": "A",
  "title": "List of Symbols",
  "body": " List of Symbols   "
},
{
  "id": "ap_shell_cheat_sheet",
  "level": "1",
  "url": "ap_shell_cheat_sheet.html",
  "type": "Section",
  "number": "B.1",
  "title": "Bash Shell Cheat Sheet",
  "body": " Bash Shell Cheat Sheet   Getting help with shell commands     man <command-name>  Use the built-in manual .    e.g. man cd retrieves the manual for the change directory command.      <command-name> --help   Request the help page (when it exists) for the specified command. Note that not every command supports --help .    e.g. cd --help retrieves help for the change directory command.         File and Directory Commands     pwd   Print working directory displays the path of the current working directory.    e.g. pwd prints the path of the current working directory.      whoami  The whoami prints the userid of the current user.    e.g. whoami prints the userid.      ls   List displays basic information about files and directories.     e.g. ls lists directories and files in the current directory.    e.g. ls -l lists directories and files in the current directory using a long listing.    e.g. ls ~ lists directories and files in the user's home directory.       touch <file-name>  The touch command is commonly used for file creation. Its intended primary function is to update its timestamp, by \"touching\" it. See man touch for more information on the intended use.    e.g. touch newfile.txt creates an empty file named newfile.txt.      cd <directory-name>   Change directory to <directory-name> .   e.g. cd \/ changes the current directory to the root directory.    e.g. cd ~ changes the current directory to the user's home directory.    e.g. cd .. changes the directory to the immediate parent directory.       mv <old-name> <new-name>   Move (rename) files or directories.   e.g. mv old.txt new.txt changes the name of old.txt to new.txt.       rm <file-name>   Remove deletes a file or directory.   e.g. rm junk.txt removes the file named junk.txt.       mkdir <directory-name>   Make directory with name <directory-name>.   e.g. mkdir newdir makes a new directory with the name newdir.        rmdir <directory-name>   Remove directory with specified name <directory-name>   e.g. mkdir olddir removes (deletes) the directory with the name olddir.          The Basics: Reading, Writing, Counting, etc     echo <text>  The echo command displays a line of text and\/or requests the value of a variable from the shell and displays its value. Often used with output redirection.   e.g. echo 'Hello World!' print the text 'Hello World!' on the standard output.    e.g. echo $USER prints the value of the USER environment variable on the standard output.       cat <file-name>  The concatenate prints file contents on the standard output after concatenation. Note that with a single file, it just prints that file. It is often used with output redirection.   e.g. cat file.txt prints the contents of file.txt on the standard output.    e.g. cat file1.txt file2.txt prints the contents of the concatenation of file1.txt and file2.txt on the standard output.       read <variable-name>  The read command reads a line or variable from the keyboard. It is often used with scripts or input redirection.   e.g. read MYVAR takes input from the keyboard and directs it into a variable called MYVAR.       wc <file-name>  The word count command performs a count of lines, words, and bytes for each file.   e.g. wc file.txt reports the count of lines, words, and bytes in file.txt.          Input and Output Redirection     Input redirection using <  Input redirection uses using < to allow the user to redirect the input from a file rather than the keyboard.   e.g. wc < info2count.txt performs the wc command on the information in the file info2count.txt.       Output redirection using > or >>  Output redirection allows the user to redirect the output from the standard output to a file using > for overwriting or >> for appending.   e.g. echo 'I love open source!' > file.txt writes the line 'I love open source!' into the file file.txt replacing the current contents or making a new file if it doesn't already exist.       Piping |  A pipe  | in the bash shell allows you to redirect (pipe) the output of one command into the input of another command.   e.g. ls | wc runs the command ls >and uses the output of the ls command as the input into the wc command.          File Permissions     chown <newuser:newgroup> <file-name>  The chown command is used to change the file owner and\/or group.   e.g. chmod pearcej file.txt changes the owner of file.txt to pearcej.    e.g. chmod :friends file.txt changes the group of file.txt to friends.       chmod <change><which> <file-name>  The chmod command is used to change permissions. The following symbols are the most commonly used:   + change by adding permission   - change by removing permission   r which permission: read   w which permission: write   x which permission: execute     e.g. chmod +x helloworld.sh adds execute permission for all users to the helloworld.sh file.          Need more detail?    For more information on any of these commands, see or use the man pages.   "
},
{
  "id": "p-945",
  "level": "2",
  "url": "ap_shell_cheat_sheet.html#p-945",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "manual help page "
},
{
  "id": "p-950",
  "level": "2",
  "url": "ap_shell_cheat_sheet.html#p-950",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Print working directory whoami List touch Change directory Move Remove Make directory Remove directory "
},
{
  "id": "p-974",
  "level": "2",
  "url": "ap_shell_cheat_sheet.html#p-974",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "echo concatenate read word count "
},
{
  "id": "p-985",
  "level": "2",
  "url": "ap_shell_cheat_sheet.html#p-985",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "pipe "
},
{
  "id": "p-992",
  "level": "2",
  "url": "ap_shell_cheat_sheet.html#p-992",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "chown "
},
{
  "id": "ap_git_cheat_sheet",
  "level": "1",
  "url": "ap_git_cheat_sheet.html",
  "type": "Section",
  "number": "B.2",
  "title": "Git Cheat Sheet",
  "body": " Git Cheat Sheet      Getting started with a project    git init <directory-name>  Create an empty git repo in a new directory named directory-name . Take care with the directory-name ; it is typical to use a short, descriptive, name using only lower case letters and the \"-\" character. Note that if you leave off the directory name then the current directory will be initialized as a git repository. For more detail see Git Guides: Git Init     git clone <repository-url>  Clone a repository from a repository in the cloud to your local system. Note that if you are planning to contribute to a project that is not yours, you will likely want to fork the repository into your own account first. For example, to contribute to a project hosted on GitHub, go to that repository and fork it into your own GitHub account. For more detail see Git Guides: Git Clone       Current state    git diff  List the changes to files that have not yet been added (staged).    git status  Check the status to see if there are files that have been changed but not added (staged). This command will also list all staged changes. For more detail see Git Guides: Git Status     git log  List recent commits.    git pull  Download content from the remote repository and integrate these changes into the local repository. This command should be used regularly because without it your local branch won't have any of the updates that are present on the remote. For more detail see Git Guides: Git Pull     git add <filename>  Add all current changes in <filename>to the those staged for the next commit. For more detail see Git Guides: Git Add     git commit -m \"<commit-message>\"  Commit all staged files to the local repository. For more detail see Git Guides: Git Commit     git push  Push the current branch and all commits to the remote repository. Note that git push only updates the corresponding branch on the remote.    git push -u origin <branchname>  Here -u stands for set upstream. It is used to push a new branch named <branchname> by creating an upstream tracking branch that is related to your current local branch. For more detail see Git Guides: Git Push       Git branching    git branch  List all existing branches.    git checkout -b <branch-name>  Create a new branch called <branch-name> and switch to that branch. Without the -b flag will allow you to checkout an existing branch.     "
},
{
  "id": "p-1007",
  "level": "2",
  "url": "ap_git_cheat_sheet.html#p-1007",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "fork "
},
{
  "id": "index-1",
  "level": "1",
  "url": "index-1.html",
  "type": "Index",
  "number": "",
  "title": "Index",
  "body": " Index   "
},
{
  "id": "colophon-2",
  "level": "1",
  "url": "colophon-2.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " This book was authored in PreTeXt .  "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
